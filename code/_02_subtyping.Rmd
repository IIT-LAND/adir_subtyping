---
title: "NDAR EU-AIMS subtyping analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load libraries and data

```{r, warning=FALSE, message=FALSE}
easypackages::libraries("here","ggplot2","caret","e1071","pheatmap","reshape2","NbClust","grid","patchwork","readxl","patchwork","WGCNA","psych","nlme","reshape2")
source(here("code","ndar_functions.R"))
source(here("code","euaims_functions.R"))
source(here("code","get_ggColorHue.R"))
source(here("code","cohens_d.R"))
source(here("code","Repfunctionspack6.R"))


options(stringsAsFactors = FALSE)
fontSize = 20
nperm=1

codepath = here("code")
datapath = here("data")
figpath = here("figures")
resultpath = here("results","ndar")
plotpath = here("plots","ndar")

# function to make subtype
make_subtype <- function(data2use, z_thresh, mean2use=NULL, sd2use=NULL){
  # compute difference score
  vars2use = c("dbaes_atotal","dbaes_btotal")
  diff_score = data2use[,vars2use[1]] - data2use[,vars2use[2]]

  # compute mean and sd if necessary
  if (is.null(mean2use)){
    mean2use = mean(diff_score)
  } # if (is.null(mean2use))

  if (is.null(sd2use)){
    sd2use = sd(diff_score)
  } # if (is.null(sd2use))

  # compute z-score
  data2use$z_ds = (diff_score - mean2use)/sd2use

  # make subtype factor
  data2use$z_ds_group = "SC_equal_RRB"
  data2use$z_ds_group[data2use$z_ds>z_thresh] = "SC_over_RRB"
  data2use$z_ds_group[data2use$z_ds<(z_thresh*-1)] = "RRB_over_SC"
  data2use$z_ds_group = factor(data2use$z_ds_group)
  return(data2use)

} # function make_subtype

# read in data
Dverbal_Discovery = read.csv(file.path(datapath,"tidy_verbal_disc.csv"))
Dverbal_Replication = read.csv(file.path(datapath,"tidy_verbal_rep.csv"))
vars2use = c("dbaes_atotal","dbaes_btotal")
rownames(Dverbal_Discovery) = Dverbal_Discovery$subjectkey
rownames(Dverbal_Replication) = Dverbal_Replication$subjectkey

#------------------------------------------------------------------------------
# add in ADOS
ados_Discovery = read.csv(file.path(datapath,"ndar_ados_css_discovery.csv"))
ados_Replication = read.csv(file.path(datapath,"ndar_ados_css_replication.csv"))
ados_Discovery$ados_age = ados_Discovery$interview_age
ados_Replication$ados_age = ados_Replication$interview_age

Dverbal_Discovery$ados_age = NA
Dverbal_Discovery$ados_sa_css = NA
Dverbal_Discovery$ados_rrb_css = NA
Dverbal_Replication$ados_age = NA
Dverbal_Replication$ados_sa_css = NA
Dverbal_Replication$ados_rrb_css = NA
# mask = is.element(Dverbal_Discovery$subjectkey,ados_Discovery$subjectkey)
Dverbal_Discovery[ados_Discovery$subjectkey,"ados_age"] = ados_Discovery$interview_age
Dverbal_Discovery[ados_Discovery$subjectkey,"ados_sa_css"] = ados_Discovery$ados_sa_css
Dverbal_Discovery[ados_Discovery$subjectkey,"ados_rrb_css"] = ados_Discovery$ados_rrb_css
Dverbal_Replication[ados_Replication$subjectkey,"ados_age"] = ados_Replication$interview_age
Dverbal_Replication[ados_Replication$subjectkey,"ados_sa_css"] = ados_Replication$ados_sa_css
Dverbal_Replication[ados_Replication$subjectkey,"ados_rrb_css"] = ados_Replication$ados_rrb_css

#------------------------------------------------------------------------------
# add in IQ
iq_Discovery = read.csv(file.path(datapath,"ndar_iq_discovery.csv"))
iq_Replication = read.csv(file.path(datapath,"ndar_iq_replication.csv"))
iq_Discovery$iq_age = iq_Discovery$interview_age
iq_Replication$iq_age = iq_Replication$interview_age

Dverbal_Discovery$iq_age = NA
Dverbal_Discovery$iq = NA
Dverbal_Replication$iq_age = NA
Dverbal_Replication$iq = NA
# mask = is.element(Dverbal_Discovery$subjectkey,ados_Discovery$subjectkey)
Dverbal_Discovery[iq_Discovery$subjectkey,"iq_age"] = iq_Discovery$iq_age
Dverbal_Discovery[iq_Discovery$subjectkey,"iq"] = iq_Discovery$IQ
Dverbal_Replication[iq_Replication$subjectkey,"iq_age"] = iq_Replication$iq_age
Dverbal_Replication[iq_Replication$subjectkey,"iq"] = iq_Replication$IQ
```

## Hierarchical clustering

```{r, warning=FALSE, message=FALSE}
#------------------------------------------------------------------------------
# Subtype using hierarchical clustering and dynamic hybrid tree cut algorithm to find the subtypes

# NDAR Discovery --------------------------------------------------------------

# deep split parameter
dS = 0
maxScores = c(3,4)

data2use = Dverbal_Discovery[,vars2use]

# discReorderedItems = colnames(data2use)
fname2save = file.path(plotpath,
                       sprintf("clustergram_ADIalgoTotals_verbalDiscovery_euclidean_ward_deepSplit%d.pdf",dS))
verbalDiscovery_clustResults = ClusterData(data2use,
                                           deepSplit=dS,
                                           fname2save = fname2save)

oldColors = c("blue","brown","green","red","turquoise","yellow")
newColors = c("5","4","6","3","2","1")

verbalDiscovery_clustResults = relabelClusters(verbalDiscovery_clustResults, oldColors, newColors)
makeClustergram(verbalDiscovery_clustResults, fname2save = fname2save)

# make plot with all individuals shown as lines
df2use = Dverbal_Discovery[,c("subjectkey",vars2use)]
df2use$subgrp = factor(verbalDiscovery_clustResults$dynamicColors)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
# df2use$dbaes_atotal = df2use$dbaes_atotal
# df2use$dbaes_btotal = df2use$dbaes_btotal
df2use$SC = df2use$dbaes_atotal
df2use$RRB = df2use$dbaes_btotal
df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"),
               measure.vars = c("SC","RRB"))

colors2use = get_ggColorHue(7)
colors2use = colors2use[1:6]
p = ggplot(data = df4plot, aes(x = variable,
                               y = value,
                               colour = subgrp,
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + guides(color=FALSE) + ylim(0,1)
p = p + scale_colour_manual(values = colors2use)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
fname2save = file.path(plotpath,
                       sprintf("summaryPlot_IndividualSubs_ADIalgoTotals_verbalDiscovery_euclidean_ward_deepSplit%d.pdf",dS))
ggsave(filename = fname2save)
p

# scatterplot
p_disc = ggplot(data = df2use, aes(x = SC, y = RRB, colour = factor(subgrp))) + geom_point() + xlab("Social-Communication") + ylab("Restricted Repetitive Behaviors") + ggtitle("NDAR Discovery") + ylim(0,1) + xlim(0,1) + scale_colour_manual(values = colors2use)
p_disc


# NDAR Replication ------------------------------------------------------------

# deep split parameter
dS = 0
maxScores = c(3,4)

data2use = Dverbal_Replication[,vars2use]

# discReorderedItems = colnames(data2use)
fname2save = file.path(plotpath,
                       sprintf("clustergram_ADIalgoTotals_verbalReplication_euclidean_ward_deepSplit%d.pdf",dS))
verbalReplication_clustResults = ClusterData(data2use,
                                             deepSplit=dS,
                                             fname2save = fname2save)

oldColors = c("black","blue","brown","green","red","turquoise","yellow")
newColors = c("7","1","4","3","2","6","5")

verbalReplication_clustResults = relabelClusters(verbalReplication_clustResults, oldColors, newColors)
makeClustergram(verbalReplication_clustResults, fname2save = fname2save)

# make plot with all individuals shown as lines
df2use = Dverbal_Replication[,c("subjectkey",vars2use)]
df2use$subgrp = factor(verbalReplication_clustResults$dynamicColors)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
# df2use$dbaes_atotal = df2use$dbaes_atotal
# df2use$dbaes_btotal = df2use$dbaes_btotal
df2use$SC = df2use$dbaes_atotal
df2use$RRB = df2use$dbaes_btotal

df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"),
               measure.vars = c("SC","RRB"))

p = ggplot(data = df4plot, aes(x = variable,
                               y = value,
                               colour = subgrp,
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + guides(color=FALSE) + ylim(0,1)
# p = p + scale_colour_manual(values = colors2use)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
fname2save = file.path(plotpath,
                       sprintf("summaryPlot_IndividualSubs_ADIalgoTotals_verbalReplication_euclidean_ward_deepSplit%d.pdf",dS))
ggsave(filename = fname2save)
p

# scatterplot
p_rep = ggplot(data = df2use, aes(x = SC, y = RRB, colour = factor(subgrp))) + geom_point() + xlab("Social-Communication") + ylab("Restricted Repetitive Behaviors") + ggtitle("NDAR Replication") + ylim(0,1) + xlim(0,1)
p_rep

# Subtype using hierarchical agglomerative clustering, looking for k=3

# Will use SC, RRB and the difference score as features

# how many clusters do you want?
nclusters = 3

# cluster with SC, RRB, and difference score
ds = Dverbal_Discovery[,vars2use[1]] - Dverbal_Discovery[,vars2use[2]]
# distance matrix
distmat = dist(x = cbind(Dverbal_Discovery[,vars2use], ds), method="euclidean")
# hierarchical clustering
disc_tree = hclust(d=distmat, method="ward.D2")
# cut the tree
treecut_res = cutree(tree=disc_tree, k=nclusters)
Dverbal_Discovery$hc_subgrp = treecut_res

ds = Dverbal_Replication[,vars2use[1]] - Dverbal_Replication[,vars2use[2]]
# distance matrix
distmat = dist(x = cbind(Dverbal_Replication[,vars2use], ds), method="euclidean")
# hierarchical clustering
disc_tree = hclust(d=distmat, method="ward.D2")
# cut the tree
treecut_res = cutree(tree=disc_tree, k=nclusters)
Dverbal_Replication$hc_subgrp = treecut_res

# Plot Discovery dataset after using hierarchical agglomerative clustering

# Discovery set
maxScores = c(3,4)

# Discovery - make plot with all individuals shown as lines
df2use = Dverbal_Discovery[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(Dverbal_Discovery$hc_subgrp)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$SC = df2use$dbaes_atotal
df2use$RRB = df2use$dbaes_btotal

df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"),
               measure.vars = c("SC","RRB"))

p = ggplot(data = df4plot, aes(x = variable,
                               y = value,
                               colour = subgrp,
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + guides(color=FALSE)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
p

# scatterplot
p_disc = ggplot(data = Dverbal_Discovery, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(hc_subgrp))) + geom_point() + xlab("Social-Communication") + ylab("Restricted Repetitive Behaviors") + ggtitle("NDAR Discovery")
p_disc
table(Dverbal_Discovery$hc_subgrp)

# Plot Replication dataset after using hierarchical agglomerative clustering
maxScores = c(3,4)

# Replication - make plot with all individuals shown as lines
df2use = Dverbal_Replication[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(Dverbal_Replication$hc_subgrp)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$SC = df2use$dbaes_atotal
df2use$RRB = df2use$dbaes_btotal

df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"),
               measure.vars = c("SC","RRB"))

p = ggplot(data = df4plot, aes(x = variable,
                               y = value,
                               colour = subgrp,
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + guides(color=FALSE)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
p

# scatterplot
p_rep = ggplot(data = Dverbal_Replication, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(hc_subgrp))) + geom_point() + xlab("Social-Communication") + ylab("Restricted Repetitive Behaviors") + ggtitle("NDAR Replication")
p_rep
table(Dverbal_Replication$hc_subgrp)

# Subtype using hierarchical agglomerative clustering, but use NbClust to find optimal number of clusters
nbc_disc_res = NbClust(data = Dverbal_Discovery[,vars2use], method = "ward.D2")
nbc_rep_res = NbClust(data = Dverbal_Replication[,vars2use], method = "ward.D2")

# Plot Discovery dataset after using hierarchical agglomerative clustering and NbClust

# Discovery set
maxScores = c(3,4)

# Discovery - make plot with all individuals shown as lines
df2use = Dverbal_Discovery[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(nbc_disc_res$Best.partition)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$SC = df2use$dbaes_atotal
df2use$RRB = df2use$dbaes_btotal

df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"),
               measure.vars = c("SC","RRB"))

p = ggplot(data = df4plot, aes(x = variable,
                               y = value,
                               colour = subgrp,
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + guides(color=FALSE)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
p

# scatterplot
Dverbal_Discovery$nbclust_subgrp = factor(nbc_disc_res$Best.partition)
p_disc = ggplot(data = Dverbal_Discovery, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(nbclust_subgrp))) + geom_point() + xlab("Social-Communication") + ylab("Restricted Repetitive Behaviors") + ggtitle("NDAR Discovery")
p_disc
table(Dverbal_Discovery$nbclust_subgrp)

# Plot Replication dataset after using hierarchical agglomerative clustering
maxScores = c(3,4)

# Replication - make plot with all individuals shown as lines
df2use = Dverbal_Replication[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(nbc_rep_res$Best.partition)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$SC = df2use$dbaes_atotal
df2use$RRB = df2use$dbaes_btotal

df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"),
               measure.vars = c("SC","RRB"))

p = ggplot(data = df4plot, aes(x = variable,
                               y = value,
                               colour = subgrp,
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + guides(color=FALSE)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
p

# scatterplot
Dverbal_Replication$nbclust_subgrp = factor(nbc_rep_res$Best.partition)
p_rep = ggplot(data = Dverbal_Replication, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(nbclust_subgrp))) + geom_point() + xlab("Social-Communication") + ylab("Restricted Repetitive Behaviors") + ggtitle("NDAR Replication")
p_rep
table(Dverbal_Replication$nbclust_subgrp)
```

## SC-RRB difference z = 0.5

```{r, warning=FALSE, message=FALSE}
#------------------------------------------------------------------------------
# Subtyping using Z-score of the difference between SC and RRB
# Z-score threshold to use for subtyping
z_thresh = 0.5

# vars2use = c("dbaes_atotal","dbaes_btotal")

# compute Discovery mean and sd
ds_disc = Dverbal_Discovery[,vars2use[1]] - Dverbal_Discovery[,vars2use[2]]
mean2use = mean(ds_disc)
sd2use = sd(ds_disc)

Dverbal_Discovery = make_subtype(data2use = Dverbal_Discovery,
                                 z_thresh = z_thresh,
                                 mean2use = mean2use,
                                 sd2use = sd2use)

# compute Replication mean and sd
ds_rep = Dverbal_Replication[,vars2use[1]] - Dverbal_Replication[,vars2use[2]]
mean2use = mean(ds_rep)
sd2use = sd(ds_rep)

Dverbal_Replication = make_subtype(data2use = Dverbal_Replication,
                                 z_thresh = z_thresh,
                                 mean2use = mean2use,
                                 sd2use = sd2use)

#------------------------------------------------------------------------------
# Table of subtypes X sex

# Discovery
table(Dverbal_Discovery$z_ds_group,Dverbal_Discovery$sex)
cs_res = chisq.test(Dverbal_Discovery$z_ds_group,Dverbal_Discovery$sex)
cs_res

# Replication
table(Dverbal_Replication$z_ds_group,Dverbal_Replication$sex)
cs_res = chisq.test(Dverbal_Replication$z_ds_group,Dverbal_Replication$sex)
cs_res

#------------------------------------------------------------------------------
# Descriptive stats

# Discovery
df2use = Dverbal_Discovery[,c("subjectkey","dataset_id","collection_id","interview_age","sex","z_ds_group","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")]
df2use$age = df2use$interview_age/12

cols2use = c("z_ds_group","sex","age","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")
res=describeBy(x = df2use[,cols2use], group = "z_ds_group")
res

# Replication
df2use = Dverbal_Replication[,c("subjectkey","dataset_id","collection_id","interview_age","sex","z_ds_group","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")]
df2use$age = df2use$interview_age/12

cols2use = c("z_ds_group","sex","age","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")
res=describeBy(x = df2use[,cols2use], group = "z_ds_group")
res

#------------------------------------------------------------------------------
# Tests of differences in interview age across the subtypes

# Discovery
mod2use = lm(formula = interview_age ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = interview_age ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in SC across the subtypes

# Discovery
mod2use = lm(formula = dbaes_atotal ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = dbaes_atotal ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in RRB across the subtypes

# Discovery
mod2use = lm(formula = dbaes_btotal ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = dbaes_btotal ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in ADOS SA CSS across the subtypes

# Discovery
mod2use = lm(formula = ados_sa_css ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = ados_sa_css ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in ADOS RRB CSS across the subtypes

# Discovery
mod2use = lm(formula = ados_rrb_css ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = ados_rrb_css ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)


#------------------------------------------------------------------------------
# Tests of differences in IQ across the subtypes

# Discovery
mod2use = lm(formula = iq ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = iq ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)


#------------------------------------------------------------------------------
# Make scatterplots with difference score Z subtypes in different colors
maxScores = c(3,4)

p_disc = ggplot(data = Dverbal_Discovery, aes(x = dbaes_atotal, y = dbaes_btotal, colour = z_ds_group)) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,1) + xlim(0,1) + ggtitle("NDAR Discovery")
p1_top_left = p_disc + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Disc_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p1_top_left)
p_disc
table(Dverbal_Discovery$z_ds_group)

cor_res = cor.test(Dverbal_Discovery$dbaes_atotal, Dverbal_Discovery$dbaes_btotal)
cor_res

p_rep = ggplot(data = Dverbal_Replication, aes(x = dbaes_atotal, y = dbaes_btotal, colour = z_ds_group)) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,1) + xlim(0,1) +  ggtitle("NDAR Replication")
p2_bottom_left = p_rep + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Rep_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p2_bottom_left)
p_rep
table(Dverbal_Replication$z_ds_group)

cor_res = cor.test(Dverbal_Replication$dbaes_atotal, Dverbal_Replication$dbaes_btotal)
cor_res

#------------------------------------------------------------------------------
# Run supervised model with Discovery as training and Replication as Test

# run validation
# make subtypes using z-scores computed from the mean and sd of the training set
train_data = Dverbal_Discovery
test_data = Dverbal_Replication

mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]])
sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]])
tmp_train = make_subtype(data2use = train_data,
                         z_thresh = z_thresh,
                         mean2use = mean2use,
                         sd2use = sd2use)

mean2use = mean(test_data[,vars2use[1]] - test_data[,vars2use[2]])
sd2use = sd(test_data[,vars2use[1]] - test_data[,vars2use[2]])
tmp_test = make_subtype(data2use = test_data,
                        z_thresh = z_thresh,
                        mean2use = mean2use,
                        sd2use = sd2use)




#==============================================================================
#==============================================================================
# make labels based on train mean and sd
mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]])
sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]])
train_mean = mean2use
train_sd = sd2use

pred_labels = make_subtype(data2use = test_data,
                        z_thresh = z_thresh,
                        mean2use = train_mean,
                        sd2use = train_sd)
confmat = table(tmp_test$z_ds_group,pred_labels$z_ds_group)
acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/dim(pred_labels)[1]

# # compute model
# mod2use = svm(x = tmp_train[,vars2use], y = tmp_train$z_ds_group)
# pred_labels = predict(mod2use, tmp_test[,vars2use])
# confmat = table(tmp_test$z_ds_group,pred_labels)
# acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/length(pred_labels)
#==============================================================================
#==============================================================================




# plot confusion matrix
setHook("grid.newpage", function() pushViewport(viewport(x=1,y=1,width=0.9, height=0.9, name="vp", just=c("right","top"))), action="prepend")
pheatmap(confmat/rowSums(confmat)*100, display_numbers = confmat, color = colorRampPalette(c('white','red'))(100), cluster_rows = FALSE, cluster_cols = FALSE, fontsize_number = fontSize, fontsize_row = fontSize, fontsize_col = fontSize,labels_row = c("RRB>SC","SC=RRB","SC>RRB"),labels_col = c("RRB>SC","SC=RRB","SC>RRB"),angle_col=90,
         breaks= seq(0,100, length=100))
setHook("grid.newpage", NULL, "replace")
grid::grid.text("Actual Labels", y=-0.07, gp=gpar(fontsize=fontSize))
grid::grid.text("Predicted Labels", x=-0.07, rot=90, gp=gpar(fontsize=fontSize))


# show accuracy
true_accuracy = acc
true_accuracy





#================================================================================
#================================================================================
# #------------------------------------------------------------------------------
# # Permute subtype labels to examine how well supervised model performs
#
# # nperm = 10000
#
# # make subtypes using z-scores computed from the mean and sd of the training set
# train_data = Dverbal_Discovery
# test_data = Dverbal_Replication
# mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]])
# sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]])
# tmp_train = make_subtype(data2use = train_data,
#                          z_thresh = z_thresh,
#                          mean2use = mean2use,
#                          sd2use = sd2use)
#
# mean2use = mean(test_data[,vars2use[1]] - test_data[,vars2use[2]])
# sd2use = sd(test_data[,vars2use[1]] - test_data[,vars2use[2]])
# tmp_test = make_subtype(data2use = test_data,
#                         z_thresh = z_thresh,
#                         mean2use = mean2use,
#                         sd2use = sd2use)
#
# acc = vector(length = nperm)
# for (iperm in 1:nperm){
#   # set seed for reproducibility
#   set.seed(iperm)
#
#   sc_perm = sample(train_data[,vars2use[1]])
#   rrb_perm = sample(train_data[,vars2use[2]])
#   perm_mean2use = mean(sc_perm - rrb_perm)
#   perm_sd2use = sd(sc_perm - rrb_perm)
#   # perm_mean2use = mean(train_data[,vars2use[1]] - rrb_perm)
#   # perm_sd2use = sd(train_data[,vars2use[1]] - rrb_perm)
#   pred_labels = make_subtype(data2use = tmp_test,
#                         z_thresh = z_thresh,
#                         mean2use = perm_mean2use,
#                         sd2use = perm_sd2use)
#   confmat = table(tmp_test$z_ds_group,pred_labels$z_ds_group)
#   acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/dim(pred_labels)[1]
#
#   # compute model
#   permuted_labels = sample(tmp_train$z_ds_group)
#   mod2use = svm(x = tmp_train[,vars2use], y = permuted_labels)
#   pred_labels = predict(mod2use, tmp_test[,vars2use])
#   confmat = table(tmp_test$z_ds_group,pred_labels)
#   acc[iperm] = (confmat[1,1]+confmat[2,2]+confmat[3,3])/length(pred_labels)
#   #============================================================================
# } # for (iperm in 1:nperm)
#
# df2plot = data.frame(Accuracy = acc)
# p = ggplot(data = df2plot, aes(x = Accuracy)) + geom_histogram() + geom_vline(xintercept=true_accuracy)
# p
#
# # compute p-value
# pval = sum(c(true_accuracy,acc)>=true_accuracy)/(nperm+1)
# pval
#================================================================================
#================================================================================




#------------------------------------------------------------------------------
# Plot difference score Z subtypes in Discovery set
maxScores = c(3,4)

# Discovery - make plot with all individuals shown as lines
df2use = Dverbal_Discovery[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(tmp_train$z_ds_group)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$SC = df2use$dbaes_atotal
df2use$RRB = df2use$dbaes_btotal

df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"),
               measure.vars = c("SC","RRB"))

p = ggplot(data = df4plot, aes(x = variable,
                               y = value,
                               colour = subgrp,
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + ylim(0,1) + guides(color=FALSE)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
p3_middle_top = p + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Disc_jitterplot_z%s.pdf",as.character(z_thresh))), plot = p3_middle_top)
p

# Plot difference score Z subtypes in Replication set
maxScores = c(3,4)

# Replication - make plot with all individuals shown as lines
df2use = Dverbal_Replication[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(tmp_test$z_ds_group)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$SC = df2use$dbaes_atotal
df2use$RRB = df2use$dbaes_btotal

df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"),
               measure.vars = c("SC","RRB"))

p = ggplot(data = df4plot, aes(x = variable,
                               y = value,
                               colour = subgrp,
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + ylim(0,1) + guides(color=FALSE)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
p4_middle_bottom = p + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Rep_jitterplot_z%s.pdf",as.character(z_thresh))), plot = p4_middle_bottom)
p

#------------------------------------------------------------------------------
# Apply NDAR subtypes to EU-AIMS LEAP data

# make SC and RRB percentages since EU-AIMS data is specified as percentages
Dverbal = read.csv(file.path(datapath,"tidy_verbal.csv"))
euaims_data = read.csv(file.path(datapath,"tidy_euaims.csv"))
mask1 = euaims_data$Diagnosis=="ASD"
mask2 =  (is.na(euaims_data$A1_pct_severity) | is.na(euaims_data$A2_pct_severity) | is.na(euaims_data$A3_pct_severity) | is.na(euaims_data$B1_pct_severity) | is.na(euaims_data$B2_pct_severity) | is.na(euaims_data$B3_pct_severity) | is.na(euaims_data$B4_pct_severity))
euaims_data = subset(euaims_data, (mask1 & !mask2))

Dverbal[,vars2use[1]] = Dverbal[,vars2use[1]]
Dverbal[,vars2use[2]] = Dverbal[,vars2use[2]]
euaims_data[,vars2use[1]] = (euaims_data$A1_pct_severity +
                               euaims_data$A2_pct_severity +
                               euaims_data$A3_pct_severity)/3
euaims_data[,vars2use[2]] = (euaims_data$B1_pct_severity +
                               euaims_data$B2_pct_severity +
                               euaims_data$B3_pct_severity +
                               euaims_data$B4_pct_severity)/4

train_data = Dverbal
test_data = euaims_data

mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]], na.rm=TRUE)
sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]], na.rm=TRUE)
c(mean2use, sd2use)

tmp_train = make_subtype(data2use = train_data,
                         z_thresh = z_thresh,
                         mean2use = mean2use,
                         sd2use = sd2use)

tmp_test = make_subtype(data2use = test_data,
                        z_thresh = z_thresh,
                        mean2use = mean2use,
                        sd2use = sd2use)




#===========================================================================
#===========================================================================
# # compute model
# mod2use = svm(x = tmp_train[,vars2use], y = tmp_train$z_ds_group)
# pred_labels = predict(mod2use, tmp_test[,vars2use])
# confmat = table(tmp_test$z_ds_group,pred_labels)
# acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/length(pred_labels)
#
# tmp_test$svm_pred_labels = pred_labels
#
# # plot confusion matrix
# setHook("grid.newpage", function() pushViewport(viewport(x=1,y=1,width=0.9, height=0.9, name="vp", just=c("right","top"))), action="prepend")
# pheatmap(confmat/rowSums(confmat)*100, display_numbers = confmat, color = colorRampPalette(c('white','red'))(100), cluster_rows = FALSE, cluster_cols = FALSE, fontsize_number = fontSize, fontsize_row = fontSize, fontsize_col = fontSize,labels_row = c("RRB>SC","SC=RRB","SC>RRB"),labels_col = c("RRB>SC","SC=RRB","SC>RRB"),angle_col=90,
#          breaks= seq(0,100, length=100))
# setHook("grid.newpage", NULL, "replace")
# grid::grid.text("Actual Labels", y=-0.07, gp=gpar(fontsize=fontSize))
# grid::grid.text("Predicted Labels", x=-0.07, rot=90, gp=gpar(fontsize=fontSize))
#===========================================================================
#===========================================================================


# scatterplot
p1 = ggplot(data = tmp_train, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(z_ds_group))) + geom_point() + xlab("Social-Communication") + ylab("Restricted Repetitive Behaviors") + ylim(0,0.8) + xlim(0,0.8) + ggtitle("NDAR ALL")
p1

p2 = ggplot(data = tmp_test, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(z_ds_group))) + geom_point() + xlab("Social-Communication") + ylab("Restricted Repetitive Behaviors") + ylim(0,0.8) + xlim(0,0.8) + ggtitle("EU-AIMS with Groups from NDAR ALL")
p2

#===========================================================================
#===========================================================================
# p3 = ggplot(data = tmp_test, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(pred_labels))) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,0.8) + xlim(0,0.8) + ggtitle("EU-AIMS")
# p5_bottom_right = p3 + guides(colour=FALSE)
# ggsave(filename = file.path(plotpath, sprintf("final_EUAIMS_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p5_bottom_right)
# p3
#===========================================================================
#===========================================================================

# # write out EU-AIMS LEAP data with subgroups defined by NDAR All
write.csv(tmp_test, file.path(datapath, sprintf("tidy_euaims_NDAR_subtypes_diffscore_z%s.csv",as.character(z_thresh))))

#===========================================================================
#===========================================================================
# # Make final plot
# p_final = p1_top_left + p3_middle_top + plot_spacer() + p2_bottom_left + p4_middle_bottom + p5_bottom_right + plot_layout(nrow=3, ncol=3, widths = c(4,4,4), heights = c(8,8,8))
# ggsave(filename = file.path(plotpath, sprintf("final_NDAR_EUAIMS_subtypes_plot_z%s.pdf",as.character(z_thresh))), plot = p_final)
# p_final
#===========================================================================
#===========================================================================

#------------------------------------------------------------------------------
# Integrate subtypes with rest of EU-AIMS LEAP data
euaims_data = read.csv(file.path(datapath,"tidy_euaims.csv"))
td_df = subset(euaims_data, euaims_data$Diagnosis=="TD",select=2:6)
td_df$A_pct_severity = as.numeric(NA)
td_df$B_pct_severity = as.numeric(NA)
td_df$subgrp = "TD"

#===========================================================================
#===========================================================================
# cols2use = c("subid","age","Centre","Schedule","Diagnosis","dbaes_atotal","dbaes_btotal","svm_pred_labels")
cols2use = c("subid","age","Centre","Schedule","Diagnosis","dbaes_atotal","dbaes_btotal","z_ds_group")
#===========================================================================
#===========================================================================
tmp_asd = tmp_test[,cols2use]
colnames(tmp_asd)[6] = "A_pct_severity"
colnames(tmp_asd)[7] = "B_pct_severity"
colnames(tmp_asd)[8] = "subgrp"
asd_df = tmp_asd

all_data = rbind(td_df,asd_df)

fname = "/Users/mlombardo/Dropbox/euaims/data/rsfmri_preproc/euaims_preproc.xlsx"
pp_data = read_excel(fname)
mask = pp_data$notes=="ok"
pp_data = subset(pp_data, mask)

asd_df = merge(pp_data[,c("subid","sex")],asd_df, by = "subid")
td_df = merge(pp_data[,c("subid","sex")],td_df, by = "subid")

all_data = rbind(td_df,asd_df)

data2write = merge(pp_data, all_data, by = "subid")
data2write$age = data2write$age.x
data2write$sex = data2write$sex.y
print(table(data2write$Schedule, data2write$subgrp))
print(table(data2write$Centre, data2write$subgrp))
print(table(data2write$sex, data2write$subgrp))

#DSM-5 - find best split that balances participants across sites
a = findBestSplit(asd_df, seed_range = c(172342)) #,300001:500000))
best_seeds = a$seed[!is.na(a$discrepancy) & a$discrepancy==min(a$discrepancy, na.rm = TRUE)]
print(best_seeds)

# Split datasets -------------------------------------------------------------
rngSeed = best_seeds[1]

# split Schedule A dataset
dset2use = subset(asd_df, asd_df$Schedule=="A")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
A_Discovery = tmp_d[[2]]
A_Replication = tmp_d[[1]]

# split Schedule B dataset
dset2use = subset(asd_df, asd_df$Schedule=="B")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
B_Discovery = tmp_d[[2]]
B_Replication = tmp_d[[1]]

# split Schedule C dataset
dset2use = subset(asd_df, asd_df$Schedule=="C")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
C_Discovery = tmp_d[[2]]
C_Replication = tmp_d[[1]]

# split Schedule D dataset
dset2use = subset(asd_df, asd_df$Schedule=="D")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
D_Discovery = tmp_d[[2]]
D_Replication = tmp_d[[1]]

df_Disc = rbind(A_Discovery, B_Discovery, C_Discovery, D_Discovery)
df_Rep = rbind(A_Replication, B_Replication, C_Replication, D_Replication)

a = table(df_Disc$Schedule, df_Disc$Centre); print(a)
b = table(df_Rep$Schedule, df_Rep$Centre); print(b)
print(a-b)
print(sum(rowSums(abs(a-b))))

data2write$dataset = NA
mask  = is.element(data2write$subid,df_Disc$subid)
data2write[mask,"dataset"] = "Discovery"
mask  = is.element(data2write$subid,df_Rep$subid)
data2write[mask,"dataset"] = "Replication"

asd_Disc = subset(data2write, data2write$dataset=="Discovery" & data2write$Diagnosis=="ASD")
asd_Rep = subset(data2write, data2write$dataset=="Replication" & data2write$Diagnosis=="ASD")

# # find which seed gives best TD age-match -------------------------------------
# seeds = 1:1000
# pvals = data.frame(matrix(nrow = length(seeds), ncol = 2))
# for (i in 1:length(seeds)) {
#   res = findTDAgeMatch(data2write, seed_range = c(seeds[i],seeds[i]))
#   td_Disc_matched = res[[2]]
#   td_Rep_matched = res[[1]]
#   tres = t.test(td_Disc_matched$age, asd_Disc$age)
#   pvals[i,1] = tres$p.value
#   tres = t.test(td_Rep_matched$age, asd_Rep$age)
#   pvals[i,2] = tres$p.value
#   #print(i)
# }
# a = sort.int(pvals[,1], decreasing = TRUE, index.return = TRUE)
# b=pvals[a$ix,]

seed2use = 929
res = findTDAgeMatch(data2write, seed_range = c(seed2use,seed2use))
td_Disc_matched = res[[2]]
td_Rep_matched = res[[1]]

mask = is.element(data2write$subid, td_Disc_matched$subid)
data2write$dataset[mask] = "Discovery"

mask = is.element(data2write$subid, td_Rep_matched$subid)
data2write$dataset[mask] = "Replication"

print(table(data2write$dataset, data2write$subgrp))

fname2save = here(sprintf("asd_subgrp_data_rsfmri_ALL_DSM5_diffzscoreGrps_z%s.csv",as.character(z_thresh)))
write.csv(data2write,file = fname2save)


#------------------------------------------------------------------------------
# Descriptive stats
df2use = data2write[,c("subid","Diagnosis","dataset","Centre","meanFD","age","sex","subgrp","viq_all","piq_all","fsiq4_all","A_pct_severity","B_pct_severity","ADI_social_total","ADI_communication_total","ADI_RRB_total","ados_2_SA_CSS","ados_2_RRB_CSS","SRS_tscore","SRS_tscore_self","RBS_total","SSP_total","vabsdscoresc_dss","vabsdscoresd_dss","vabsdscoress_dss","vabsabcabc_standard")]
mask = df2use==999 | df2use==777
df2use[mask] = NA
df2use$age = df2use$age/365

cols2use = c("dataset","subgrp","age","meanFD","viq_all","piq_all","fsiq4_all","A_pct_severity","B_pct_severity","ADI_social_total","ADI_communication_total","ADI_RRB_total","ados_2_SA_CSS","ados_2_RRB_CSS","SRS_tscore","SRS_tscore_self","RBS_total","SSP_total","vabsdscoresc_dss","vabsdscoresd_dss","vabsdscoress_dss","vabsabcabc_standard")
res=describeBy(x = df2use[,cols2use], group = c("subgrp","dataset"))
res

#------------------------------------------------------------------------------
# Table of subtypes X sex

# Discovery
data2use = subset(data2write,data2write$dataset=="Discovery")
table(data2use$subgrp,data2use$sex)
cs_res = chisq.test(data2use$subgrp,data2use$sex)
cs_res

# Replication
data2use = subset(data2write,data2write$dataset=="Replication")
table(data2use$subgrp,data2use$sex)
cs_res = chisq.test(data2use$subgrp,data2use$sex)
cs_res

#------------------------------------------------------------------------------
vars2analyze = c("age","meanFD","viq_all","piq_all","fsiq4_all",
                 "A_pct_severity","B_pct_severity",
                 "ADI_social_total","ADI_communication_total","ADI_RRB_total",
                 "ados_2_SA_CSS","ados_2_RRB_CSS",
                 "SRS_tscore_self","RBS_total","SSP_total",
                 "vabsdscoress_dss","vabsdscoresd_dss","vabsdscoresc_dss","vabsabcabc_standard")

vnames = c("Age","Mean FD","VIQ","PIQ","FIQ","ADI-R SC","ADI-R RRB","ADI-R Social","ADI-R Communication","ADI-R RRB","ADOS SA CSS","ADOS RRB CSS","SRS","RBS","SSP","Vineland Socialization","Vineland Daily Living Skills","Vineland Communication","Vineland ABC")

cnames = c("All_Disc.fstat","All_Disc.pval","All_Rep.fstat","All_Rep.pval",
           "SCequalRRB_vs_SCoverRRB_Disc.fstat","SCequalRRB_vs_SCoverRRB_Disc.tstat",
           "SCequalRRB_vs_SCoverRRB_Disc.pval","SCequalRRB_vs_SCoverRRB_Disc.es",
           "SCequalRRB_vs_SCoverRRB_Rep.fstat","SCequalRRB_vs_SCoverRRB_Rep.tstat",
           "SCequalRRB_vs_SCoverRRB_Rep.pval","SCequalRRB_vs_SCoverRRB_Rep.es",
           "SCequalRRB_vs_SCoverRRB.repBF")

output_res = data.frame(matrix(nrow = length(vars2analyze),ncol = length(cnames)))
colnames(output_res) = cnames
rownames(output_res) = vars2analyze
output_res$varNames = vars2analyze

for (ivar in 1:length(vars2analyze)){

  y_var = vars2analyze[ivar]
  # print(y_var)
  #----------------------------------------------------------------------------
  # Discovery
  df4mod = subset(df2use, df2use$dataset=="Discovery")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"All_Disc.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"All_Disc.pval"] = res["subgrp","p-value"]

  #----------------------------------------------------------------------------
  # Replication
  df4mod = subset(df2use, df2use$dataset=="Replication")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"All_Rep.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"All_Rep.pval"] = res["subgrp","p-value"]

  #----------------------------------------------------------------------------
  # Discovery
  df4mod = subset(df2use, df2use$dataset=="Discovery" & !is.element(df2use$subgrp,c("TD","RRB_over_SC")))
  n1 = sum(df4mod$subgrp=="SC_equal_RRB")
  m1 = sum(df4mod$subgrp=="SC_over_RRB")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.pval"] = res["subgrp","p-value"]
  res = summary(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.tstat"] = res$tTable[2,"t-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.es"] = cohens_d(df4mod[df4mod$subgrp=="SC_equal_RRB",y_var],
                                                                 df4mod[df4mod$subgrp=="SC_over_RRB",y_var])

  #----------------------------------------------------------------------------
  # Replication
  df4mod = subset(df2use, df2use$dataset=="Replication" & !is.element(df2use$subgrp,c("TD","RRB_over_SC")))
  n2 = sum(df4mod$subgrp=="SC_equal_RRB")
  m2 = sum(df4mod$subgrp=="SC_over_RRB")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.pval"] = res["subgrp","p-value"]
  res = summary(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.tstat"] = res$tTable[2,"t-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.es"] = cohens_d(df4mod[df4mod$subgrp=="SC_equal_RRB",y_var],
                                                                 df4mod[df4mod$subgrp=="SC_over_RRB",y_var])

  #----------------------------------------------------------------------------
  # Replication Bayes Factor
  res_bf = BFSALL(tobs = output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.tstat"],
                  trep = output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.tstat"],
                  n1 = n1,
                  n2 = n2,
                  m1 = m1,
                  m2 = m2,
                  sample = 2,
                  Type = 'ALL')
  output_res[y_var,"SCequalRRB_vs_SCoverRRB.repBF"] = res_bf["Replication BF","Replication 1"]

  # make a plot
  colors2use = get_ggColorHue(3)
  df4plot = subset(df2use, df2use$subgrp!="RRB_over_SC")
  p = ggplot(data = df4plot, aes_string(x = "subgrp", y = y_var, colour = "subgrp")) + facet_grid(. ~ dataset)
  p = p + geom_jitter() + geom_boxplot(fill = NA, colour = "#000000", outlier.shape = NA)
  p = p + ylab(vnames[ivar]) + xlab("Group") +
    scale_x_discrete(labels=c("SC_equal_RRB"="SC=RRB","SC_over_RRB"="SC>RRB","TD"="TD")) +
                       scale_colour_manual(values = c(colors2use[2:3],"grey60")) + guides(colour=FALSE) +
    theme(text = element_text(size=fontSize-5),
        axis.text.x = element_text(size=fontSize-5),
        axis.text.y = element_text(size=fontSize-5))
  print(p)

}
vabc = data.frame(matrix(nrow=6,ncol=2))
colnames(vabc) = c("Discovery","Replication")
rownames(vabc) = c("0.5","0.6","0.7","0.8","0.9","1")
vabc["0.5","Discovery"] = output_res["vabsabcabc_standard","SCequalRRB_vs_SCoverRRB_Disc.es"]
vabc["0.5","Replication"] = output_res["vabsabcabc_standard","SCequalRRB_vs_SCoverRRB_Rep.es"]

vabc_dls = data.frame(matrix(nrow=6,ncol=2))
colnames(vabc_dls) = c("Discovery","Replication")
rownames(vabc_dls) = c("0.5","0.6","0.7","0.8","0.9","1")
vabc_dls["0.5","Discovery"] = output_res["vabsdscoresd_dss","SCequalRRB_vs_SCoverRRB_Disc.es"]
vabc_dls["0.5","Replication"] = output_res["vabsdscoresd_dss","SCequalRRB_vs_SCoverRRB_Rep.es"]
output_res
```

## SC-RRB difference z = 0.6

```{r, warning=FALSE, message=FALSE}
#------------------------------------------------------------------------------
# Z-score threshold to use for subtyping
z_thresh = 0.6

# vars2use = c("dbaes_atotal","dbaes_btotal")

# compute Discovery mean and sd
ds_disc = Dverbal_Discovery[,vars2use[1]] - Dverbal_Discovery[,vars2use[2]]
mean2use = mean(ds_disc)
sd2use = sd(ds_disc)

Dverbal_Discovery = make_subtype(data2use = Dverbal_Discovery,
                                 z_thresh = z_thresh,
                                 mean2use = mean2use,
                                 sd2use = sd2use)

# compute Replication mean and sd
ds_rep = Dverbal_Replication[,vars2use[1]] - Dverbal_Replication[,vars2use[2]]
mean2use = mean(ds_rep)
sd2use = sd(ds_rep)

Dverbal_Replication = make_subtype(data2use = Dverbal_Replication,
                                 z_thresh = z_thresh,
                                 mean2use = mean2use,
                                 sd2use = sd2use)

#------------------------------------------------------------------------------
# Table of subtypes X sex

# Discovery
table(Dverbal_Discovery$z_ds_group,Dverbal_Discovery$sex)
cs_res = chisq.test(Dverbal_Discovery$z_ds_group,Dverbal_Discovery$sex)
cs_res

# Replication
table(Dverbal_Replication$z_ds_group,Dverbal_Replication$sex)
cs_res = chisq.test(Dverbal_Replication$z_ds_group,Dverbal_Replication$sex)
cs_res

#------------------------------------------------------------------------------
# Descriptive stats

# Discovery
df2use = Dverbal_Discovery[,c("subjectkey","dataset_id","collection_id","interview_age","sex","z_ds_group","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")]
df2use$age = df2use$interview_age/12

cols2use = c("z_ds_group","sex","age","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")
res=describeBy(x = df2use[,cols2use], group = "z_ds_group")
res

# Replication
df2use = Dverbal_Replication[,c("subjectkey","dataset_id","collection_id","interview_age","sex","z_ds_group","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")]
df2use$age = df2use$interview_age/12

cols2use = c("z_ds_group","sex","age","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")
res=describeBy(x = df2use[,cols2use], group = "z_ds_group")
res

#------------------------------------------------------------------------------
# Tests of differences in interview age across the subtypes

# Discovery
mod2use = lm(formula = interview_age ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = interview_age ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in SC across the subtypes

# Discovery
mod2use = lm(formula = dbaes_atotal ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = dbaes_atotal ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in RRB across the subtypes

# Discovery
mod2use = lm(formula = dbaes_btotal ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = dbaes_btotal ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in ADOS SA CSS across the subtypes

# Discovery
mod2use = lm(formula = ados_sa_css ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = ados_sa_css ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in ADOS RRB CSS across the subtypes

# Discovery
mod2use = lm(formula = ados_rrb_css ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = ados_rrb_css ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)


#------------------------------------------------------------------------------
# Tests of differences in IQ across the subtypes

# Discovery
mod2use = lm(formula = iq ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = iq ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)


#------------------------------------------------------------------------------
# Make scatterplots with difference score Z subtypes in different colors
maxScores = c(3,4)

p_disc = ggplot(data = Dverbal_Discovery, aes(x = dbaes_atotal, y = dbaes_btotal, colour = z_ds_group)) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,1) + xlim(0,1) + ggtitle("NDAR Discovery")
p1_top_left = p_disc + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Disc_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p1_top_left)
p_disc
table(Dverbal_Discovery$z_ds_group)

cor_res = cor.test(Dverbal_Discovery$dbaes_atotal, Dverbal_Discovery$dbaes_btotal)
cor_res

p_rep = ggplot(data = Dverbal_Replication, aes(x = dbaes_atotal, y = dbaes_btotal, colour = z_ds_group)) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,1) + xlim(0,1) +  ggtitle("NDAR Replication")
p2_bottom_left = p_rep + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Rep_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p2_bottom_left)
p_rep
table(Dverbal_Replication$z_ds_group)

cor_res = cor.test(Dverbal_Replication$dbaes_atotal, Dverbal_Replication$dbaes_btotal)
cor_res

#------------------------------------------------------------------------------
# Run supervised model with Discovery as training and Replication as Test

# run validation
# make subtypes using z-scores computed from the mean and sd of the training set
train_data = Dverbal_Discovery
test_data = Dverbal_Replication

mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]])
sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]])
tmp_train = make_subtype(data2use = train_data,
                         z_thresh = z_thresh,
                         mean2use = mean2use,
                         sd2use = sd2use)

mean2use = mean(test_data[,vars2use[1]] - test_data[,vars2use[2]])
sd2use = sd(test_data[,vars2use[1]] - test_data[,vars2use[2]])
tmp_test = make_subtype(data2use = test_data,
                        z_thresh = z_thresh,
                        mean2use = mean2use,
                        sd2use = sd2use)

#==============================================================================
#==============================================================================
# make labels based on train mean and sd
mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]])
sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]])
train_mean = mean2use
train_sd = sd2use

pred_labels = make_subtype(data2use = test_data,
                        z_thresh = z_thresh,
                        mean2use = train_mean,
                        sd2use = train_sd)
confmat = table(tmp_test$z_ds_group,pred_labels$z_ds_group)
acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/dim(pred_labels)[1]

# # compute model
# mod2use = svm(x = tmp_train[,vars2use], y = tmp_train$z_ds_group)
# pred_labels = predict(mod2use, tmp_test[,vars2use])
# confmat = table(tmp_test$z_ds_group,pred_labels)
# acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/length(pred_labels)
#==============================================================================
#==============================================================================

# plot confusion matrix
setHook("grid.newpage", function() pushViewport(viewport(x=1,y=1,width=0.9, height=0.9, name="vp", just=c("right","top"))), action="prepend")
pheatmap(confmat/rowSums(confmat)*100, display_numbers = confmat, color = colorRampPalette(c('white','red'))(100), cluster_rows = FALSE, cluster_cols = FALSE, fontsize_number = fontSize, fontsize_row = fontSize, fontsize_col = fontSize,labels_row = c("RRB>SC","SC=RRB","SC>RRB"),labels_col = c("RRB>SC","SC=RRB","SC>RRB"),angle_col=90,
         breaks= seq(0,100, length=100))
setHook("grid.newpage", NULL, "replace")
grid::grid.text("Actual Labels", y=-0.07, gp=gpar(fontsize=fontSize))
grid::grid.text("Predicted Labels", x=-0.07, rot=90, gp=gpar(fontsize=fontSize))


# show accuracy
true_accuracy = acc
true_accuracy

#================================================================================
#================================================================================
# #------------------------------------------------------------------------------
# # Permute subtype labels to examine how well supervised model performs
#
# # nperm = 10000
#
# # make subtypes using z-scores computed from the mean and sd of the training set
# train_data = Dverbal_Discovery
# test_data = Dverbal_Replication
# mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]])
# sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]])
# tmp_train = make_subtype(data2use = train_data,
#                          z_thresh = z_thresh,
#                          mean2use = mean2use,
#                          sd2use = sd2use)
#
# mean2use = mean(test_data[,vars2use[1]] - test_data[,vars2use[2]])
# sd2use = sd(test_data[,vars2use[1]] - test_data[,vars2use[2]])
# tmp_test = make_subtype(data2use = test_data,
#                         z_thresh = z_thresh,
#                         mean2use = mean2use,
#                         sd2use = sd2use)
#
# acc = vector(length = nperm)
# for (iperm in 1:nperm){
#   # set seed for reproducibility
#   set.seed(iperm)
#
#   sc_perm = sample(train_data[,vars2use[1]])
#   rrb_perm = sample(train_data[,vars2use[2]])
#   perm_mean2use = mean(sc_perm - rrb_perm)
#   perm_sd2use = sd(sc_perm - rrb_perm)
#   # perm_mean2use = mean(train_data[,vars2use[1]] - rrb_perm)
#   # perm_sd2use = sd(train_data[,vars2use[1]] - rrb_perm)
#   pred_labels = make_subtype(data2use = tmp_test,
#                         z_thresh = z_thresh,
#                         mean2use = perm_mean2use,
#                         sd2use = perm_sd2use)
#   confmat = table(tmp_test$z_ds_group,pred_labels$z_ds_group)
#   acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/dim(pred_labels)[1]
#
#   # compute model
#   permuted_labels = sample(tmp_train$z_ds_group)
#   mod2use = svm(x = tmp_train[,vars2use], y = permuted_labels)
#   pred_labels = predict(mod2use, tmp_test[,vars2use])
#   confmat = table(tmp_test$z_ds_group,pred_labels)
#   acc[iperm] = (confmat[1,1]+confmat[2,2]+confmat[3,3])/length(pred_labels)
#   #============================================================================
# } # for (iperm in 1:nperm)
#
# df2plot = data.frame(Accuracy = acc)
# p = ggplot(data = df2plot, aes(x = Accuracy)) + geom_histogram() + geom_vline(xintercept=true_accuracy)
# p
#
# # compute p-value
# pval = sum(c(true_accuracy,acc)>=true_accuracy)/(nperm+1)
# pval
#================================================================================
#================================================================================

#------------------------------------------------------------------------------
# Plot difference score Z subtypes in Discovery set
maxScores = c(3,4)

# Discovery - make plot with all individuals shown as lines
df2use = Dverbal_Discovery[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(tmp_train$z_ds_group)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$SC = df2use$dbaes_atotal
df2use$RRB = df2use$dbaes_btotal

df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"),
               measure.vars = c("SC","RRB"))

p = ggplot(data = df4plot, aes(x = variable,
                               y = value,
                               colour = subgrp,
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + ylim(0,1) + guides(color=FALSE)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
p3_middle_top = p + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Disc_jitterplot_z%s.pdf",as.character(z_thresh))), plot = p3_middle_top)
p

# Plot difference score Z subtypes in Replication set
maxScores = c(3,4)

# Replication - make plot with all individuals shown as lines
df2use = Dverbal_Replication[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(tmp_test$z_ds_group)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$SC = df2use$dbaes_atotal
df2use$RRB = df2use$dbaes_btotal

df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"),
               measure.vars = c("SC","RRB"))

p = ggplot(data = df4plot, aes(x = variable,
                               y = value,
                               colour = subgrp,
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + ylim(0,1) + guides(color=FALSE)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
p4_middle_bottom = p + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Rep_jitterplot_z%s.pdf",as.character(z_thresh))), plot = p4_middle_bottom)
p

#------------------------------------------------------------------------------
# Apply NDAR subtypes to EU-AIMS LEAP data

# make SC and RRB percentages since EU-AIMS data is specified as percentages
Dverbal = read.csv(file.path(datapath,"tidy_verbal.csv"))
euaims_data = read.csv(file.path(datapath,"tidy_euaims.csv"))
mask1 = euaims_data$Diagnosis=="ASD"
mask2 =  (is.na(euaims_data$A1_pct_severity) | is.na(euaims_data$A2_pct_severity) | is.na(euaims_data$A3_pct_severity) | is.na(euaims_data$B1_pct_severity) | is.na(euaims_data$B2_pct_severity) | is.na(euaims_data$B3_pct_severity) | is.na(euaims_data$B4_pct_severity))
euaims_data = subset(euaims_data, (mask1 & !mask2))

Dverbal[,vars2use[1]] = Dverbal[,vars2use[1]]
Dverbal[,vars2use[2]] = Dverbal[,vars2use[2]]
euaims_data[,vars2use[1]] = (euaims_data$A1_pct_severity +
                               euaims_data$A2_pct_severity +
                               euaims_data$A3_pct_severity)/3
euaims_data[,vars2use[2]] = (euaims_data$B1_pct_severity +
                               euaims_data$B2_pct_severity +
                               euaims_data$B3_pct_severity +
                               euaims_data$B4_pct_severity)/4

train_data = Dverbal
test_data = euaims_data

mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]], na.rm=TRUE)
sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]], na.rm=TRUE)
c(mean2use, sd2use)

tmp_train = make_subtype(data2use = train_data,
                         z_thresh = z_thresh,
                         mean2use = mean2use,
                         sd2use = sd2use)

tmp_test = make_subtype(data2use = test_data,
                        z_thresh = z_thresh,
                        mean2use = mean2use,
                        sd2use = sd2use)

#===========================================================================
#===========================================================================
# # compute model
# mod2use = svm(x = tmp_train[,vars2use], y = tmp_train$z_ds_group)
# pred_labels = predict(mod2use, tmp_test[,vars2use])
# confmat = table(tmp_test$z_ds_group,pred_labels)
# acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/length(pred_labels)
#
# tmp_test$svm_pred_labels = pred_labels
#
# # plot confusion matrix
# setHook("grid.newpage", function() pushViewport(viewport(x=1,y=1,width=0.9, height=0.9, name="vp", just=c("right","top"))), action="prepend")
# pheatmap(confmat/rowSums(confmat)*100, display_numbers = confmat, color = colorRampPalette(c('white','red'))(100), cluster_rows = FALSE, cluster_cols = FALSE, fontsize_number = fontSize, fontsize_row = fontSize, fontsize_col = fontSize,labels_row = c("RRB>SC","SC=RRB","SC>RRB"),labels_col = c("RRB>SC","SC=RRB","SC>RRB"),angle_col=90,
#          breaks= seq(0,100, length=100))
# setHook("grid.newpage", NULL, "replace")
# grid::grid.text("Actual Labels", y=-0.07, gp=gpar(fontsize=fontSize))
# grid::grid.text("Predicted Labels", x=-0.07, rot=90, gp=gpar(fontsize=fontSize))
#===========================================================================
#===========================================================================

# scatterplot
p1 = ggplot(data = tmp_train, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(z_ds_group))) + geom_point() + xlab("Social-Communication") + ylab("Restricted Repetitive Behaviors") + ylim(0,0.8) + xlim(0,0.8) + ggtitle("NDAR ALL")
p1

p2 = ggplot(data = tmp_test, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(z_ds_group))) + geom_point() + xlab("Social-Communication") + ylab("Restricted Repetitive Behaviors") + ylim(0,0.8) + xlim(0,0.8) + ggtitle("EU-AIMS with Groups from NDAR ALL")
p2

#===========================================================================
#===========================================================================
# p3 = ggplot(data = tmp_test, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(pred_labels))) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,0.8) + xlim(0,0.8) + ggtitle("EU-AIMS")
# p5_bottom_right = p3 + guides(colour=FALSE)
# ggsave(filename = file.path(plotpath, sprintf("final_EUAIMS_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p5_bottom_right)
# p3
#===========================================================================
#===========================================================================

# # write out EU-AIMS LEAP data with subgroups defined by NDAR All
write.csv(tmp_test, file.path(datapath, sprintf("tidy_euaims_NDAR_subtypes_diffscore_z%s.csv",as.character(z_thresh))))

#===========================================================================
#===========================================================================
# # Make final plot
# p_final = p1_top_left + p3_middle_top + plot_spacer() + p2_bottom_left + p4_middle_bottom + p5_bottom_right + plot_layout(nrow=3, ncol=3, widths = c(4,4,4), heights = c(8,8,8))
# ggsave(filename = file.path(plotpath, sprintf("final_NDAR_EUAIMS_subtypes_plot_z%s.pdf",as.character(z_thresh))), plot = p_final)
# p_final
#===========================================================================
#===========================================================================

#------------------------------------------------------------------------------
# Integrate subtypes with rest of EU-AIMS LEAP data
euaims_data = read.csv(file.path(datapath,"tidy_euaims.csv"))
td_df = subset(euaims_data, euaims_data$Diagnosis=="TD",select=2:6)
td_df$A_pct_severity = as.numeric(NA)
td_df$B_pct_severity = as.numeric(NA)
td_df$subgrp = "TD"

#===========================================================================
#===========================================================================
# cols2use = c("subid","age","Centre","Schedule","Diagnosis","dbaes_atotal","dbaes_btotal","svm_pred_labels")
cols2use = c("subid","age","Centre","Schedule","Diagnosis","dbaes_atotal","dbaes_btotal","z_ds_group")
#===========================================================================
#===========================================================================
tmp_asd = tmp_test[,cols2use]
colnames(tmp_asd)[6] = "A_pct_severity"
colnames(tmp_asd)[7] = "B_pct_severity"
colnames(tmp_asd)[8] = "subgrp"
asd_df = tmp_asd

all_data = rbind(td_df,asd_df)

fname = "/Users/mlombardo/Dropbox/euaims/data/rsfmri_preproc/euaims_preproc.xlsx"
pp_data = read_excel(fname)
mask = pp_data$notes=="ok"
pp_data = subset(pp_data, mask)

asd_df = merge(pp_data[,c("subid","sex")],asd_df, by = "subid")
td_df = merge(pp_data[,c("subid","sex")],td_df, by = "subid")

all_data = rbind(td_df,asd_df)

data2write = merge(pp_data, all_data, by = "subid")
data2write$age = data2write$age.x
data2write$sex = data2write$sex.y
print(table(data2write$Schedule, data2write$subgrp))
print(table(data2write$Centre, data2write$subgrp))
print(table(data2write$sex, data2write$subgrp))

#DSM-5 - find best split that balances participants across sites
a = findBestSplit(asd_df, seed_range = c(172342)) #,300001:500000))
best_seeds = a$seed[!is.na(a$discrepancy) & a$discrepancy==min(a$discrepancy, na.rm = TRUE)]
print(best_seeds)

# Split datasets -------------------------------------------------------------
rngSeed = best_seeds[1]

# split Schedule A dataset
dset2use = subset(asd_df, asd_df$Schedule=="A")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
A_Discovery = tmp_d[[2]]
A_Replication = tmp_d[[1]]

# split Schedule B dataset
dset2use = subset(asd_df, asd_df$Schedule=="B")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
B_Discovery = tmp_d[[2]]
B_Replication = tmp_d[[1]]

# split Schedule C dataset
dset2use = subset(asd_df, asd_df$Schedule=="C")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
C_Discovery = tmp_d[[2]]
C_Replication = tmp_d[[1]]

# split Schedule D dataset
dset2use = subset(asd_df, asd_df$Schedule=="D")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
D_Discovery = tmp_d[[2]]
D_Replication = tmp_d[[1]]

df_Disc = rbind(A_Discovery, B_Discovery, C_Discovery, D_Discovery)
df_Rep = rbind(A_Replication, B_Replication, C_Replication, D_Replication)

a = table(df_Disc$Schedule, df_Disc$Centre); print(a)
b = table(df_Rep$Schedule, df_Rep$Centre); print(b)
print(a-b)
print(sum(rowSums(abs(a-b))))

data2write$dataset = NA
mask  = is.element(data2write$subid,df_Disc$subid)
data2write[mask,"dataset"] = "Discovery"
mask  = is.element(data2write$subid,df_Rep$subid)
data2write[mask,"dataset"] = "Replication"

asd_Disc = subset(data2write, data2write$dataset=="Discovery" & data2write$Diagnosis=="ASD")
asd_Rep = subset(data2write, data2write$dataset=="Replication" & data2write$Diagnosis=="ASD")

# # find which seed gives best TD age-match -------------------------------------
# seeds = 1:1000
# pvals = data.frame(matrix(nrow = length(seeds), ncol = 2))
# for (i in 1:length(seeds)) {
#   res = findTDAgeMatch(data2write, seed_range = c(seeds[i],seeds[i]))
#   td_Disc_matched = res[[2]]
#   td_Rep_matched = res[[1]]
#   tres = t.test(td_Disc_matched$age, asd_Disc$age)
#   pvals[i,1] = tres$p.value
#   tres = t.test(td_Rep_matched$age, asd_Rep$age)
#   pvals[i,2] = tres$p.value
#   #print(i)
# }
# a = sort.int(pvals[,1], decreasing = TRUE, index.return = TRUE)
# b=pvals[a$ix,]

seed2use = 929
res = findTDAgeMatch(data2write, seed_range = c(seed2use,seed2use))
td_Disc_matched = res[[2]]
td_Rep_matched = res[[1]]

mask = is.element(data2write$subid, td_Disc_matched$subid)
data2write$dataset[mask] = "Discovery"

mask = is.element(data2write$subid, td_Rep_matched$subid)
data2write$dataset[mask] = "Replication"

print(table(data2write$dataset, data2write$subgrp))

fname2save = here(sprintf("asd_subgrp_data_rsfmri_ALL_DSM5_diffzscoreGrps_z%s.csv",as.character(z_thresh)))
write.csv(data2write,file = fname2save)


#------------------------------------------------------------------------------
# Descriptive stats
df2use = data2write[,c("subid","Diagnosis","dataset","Centre","meanFD","age","sex","subgrp","viq_all","piq_all","fsiq4_all","A_pct_severity","B_pct_severity","ADI_social_total","ADI_communication_total","ADI_RRB_total","ados_2_SA_CSS","ados_2_RRB_CSS","SRS_tscore","SRS_tscore_self","RBS_total","SSP_total","vabsdscoresc_dss","vabsdscoresd_dss","vabsdscoress_dss","vabsabcabc_standard")]
mask = df2use==999 | df2use==777
df2use[mask] = NA
df2use$age = df2use$age/365

cols2use = c("dataset","subgrp","age","meanFD","viq_all","piq_all","fsiq4_all","A_pct_severity","B_pct_severity","ADI_social_total","ADI_communication_total","ADI_RRB_total","ados_2_SA_CSS","ados_2_RRB_CSS","SRS_tscore","SRS_tscore_self","RBS_total","SSP_total","vabsdscoresc_dss","vabsdscoresd_dss","vabsdscoress_dss","vabsabcabc_standard")
res=describeBy(x = df2use[,cols2use], group = c("subgrp","dataset"))
res

#------------------------------------------------------------------------------
# Table of subtypes X sex

# Discovery
data2use = subset(data2write,data2write$dataset=="Discovery")
table(data2use$subgrp,data2use$sex)
cs_res = chisq.test(data2use$subgrp,data2use$sex)
cs_res

# Replication
data2use = subset(data2write,data2write$dataset=="Replication")
table(data2use$subgrp,data2use$sex)
cs_res = chisq.test(data2use$subgrp,data2use$sex)
cs_res

#------------------------------------------------------------------------------
vars2analyze = c("age","meanFD","viq_all","piq_all","fsiq4_all",
                 "A_pct_severity","B_pct_severity",
                 "ADI_social_total","ADI_communication_total","ADI_RRB_total",
                 "ados_2_SA_CSS","ados_2_RRB_CSS",
                 "SRS_tscore_self","RBS_total","SSP_total",
                 "vabsdscoress_dss","vabsdscoresd_dss","vabsdscoresc_dss","vabsabcabc_standard")

vnames = c("Age","Mean FD","VIQ","PIQ","FIQ","ADI-R SC","ADI-R RRB","ADI-R Social","ADI-R Communication","ADI-R RRB","ADOS SA CSS","ADOS RRB CSS","SRS","RBS","SSP","Vineland Socialization","Vineland Daily Living Skills","Vineland Communication","Vineland ABC")

cnames = c("All_Disc.fstat","All_Disc.pval","All_Rep.fstat","All_Rep.pval",
           "SCequalRRB_vs_SCoverRRB_Disc.fstat","SCequalRRB_vs_SCoverRRB_Disc.tstat",
           "SCequalRRB_vs_SCoverRRB_Disc.pval","SCequalRRB_vs_SCoverRRB_Disc.es",
           "SCequalRRB_vs_SCoverRRB_Rep.fstat","SCequalRRB_vs_SCoverRRB_Rep.tstat",
           "SCequalRRB_vs_SCoverRRB_Rep.pval","SCequalRRB_vs_SCoverRRB_Rep.es",
           "SCequalRRB_vs_SCoverRRB.repBF")

output_res = data.frame(matrix(nrow = length(vars2analyze),ncol = length(cnames)))
colnames(output_res) = cnames
rownames(output_res) = vars2analyze
output_res$varNames = vars2analyze

for (ivar in 1:length(vars2analyze)){

  y_var = vars2analyze[ivar]
  # print(y_var)
  #----------------------------------------------------------------------------
  # Discovery
  df4mod = subset(df2use, df2use$dataset=="Discovery")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"All_Disc.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"All_Disc.pval"] = res["subgrp","p-value"]

  #----------------------------------------------------------------------------
  # Replication
  df4mod = subset(df2use, df2use$dataset=="Replication")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"All_Rep.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"All_Rep.pval"] = res["subgrp","p-value"]

  #----------------------------------------------------------------------------
  # Discovery
  df4mod = subset(df2use, df2use$dataset=="Discovery" & !is.element(df2use$subgrp,c("TD","RRB_over_SC")))
  n1 = sum(df4mod$subgrp=="SC_equal_RRB")
  m1 = sum(df4mod$subgrp=="SC_over_RRB")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.pval"] = res["subgrp","p-value"]
  res = summary(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.tstat"] = res$tTable[2,"t-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.es"] = cohens_d(df4mod[df4mod$subgrp=="SC_equal_RRB",y_var],
                                                                 df4mod[df4mod$subgrp=="SC_over_RRB",y_var])

  #----------------------------------------------------------------------------
  # Replication
  df4mod = subset(df2use, df2use$dataset=="Replication" & !is.element(df2use$subgrp,c("TD","RRB_over_SC")))
  n2 = sum(df4mod$subgrp=="SC_equal_RRB")
  m2 = sum(df4mod$subgrp=="SC_over_RRB")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.pval"] = res["subgrp","p-value"]
  res = summary(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.tstat"] = res$tTable[2,"t-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.es"] = cohens_d(df4mod[df4mod$subgrp=="SC_equal_RRB",y_var],
                                                                 df4mod[df4mod$subgrp=="SC_over_RRB",y_var])

  #----------------------------------------------------------------------------
  # Replication Bayes Factor
  res_bf = BFSALL(tobs = output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.tstat"],
                  trep = output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.tstat"],
                  n1 = n1,
                  n2 = n2,
                  m1 = m1,
                  m2 = m2,
                  sample = 2,
                  Type = 'ALL')
  output_res[y_var,"SCequalRRB_vs_SCoverRRB.repBF"] = res_bf["Replication BF","Replication 1"]

  # make a plot
  colors2use = get_ggColorHue(3)
  df4plot = subset(df2use, df2use$subgrp!="RRB_over_SC")
  p = ggplot(data = df4plot, aes_string(x = "subgrp", y = y_var, colour = "subgrp")) + facet_grid(. ~ dataset)
  p = p + geom_jitter() + geom_boxplot(fill = NA, colour = "#000000", outlier.shape = NA)
  p = p + ylab(vnames[ivar]) + xlab("Group") +
    scale_x_discrete(labels=c("SC_equal_RRB"="SC=RRB","SC_over_RRB"="SC>RRB","TD"="TD")) +
                       scale_colour_manual(values = c(colors2use[2:3],"grey60")) + guides(colour=FALSE) +
    theme(text = element_text(size=fontSize-5),
        axis.text.x = element_text(size=fontSize-5),
        axis.text.y = element_text(size=fontSize-5))
  print(p)

}
vabc["0.6","Discovery"] = output_res["vabsabcabc_standard","SCequalRRB_vs_SCoverRRB_Disc.es"]
vabc["0.6","Replication"] = output_res["vabsabcabc_standard","SCequalRRB_vs_SCoverRRB_Rep.es"]
vabc_dls["0.6","Discovery"] = output_res["vabsdscoresd_dss","SCequalRRB_vs_SCoverRRB_Disc.es"]
vabc_dls["0.6","Replication"] = output_res["vabsdscoresd_dss","SCequalRRB_vs_SCoverRRB_Rep.es"]
output_res
```

## SC-RRB difference z = 0.7

```{r, warning=FALSE, message=FALSE}
#------------------------------------------------------------------------------
# Z-score threshold to use for subtyping
z_thresh = 0.7

# vars2use = c("dbaes_atotal","dbaes_btotal")

# compute Discovery mean and sd
ds_disc = Dverbal_Discovery[,vars2use[1]] - Dverbal_Discovery[,vars2use[2]]
mean2use = mean(ds_disc)
sd2use = sd(ds_disc)

Dverbal_Discovery = make_subtype(data2use = Dverbal_Discovery,
                                 z_thresh = z_thresh,
                                 mean2use = mean2use,
                                 sd2use = sd2use)

# compute Replication mean and sd
ds_rep = Dverbal_Replication[,vars2use[1]] - Dverbal_Replication[,vars2use[2]]
mean2use = mean(ds_rep)
sd2use = sd(ds_rep)

Dverbal_Replication = make_subtype(data2use = Dverbal_Replication,
                                 z_thresh = z_thresh,
                                 mean2use = mean2use,
                                 sd2use = sd2use)

#------------------------------------------------------------------------------
# Table of subtypes X sex

# Discovery
table(Dverbal_Discovery$z_ds_group,Dverbal_Discovery$sex)
cs_res = chisq.test(Dverbal_Discovery$z_ds_group,Dverbal_Discovery$sex)
cs_res

# Replication
table(Dverbal_Replication$z_ds_group,Dverbal_Replication$sex)
cs_res = chisq.test(Dverbal_Replication$z_ds_group,Dverbal_Replication$sex)
cs_res

#------------------------------------------------------------------------------
# Descriptive stats

# Discovery
df2use = Dverbal_Discovery[,c("subjectkey","dataset_id","collection_id","interview_age","sex","z_ds_group","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")]
df2use$age = df2use$interview_age/12

cols2use = c("z_ds_group","sex","age","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")
res=describeBy(x = df2use[,cols2use], group = "z_ds_group")
res

# Replication
df2use = Dverbal_Replication[,c("subjectkey","dataset_id","collection_id","interview_age","sex","z_ds_group","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")]
df2use$age = df2use$interview_age/12

cols2use = c("z_ds_group","sex","age","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")
res=describeBy(x = df2use[,cols2use], group = "z_ds_group")
res

#------------------------------------------------------------------------------
# Tests of differences in interview age across the subtypes

# Discovery
mod2use = lm(formula = interview_age ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = interview_age ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in SC across the subtypes

# Discovery
mod2use = lm(formula = dbaes_atotal ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = dbaes_atotal ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in RRB across the subtypes

# Discovery
mod2use = lm(formula = dbaes_btotal ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = dbaes_btotal ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in ADOS SA CSS across the subtypes

# Discovery
mod2use = lm(formula = ados_sa_css ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = ados_sa_css ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in ADOS RRB CSS across the subtypes

# Discovery
mod2use = lm(formula = ados_rrb_css ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = ados_rrb_css ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)


#------------------------------------------------------------------------------
# Tests of differences in IQ across the subtypes

# Discovery
mod2use = lm(formula = iq ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = iq ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)


#------------------------------------------------------------------------------
# Make scatterplots with difference score Z subtypes in different colors
maxScores = c(3,4)

p_disc = ggplot(data = Dverbal_Discovery, aes(x = dbaes_atotal, y = dbaes_btotal, colour = z_ds_group)) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,1) + xlim(0,1) + ggtitle("NDAR Discovery")
p1_top_left = p_disc + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Disc_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p1_top_left)
p_disc
table(Dverbal_Discovery$z_ds_group)

cor_res = cor.test(Dverbal_Discovery$dbaes_atotal, Dverbal_Discovery$dbaes_btotal)
cor_res

p_rep = ggplot(data = Dverbal_Replication, aes(x = dbaes_atotal, y = dbaes_btotal, colour = z_ds_group)) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,1) + xlim(0,1) +  ggtitle("NDAR Replication")
p2_bottom_left = p_rep + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Rep_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p2_bottom_left)
p_rep
table(Dverbal_Replication$z_ds_group)

cor_res = cor.test(Dverbal_Replication$dbaes_atotal, Dverbal_Replication$dbaes_btotal)
cor_res

#------------------------------------------------------------------------------
# Run supervised model with Discovery as training and Replication as Test

# run validation
# make subtypes using z-scores computed from the mean and sd of the training set
train_data = Dverbal_Discovery
test_data = Dverbal_Replication

mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]])
sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]])
tmp_train = make_subtype(data2use = train_data,
                         z_thresh = z_thresh,
                         mean2use = mean2use,
                         sd2use = sd2use)

mean2use = mean(test_data[,vars2use[1]] - test_data[,vars2use[2]])
sd2use = sd(test_data[,vars2use[1]] - test_data[,vars2use[2]])
tmp_test = make_subtype(data2use = test_data,
                        z_thresh = z_thresh,
                        mean2use = mean2use,
                        sd2use = sd2use)

#==============================================================================
#==============================================================================
# make labels based on train mean and sd
mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]])
sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]])
train_mean = mean2use
train_sd = sd2use

pred_labels = make_subtype(data2use = test_data,
                        z_thresh = z_thresh,
                        mean2use = train_mean,
                        sd2use = train_sd)
confmat = table(tmp_test$z_ds_group,pred_labels$z_ds_group)
acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/dim(pred_labels)[1]

# # compute model
# mod2use = svm(x = tmp_train[,vars2use], y = tmp_train$z_ds_group)
# pred_labels = predict(mod2use, tmp_test[,vars2use])
# confmat = table(tmp_test$z_ds_group,pred_labels)
# acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/length(pred_labels)
#==============================================================================
#==============================================================================

# plot confusion matrix
setHook("grid.newpage", function() pushViewport(viewport(x=1,y=1,width=0.9, height=0.9, name="vp", just=c("right","top"))), action="prepend")
pheatmap(confmat/rowSums(confmat)*100, display_numbers = confmat, color = colorRampPalette(c('white','red'))(100), cluster_rows = FALSE, cluster_cols = FALSE, fontsize_number = fontSize, fontsize_row = fontSize, fontsize_col = fontSize,labels_row = c("RRB>SC","SC=RRB","SC>RRB"),labels_col = c("RRB>SC","SC=RRB","SC>RRB"),angle_col=90,
         breaks= seq(0,100, length=100))
setHook("grid.newpage", NULL, "replace")
grid::grid.text("Actual Labels", y=-0.07, gp=gpar(fontsize=fontSize))
grid::grid.text("Predicted Labels", x=-0.07, rot=90, gp=gpar(fontsize=fontSize))


# show accuracy
true_accuracy = acc
true_accuracy

#================================================================================
#================================================================================
# #------------------------------------------------------------------------------
# # Permute subtype labels to examine how well supervised model performs
#
# # nperm = 10000
#
# # make subtypes using z-scores computed from the mean and sd of the training set
# train_data = Dverbal_Discovery
# test_data = Dverbal_Replication
# mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]])
# sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]])
# tmp_train = make_subtype(data2use = train_data,
#                          z_thresh = z_thresh,
#                          mean2use = mean2use,
#                          sd2use = sd2use)
#
# mean2use = mean(test_data[,vars2use[1]] - test_data[,vars2use[2]])
# sd2use = sd(test_data[,vars2use[1]] - test_data[,vars2use[2]])
# tmp_test = make_subtype(data2use = test_data,
#                         z_thresh = z_thresh,
#                         mean2use = mean2use,
#                         sd2use = sd2use)
#
# acc = vector(length = nperm)
# for (iperm in 1:nperm){
#   # set seed for reproducibility
#   set.seed(iperm)
#
#   sc_perm = sample(train_data[,vars2use[1]])
#   rrb_perm = sample(train_data[,vars2use[2]])
#   perm_mean2use = mean(sc_perm - rrb_perm)
#   perm_sd2use = sd(sc_perm - rrb_perm)
#   # perm_mean2use = mean(train_data[,vars2use[1]] - rrb_perm)
#   # perm_sd2use = sd(train_data[,vars2use[1]] - rrb_perm)
#   pred_labels = make_subtype(data2use = tmp_test,
#                         z_thresh = z_thresh,
#                         mean2use = perm_mean2use,
#                         sd2use = perm_sd2use)
#   confmat = table(tmp_test$z_ds_group,pred_labels$z_ds_group)
#   acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/dim(pred_labels)[1]
#
#   # compute model
#   permuted_labels = sample(tmp_train$z_ds_group)
#   mod2use = svm(x = tmp_train[,vars2use], y = permuted_labels)
#   pred_labels = predict(mod2use, tmp_test[,vars2use])
#   confmat = table(tmp_test$z_ds_group,pred_labels)
#   acc[iperm] = (confmat[1,1]+confmat[2,2]+confmat[3,3])/length(pred_labels)
#   #============================================================================
# } # for (iperm in 1:nperm)
#
# df2plot = data.frame(Accuracy = acc)
# p = ggplot(data = df2plot, aes(x = Accuracy)) + geom_histogram() + geom_vline(xintercept=true_accuracy)
# p
#
# # compute p-value
# pval = sum(c(true_accuracy,acc)>=true_accuracy)/(nperm+1)
# pval
#================================================================================
#================================================================================

#------------------------------------------------------------------------------
# Plot difference score Z subtypes in Discovery set
maxScores = c(3,4)

# Discovery - make plot with all individuals shown as lines
df2use = Dverbal_Discovery[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(tmp_train$z_ds_group)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$SC = df2use$dbaes_atotal
df2use$RRB = df2use$dbaes_btotal

df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"),
               measure.vars = c("SC","RRB"))

p = ggplot(data = df4plot, aes(x = variable,
                               y = value,
                               colour = subgrp,
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + ylim(0,1) + guides(color=FALSE)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
p3_middle_top = p + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Disc_jitterplot_z%s.pdf",as.character(z_thresh))), plot = p3_middle_top)
p

# Plot difference score Z subtypes in Replication set
maxScores = c(3,4)

# Replication - make plot with all individuals shown as lines
df2use = Dverbal_Replication[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(tmp_test$z_ds_group)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$SC = df2use$dbaes_atotal
df2use$RRB = df2use$dbaes_btotal

df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"),
               measure.vars = c("SC","RRB"))

p = ggplot(data = df4plot, aes(x = variable,
                               y = value,
                               colour = subgrp,
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + ylim(0,1) + guides(color=FALSE)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
p4_middle_bottom = p + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Rep_jitterplot_z%s.pdf",as.character(z_thresh))), plot = p4_middle_bottom)
p

#------------------------------------------------------------------------------
# Apply NDAR subtypes to EU-AIMS LEAP data

# make SC and RRB percentages since EU-AIMS data is specified as percentages
Dverbal = read.csv(file.path(datapath,"tidy_verbal.csv"))
euaims_data = read.csv(file.path(datapath,"tidy_euaims.csv"))
mask1 = euaims_data$Diagnosis=="ASD"
mask2 =  (is.na(euaims_data$A1_pct_severity) | is.na(euaims_data$A2_pct_severity) | is.na(euaims_data$A3_pct_severity) | is.na(euaims_data$B1_pct_severity) | is.na(euaims_data$B2_pct_severity) | is.na(euaims_data$B3_pct_severity) | is.na(euaims_data$B4_pct_severity))
euaims_data = subset(euaims_data, (mask1 & !mask2))

Dverbal[,vars2use[1]] = Dverbal[,vars2use[1]]
Dverbal[,vars2use[2]] = Dverbal[,vars2use[2]]
euaims_data[,vars2use[1]] = (euaims_data$A1_pct_severity +
                               euaims_data$A2_pct_severity +
                               euaims_data$A3_pct_severity)/3
euaims_data[,vars2use[2]] = (euaims_data$B1_pct_severity +
                               euaims_data$B2_pct_severity +
                               euaims_data$B3_pct_severity +
                               euaims_data$B4_pct_severity)/4

train_data = Dverbal
test_data = euaims_data

mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]], na.rm=TRUE)
sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]], na.rm=TRUE)
c(mean2use, sd2use)

tmp_train = make_subtype(data2use = train_data,
                         z_thresh = z_thresh,
                         mean2use = mean2use,
                         sd2use = sd2use)

tmp_test = make_subtype(data2use = test_data,
                        z_thresh = z_thresh,
                        mean2use = mean2use,
                        sd2use = sd2use)

#===========================================================================
#===========================================================================
# # compute model
# mod2use = svm(x = tmp_train[,vars2use], y = tmp_train$z_ds_group)
# pred_labels = predict(mod2use, tmp_test[,vars2use])
# confmat = table(tmp_test$z_ds_group,pred_labels)
# acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/length(pred_labels)
#
# tmp_test$svm_pred_labels = pred_labels
#
# # plot confusion matrix
# setHook("grid.newpage", function() pushViewport(viewport(x=1,y=1,width=0.9, height=0.9, name="vp", just=c("right","top"))), action="prepend")
# pheatmap(confmat/rowSums(confmat)*100, display_numbers = confmat, color = colorRampPalette(c('white','red'))(100), cluster_rows = FALSE, cluster_cols = FALSE, fontsize_number = fontSize, fontsize_row = fontSize, fontsize_col = fontSize,labels_row = c("RRB>SC","SC=RRB","SC>RRB"),labels_col = c("RRB>SC","SC=RRB","SC>RRB"),angle_col=90,
#          breaks= seq(0,100, length=100))
# setHook("grid.newpage", NULL, "replace")
# grid::grid.text("Actual Labels", y=-0.07, gp=gpar(fontsize=fontSize))
# grid::grid.text("Predicted Labels", x=-0.07, rot=90, gp=gpar(fontsize=fontSize))
#===========================================================================
#===========================================================================


# scatterplot
p1 = ggplot(data = tmp_train, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(z_ds_group))) + geom_point() + xlab("Social-Communication") + ylab("Restricted Repetitive Behaviors") + ylim(0,0.8) + xlim(0,0.8) + ggtitle("NDAR ALL")
p1

p2 = ggplot(data = tmp_test, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(z_ds_group))) + geom_point() + xlab("Social-Communication") + ylab("Restricted Repetitive Behaviors") + ylim(0,0.8) + xlim(0,0.8) + ggtitle("EU-AIMS with Groups from NDAR ALL")
p2

#===========================================================================
#===========================================================================
# p3 = ggplot(data = tmp_test, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(pred_labels))) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,0.8) + xlim(0,0.8) + ggtitle("EU-AIMS")
# p5_bottom_right = p3 + guides(colour=FALSE)
# ggsave(filename = file.path(plotpath, sprintf("final_EUAIMS_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p5_bottom_right)
# p3
#===========================================================================
#===========================================================================

# # write out EU-AIMS LEAP data with subgroups defined by NDAR All
write.csv(tmp_test, file.path(datapath, sprintf("tidy_euaims_NDAR_subtypes_diffscore_z%s.csv",as.character(z_thresh))))

#===========================================================================
#===========================================================================
# # Make final plot
# p_final = p1_top_left + p3_middle_top + plot_spacer() + p2_bottom_left + p4_middle_bottom + p5_bottom_right + plot_layout(nrow=3, ncol=3, widths = c(4,4,4), heights = c(8,8,8))
# ggsave(filename = file.path(plotpath, sprintf("final_NDAR_EUAIMS_subtypes_plot_z%s.pdf",as.character(z_thresh))), plot = p_final)
# p_final
#===========================================================================
#===========================================================================

#------------------------------------------------------------------------------
# Integrate subtypes with rest of EU-AIMS LEAP data
euaims_data = read.csv(file.path(datapath,"tidy_euaims.csv"))
td_df = subset(euaims_data, euaims_data$Diagnosis=="TD",select=2:6)
td_df$A_pct_severity = as.numeric(NA)
td_df$B_pct_severity = as.numeric(NA)
td_df$subgrp = "TD"

#===========================================================================
#===========================================================================
# cols2use = c("subid","age","Centre","Schedule","Diagnosis","dbaes_atotal","dbaes_btotal","svm_pred_labels")
cols2use = c("subid","age","Centre","Schedule","Diagnosis","dbaes_atotal","dbaes_btotal","z_ds_group")
#===========================================================================
#===========================================================================
tmp_asd = tmp_test[,cols2use]
colnames(tmp_asd)[6] = "A_pct_severity"
colnames(tmp_asd)[7] = "B_pct_severity"
colnames(tmp_asd)[8] = "subgrp"
asd_df = tmp_asd

all_data = rbind(td_df,asd_df)

fname = "/Users/mlombardo/Dropbox/euaims/data/rsfmri_preproc/euaims_preproc.xlsx"
pp_data = read_excel(fname)
mask = pp_data$notes=="ok"
pp_data = subset(pp_data, mask)

asd_df = merge(pp_data[,c("subid","sex")],asd_df, by = "subid")
td_df = merge(pp_data[,c("subid","sex")],td_df, by = "subid")

all_data = rbind(td_df,asd_df)

data2write = merge(pp_data, all_data, by = "subid")
data2write$age = data2write$age.x
data2write$sex = data2write$sex.y
print(table(data2write$Schedule, data2write$subgrp))
print(table(data2write$Centre, data2write$subgrp))
print(table(data2write$sex, data2write$subgrp))

#DSM-5 - find best split that balances participants across sites
a = findBestSplit(asd_df, seed_range = c(172342)) #,300001:500000))
best_seeds = a$seed[!is.na(a$discrepancy) & a$discrepancy==min(a$discrepancy, na.rm = TRUE)]
print(best_seeds)

# Split datasets -------------------------------------------------------------
rngSeed = best_seeds[1]

# split Schedule A dataset
dset2use = subset(asd_df, asd_df$Schedule=="A")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
A_Discovery = tmp_d[[2]]
A_Replication = tmp_d[[1]]

# split Schedule B dataset
dset2use = subset(asd_df, asd_df$Schedule=="B")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
B_Discovery = tmp_d[[2]]
B_Replication = tmp_d[[1]]

# split Schedule C dataset
dset2use = subset(asd_df, asd_df$Schedule=="C")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
C_Discovery = tmp_d[[2]]
C_Replication = tmp_d[[1]]

# split Schedule D dataset
dset2use = subset(asd_df, asd_df$Schedule=="D")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
D_Discovery = tmp_d[[2]]
D_Replication = tmp_d[[1]]

df_Disc = rbind(A_Discovery, B_Discovery, C_Discovery, D_Discovery)
df_Rep = rbind(A_Replication, B_Replication, C_Replication, D_Replication)

a = table(df_Disc$Schedule, df_Disc$Centre); print(a)
b = table(df_Rep$Schedule, df_Rep$Centre); print(b)
print(a-b)
print(sum(rowSums(abs(a-b))))

data2write$dataset = NA
mask  = is.element(data2write$subid,df_Disc$subid)
data2write[mask,"dataset"] = "Discovery"
mask  = is.element(data2write$subid,df_Rep$subid)
data2write[mask,"dataset"] = "Replication"

asd_Disc = subset(data2write, data2write$dataset=="Discovery" & data2write$Diagnosis=="ASD")
asd_Rep = subset(data2write, data2write$dataset=="Replication" & data2write$Diagnosis=="ASD")

# # find which seed gives best TD age-match -------------------------------------
# seeds = 1:1000
# pvals = data.frame(matrix(nrow = length(seeds), ncol = 2))
# for (i in 1:length(seeds)) {
#   res = findTDAgeMatch(data2write, seed_range = c(seeds[i],seeds[i]))
#   td_Disc_matched = res[[2]]
#   td_Rep_matched = res[[1]]
#   tres = t.test(td_Disc_matched$age, asd_Disc$age)
#   pvals[i,1] = tres$p.value
#   tres = t.test(td_Rep_matched$age, asd_Rep$age)
#   pvals[i,2] = tres$p.value
#   #print(i)
# }
# a = sort.int(pvals[,1], decreasing = TRUE, index.return = TRUE)
# b=pvals[a$ix,]

seed2use = 929
res = findTDAgeMatch(data2write, seed_range = c(seed2use,seed2use))
td_Disc_matched = res[[2]]
td_Rep_matched = res[[1]]

mask = is.element(data2write$subid, td_Disc_matched$subid)
data2write$dataset[mask] = "Discovery"

mask = is.element(data2write$subid, td_Rep_matched$subid)
data2write$dataset[mask] = "Replication"

print(table(data2write$dataset, data2write$subgrp))

fname2save = here(sprintf("asd_subgrp_data_rsfmri_ALL_DSM5_diffzscoreGrps_z%s.csv",as.character(z_thresh)))
write.csv(data2write,file = fname2save)

#------------------------------------------------------------------------------
# Descriptive stats
df2use = data2write[,c("subid","Diagnosis","dataset","Centre","meanFD","age","sex","subgrp","viq_all","piq_all","fsiq4_all","A_pct_severity","B_pct_severity","ADI_social_total","ADI_communication_total","ADI_RRB_total","ados_2_SA_CSS","ados_2_RRB_CSS","SRS_tscore","SRS_tscore_self","RBS_total","SSP_total","vabsdscoresc_dss","vabsdscoresd_dss","vabsdscoress_dss","vabsabcabc_standard")]
mask = df2use==999 | df2use==777
df2use[mask] = NA
df2use$age = df2use$age/365

cols2use = c("dataset","subgrp","age","meanFD","viq_all","piq_all","fsiq4_all","A_pct_severity","B_pct_severity","ADI_social_total","ADI_communication_total","ADI_RRB_total","ados_2_SA_CSS","ados_2_RRB_CSS","SRS_tscore","SRS_tscore_self","RBS_total","SSP_total","vabsdscoresc_dss","vabsdscoresd_dss","vabsdscoress_dss","vabsabcabc_standard")
res=describeBy(x = df2use[,cols2use], group = c("subgrp","dataset"))
res

#------------------------------------------------------------------------------
# Table of subtypes X sex

# Discovery
data2use = subset(data2write,data2write$dataset=="Discovery")
table(data2use$subgrp,data2use$sex)
cs_res = chisq.test(data2use$subgrp,data2use$sex)
cs_res

# Replication
data2use = subset(data2write,data2write$dataset=="Replication")
table(data2use$subgrp,data2use$sex)
cs_res = chisq.test(data2use$subgrp,data2use$sex)
cs_res

#------------------------------------------------------------------------------
vars2analyze = c("age","meanFD","viq_all","piq_all","fsiq4_all",
                 "A_pct_severity","B_pct_severity",
                 "ADI_social_total","ADI_communication_total","ADI_RRB_total",
                 "ados_2_SA_CSS","ados_2_RRB_CSS",
                 "SRS_tscore_self","RBS_total","SSP_total",
                 "vabsdscoress_dss","vabsdscoresd_dss","vabsdscoresc_dss","vabsabcabc_standard")

vnames = c("Age","Mean FD","VIQ","PIQ","FIQ","ADI-R SC","ADI-R RRB","ADI-R Social","ADI-R Communication","ADI-R RRB","ADOS SA CSS","ADOS RRB CSS","SRS","RBS","SSP","Vineland Socialization","Vineland Daily Living Skills","Vineland Communication","Vineland ABC")

cnames = c("All_Disc.fstat","All_Disc.pval","All_Rep.fstat","All_Rep.pval",
           "SCequalRRB_vs_SCoverRRB_Disc.fstat","SCequalRRB_vs_SCoverRRB_Disc.tstat",
           "SCequalRRB_vs_SCoverRRB_Disc.pval","SCequalRRB_vs_SCoverRRB_Disc.es",
           "SCequalRRB_vs_SCoverRRB_Rep.fstat","SCequalRRB_vs_SCoverRRB_Rep.tstat",
           "SCequalRRB_vs_SCoverRRB_Rep.pval","SCequalRRB_vs_SCoverRRB_Rep.es",
           "SCequalRRB_vs_SCoverRRB.repBF")

output_res = data.frame(matrix(nrow = length(vars2analyze),ncol = length(cnames)))
colnames(output_res) = cnames
rownames(output_res) = vars2analyze
output_res$varNames = vars2analyze

for (ivar in 1:length(vars2analyze)){

  y_var = vars2analyze[ivar]
  # print(y_var)
  #----------------------------------------------------------------------------
  # Discovery
  df4mod = subset(df2use, df2use$dataset=="Discovery")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"All_Disc.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"All_Disc.pval"] = res["subgrp","p-value"]

  #----------------------------------------------------------------------------
  # Replication
  df4mod = subset(df2use, df2use$dataset=="Replication")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"All_Rep.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"All_Rep.pval"] = res["subgrp","p-value"]

  #----------------------------------------------------------------------------
  # Discovery
  df4mod = subset(df2use, df2use$dataset=="Discovery" & !is.element(df2use$subgrp,c("TD","RRB_over_SC")))
  n1 = sum(df4mod$subgrp=="SC_equal_RRB")
  m1 = sum(df4mod$subgrp=="SC_over_RRB")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.pval"] = res["subgrp","p-value"]
  res = summary(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.tstat"] = res$tTable[2,"t-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.es"] = cohens_d(df4mod[df4mod$subgrp=="SC_equal_RRB",y_var],
                                                                 df4mod[df4mod$subgrp=="SC_over_RRB",y_var])

  #----------------------------------------------------------------------------
  # Replication
  df4mod = subset(df2use, df2use$dataset=="Replication" & !is.element(df2use$subgrp,c("TD","RRB_over_SC")))
  n2 = sum(df4mod$subgrp=="SC_equal_RRB")
  m2 = sum(df4mod$subgrp=="SC_over_RRB")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.pval"] = res["subgrp","p-value"]
  res = summary(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.tstat"] = res$tTable[2,"t-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.es"] = cohens_d(df4mod[df4mod$subgrp=="SC_equal_RRB",y_var],
                                                                 df4mod[df4mod$subgrp=="SC_over_RRB",y_var])

  #----------------------------------------------------------------------------
  # Replication Bayes Factor
  res_bf = BFSALL(tobs = output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.tstat"],
                  trep = output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.tstat"],
                  n1 = n1,
                  n2 = n2,
                  m1 = m1,
                  m2 = m2,
                  sample = 2,
                  Type = 'ALL')
  output_res[y_var,"SCequalRRB_vs_SCoverRRB.repBF"] = res_bf["Replication BF","Replication 1"]

  # make a plot
  colors2use = get_ggColorHue(3)
  df4plot = subset(df2use, df2use$subgrp!="RRB_over_SC")
  p = ggplot(data = df4plot, aes_string(x = "subgrp", y = y_var, colour = "subgrp")) + facet_grid(. ~ dataset)
  p = p + geom_jitter() + geom_boxplot(fill = NA, colour = "#000000", outlier.shape = NA)
  p = p + ylab(vnames[ivar]) + xlab("Group") +
    scale_x_discrete(labels=c("SC_equal_RRB"="SC=RRB","SC_over_RRB"="SC>RRB","TD"="TD")) +
                       scale_colour_manual(values = c(colors2use[2:3],"grey60")) + guides(colour=FALSE) +
    theme(text = element_text(size=fontSize-5),
        axis.text.x = element_text(size=fontSize-5),
        axis.text.y = element_text(size=fontSize-5))
  print(p)

}
vabc["0.7","Discovery"] = output_res["vabsabcabc_standard","SCequalRRB_vs_SCoverRRB_Disc.es"]
vabc["0.7","Replication"] = output_res["vabsabcabc_standard","SCequalRRB_vs_SCoverRRB_Rep.es"]
vabc_dls["0.7","Discovery"] = output_res["vabsdscoresd_dss","SCequalRRB_vs_SCoverRRB_Disc.es"]
vabc_dls["0.7","Replication"] = output_res["vabsdscoresd_dss","SCequalRRB_vs_SCoverRRB_Rep.es"]
output_res
```

## SC-RRB difference z = 0.8

```{r, warning=FALSE, message=FALSE}
#------------------------------------------------------------------------------
# Z-score threshold to use for subtyping
z_thresh = 0.8

# vars2use = c("dbaes_atotal","dbaes_btotal")

# compute Discovery mean and sd
ds_disc = Dverbal_Discovery[,vars2use[1]] - Dverbal_Discovery[,vars2use[2]]
mean2use = mean(ds_disc)
sd2use = sd(ds_disc)

Dverbal_Discovery = make_subtype(data2use = Dverbal_Discovery,
                                 z_thresh = z_thresh,
                                 mean2use = mean2use,
                                 sd2use = sd2use)

# compute Replication mean and sd
ds_rep = Dverbal_Replication[,vars2use[1]] - Dverbal_Replication[,vars2use[2]]
mean2use = mean(ds_rep)
sd2use = sd(ds_rep)

Dverbal_Replication = make_subtype(data2use = Dverbal_Replication,
                                 z_thresh = z_thresh,
                                 mean2use = mean2use,
                                 sd2use = sd2use)

#------------------------------------------------------------------------------
# Table of subtypes X sex

# Discovery
table(Dverbal_Discovery$z_ds_group,Dverbal_Discovery$sex)
cs_res = chisq.test(Dverbal_Discovery$z_ds_group,Dverbal_Discovery$sex)
cs_res

# Replication
table(Dverbal_Replication$z_ds_group,Dverbal_Replication$sex)
cs_res = chisq.test(Dverbal_Replication$z_ds_group,Dverbal_Replication$sex)
cs_res

#------------------------------------------------------------------------------
# Descriptive stats

# Discovery
df2use = Dverbal_Discovery[,c("subjectkey","dataset_id","collection_id","interview_age","sex","z_ds_group","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")]
df2use$age = df2use$interview_age/12

cols2use = c("z_ds_group","sex","age","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")
res=describeBy(x = df2use[,cols2use], group = "z_ds_group")
res

# Replication
df2use = Dverbal_Replication[,c("subjectkey","dataset_id","collection_id","interview_age","sex","z_ds_group","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")]
df2use$age = df2use$interview_age/12

cols2use = c("z_ds_group","sex","age","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")
res=describeBy(x = df2use[,cols2use], group = "z_ds_group")
res

#------------------------------------------------------------------------------
# Tests of differences in interview age across the subtypes

# Discovery
mod2use = lm(formula = interview_age ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = interview_age ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in SC across the subtypes

# Discovery
mod2use = lm(formula = dbaes_atotal ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = dbaes_atotal ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in RRB across the subtypes

# Discovery
mod2use = lm(formula = dbaes_btotal ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = dbaes_btotal ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in ADOS SA CSS across the subtypes

# Discovery
mod2use = lm(formula = ados_sa_css ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = ados_sa_css ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in ADOS RRB CSS across the subtypes

# Discovery
mod2use = lm(formula = ados_rrb_css ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = ados_rrb_css ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)


#------------------------------------------------------------------------------
# Tests of differences in IQ across the subtypes

# Discovery
mod2use = lm(formula = iq ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = iq ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)


#------------------------------------------------------------------------------
# Make scatterplots with difference score Z subtypes in different colors
maxScores = c(3,4)

p_disc = ggplot(data = Dverbal_Discovery, aes(x = dbaes_atotal, y = dbaes_btotal, colour = z_ds_group)) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,1) + xlim(0,1) + ggtitle("NDAR Discovery")
p1_top_left = p_disc + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Disc_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p1_top_left)
p_disc
table(Dverbal_Discovery$z_ds_group)

cor_res = cor.test(Dverbal_Discovery$dbaes_atotal, Dverbal_Discovery$dbaes_btotal)
cor_res

p_rep = ggplot(data = Dverbal_Replication, aes(x = dbaes_atotal, y = dbaes_btotal, colour = z_ds_group)) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,1) + xlim(0,1) +  ggtitle("NDAR Replication")
p2_bottom_left = p_rep + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Rep_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p2_bottom_left)
p_rep
table(Dverbal_Replication$z_ds_group)

cor_res = cor.test(Dverbal_Replication$dbaes_atotal, Dverbal_Replication$dbaes_btotal)
cor_res

#------------------------------------------------------------------------------
# Run supervised model with Discovery as training and Replication as Test

# run validation
# make subtypes using z-scores computed from the mean and sd of the training set
train_data = Dverbal_Discovery
test_data = Dverbal_Replication

mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]])
sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]])
tmp_train = make_subtype(data2use = train_data,
                         z_thresh = z_thresh,
                         mean2use = mean2use,
                         sd2use = sd2use)

mean2use = mean(test_data[,vars2use[1]] - test_data[,vars2use[2]])
sd2use = sd(test_data[,vars2use[1]] - test_data[,vars2use[2]])
tmp_test = make_subtype(data2use = test_data,
                        z_thresh = z_thresh,
                        mean2use = mean2use,
                        sd2use = sd2use)

#==============================================================================
#==============================================================================
# make labels based on train mean and sd
mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]])
sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]])
train_mean = mean2use
train_sd = sd2use

pred_labels = make_subtype(data2use = test_data,
                        z_thresh = z_thresh,
                        mean2use = train_mean,
                        sd2use = train_sd)
confmat = table(tmp_test$z_ds_group,pred_labels$z_ds_group)
acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/dim(pred_labels)[1]

# # compute model
# mod2use = svm(x = tmp_train[,vars2use], y = tmp_train$z_ds_group)
# pred_labels = predict(mod2use, tmp_test[,vars2use])
# confmat = table(tmp_test$z_ds_group,pred_labels)
# acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/length(pred_labels)
#==============================================================================
#==============================================================================

# plot confusion matrix
setHook("grid.newpage", function() pushViewport(viewport(x=1,y=1,width=0.9, height=0.9, name="vp", just=c("right","top"))), action="prepend")
pheatmap(confmat/rowSums(confmat)*100, display_numbers = confmat, color = colorRampPalette(c('white','red'))(100), cluster_rows = FALSE, cluster_cols = FALSE, fontsize_number = fontSize, fontsize_row = fontSize, fontsize_col = fontSize,labels_row = c("RRB>SC","SC=RRB","SC>RRB"),labels_col = c("RRB>SC","SC=RRB","SC>RRB"),angle_col=90,
         breaks= seq(0,100, length=100))
setHook("grid.newpage", NULL, "replace")
grid::grid.text("Actual Labels", y=-0.07, gp=gpar(fontsize=fontSize))
grid::grid.text("Predicted Labels", x=-0.07, rot=90, gp=gpar(fontsize=fontSize))


# show accuracy
true_accuracy = acc
true_accuracy

#================================================================================
#================================================================================
# #------------------------------------------------------------------------------
# # Permute subtype labels to examine how well supervised model performs
#
# # nperm = 10000
#
# # make subtypes using z-scores computed from the mean and sd of the training set
# train_data = Dverbal_Discovery
# test_data = Dverbal_Replication
# mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]])
# sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]])
# tmp_train = make_subtype(data2use = train_data,
#                          z_thresh = z_thresh,
#                          mean2use = mean2use,
#                          sd2use = sd2use)
#
# mean2use = mean(test_data[,vars2use[1]] - test_data[,vars2use[2]])
# sd2use = sd(test_data[,vars2use[1]] - test_data[,vars2use[2]])
# tmp_test = make_subtype(data2use = test_data,
#                         z_thresh = z_thresh,
#                         mean2use = mean2use,
#                         sd2use = sd2use)
#
# acc = vector(length = nperm)
# for (iperm in 1:nperm){
#   # set seed for reproducibility
#   set.seed(iperm)
#
#   sc_perm = sample(train_data[,vars2use[1]])
#   rrb_perm = sample(train_data[,vars2use[2]])
#   perm_mean2use = mean(sc_perm - rrb_perm)
#   perm_sd2use = sd(sc_perm - rrb_perm)
#   # perm_mean2use = mean(train_data[,vars2use[1]] - rrb_perm)
#   # perm_sd2use = sd(train_data[,vars2use[1]] - rrb_perm)
#   pred_labels = make_subtype(data2use = tmp_test,
#                         z_thresh = z_thresh,
#                         mean2use = perm_mean2use,
#                         sd2use = perm_sd2use)
#   confmat = table(tmp_test$z_ds_group,pred_labels$z_ds_group)
#   acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/dim(pred_labels)[1]
#
#   # compute model
#   permuted_labels = sample(tmp_train$z_ds_group)
#   mod2use = svm(x = tmp_train[,vars2use], y = permuted_labels)
#   pred_labels = predict(mod2use, tmp_test[,vars2use])
#   confmat = table(tmp_test$z_ds_group,pred_labels)
#   acc[iperm] = (confmat[1,1]+confmat[2,2]+confmat[3,3])/length(pred_labels)
#   #============================================================================
# } # for (iperm in 1:nperm)
#
# df2plot = data.frame(Accuracy = acc)
# p = ggplot(data = df2plot, aes(x = Accuracy)) + geom_histogram() + geom_vline(xintercept=true_accuracy)
# p
#
# # compute p-value
# pval = sum(c(true_accuracy,acc)>=true_accuracy)/(nperm+1)
# pval
#================================================================================
#================================================================================

#------------------------------------------------------------------------------
# Plot difference score Z subtypes in Discovery set
maxScores = c(3,4)

# Discovery - make plot with all individuals shown as lines
df2use = Dverbal_Discovery[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(tmp_train$z_ds_group)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$SC = df2use$dbaes_atotal
df2use$RRB = df2use$dbaes_btotal

df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"),
               measure.vars = c("SC","RRB"))

p = ggplot(data = df4plot, aes(x = variable,
                               y = value,
                               colour = subgrp,
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + ylim(0,1) + guides(color=FALSE)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
p3_middle_top = p + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Disc_jitterplot_z%s.pdf",as.character(z_thresh))), plot = p3_middle_top)
p

# Plot difference score Z subtypes in Replication set
maxScores = c(3,4)

# Replication - make plot with all individuals shown as lines
df2use = Dverbal_Replication[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(tmp_test$z_ds_group)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$SC = df2use$dbaes_atotal
df2use$RRB = df2use$dbaes_btotal

df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"),
               measure.vars = c("SC","RRB"))

p = ggplot(data = df4plot, aes(x = variable,
                               y = value,
                               colour = subgrp,
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + ylim(0,1) + guides(color=FALSE)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
p4_middle_bottom = p + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Rep_jitterplot_z%s.pdf",as.character(z_thresh))), plot = p4_middle_bottom)
p

#------------------------------------------------------------------------------
# Apply NDAR subtypes to EU-AIMS LEAP data

# make SC and RRB percentages since EU-AIMS data is specified as percentages
Dverbal = read.csv(file.path(datapath,"tidy_verbal.csv"))
euaims_data = read.csv(file.path(datapath,"tidy_euaims.csv"))
mask1 = euaims_data$Diagnosis=="ASD"
mask2 =  (is.na(euaims_data$A1_pct_severity) | is.na(euaims_data$A2_pct_severity) | is.na(euaims_data$A3_pct_severity) | is.na(euaims_data$B1_pct_severity) | is.na(euaims_data$B2_pct_severity) | is.na(euaims_data$B3_pct_severity) | is.na(euaims_data$B4_pct_severity))
euaims_data = subset(euaims_data, (mask1 & !mask2))

Dverbal[,vars2use[1]] = Dverbal[,vars2use[1]]
Dverbal[,vars2use[2]] = Dverbal[,vars2use[2]]
euaims_data[,vars2use[1]] = (euaims_data$A1_pct_severity +
                               euaims_data$A2_pct_severity +
                               euaims_data$A3_pct_severity)/3
euaims_data[,vars2use[2]] = (euaims_data$B1_pct_severity +
                               euaims_data$B2_pct_severity +
                               euaims_data$B3_pct_severity +
                               euaims_data$B4_pct_severity)/4

train_data = Dverbal
test_data = euaims_data

mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]], na.rm=TRUE)
sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]], na.rm=TRUE)
c(mean2use, sd2use)

tmp_train = make_subtype(data2use = train_data,
                         z_thresh = z_thresh,
                         mean2use = mean2use,
                         sd2use = sd2use)

tmp_test = make_subtype(data2use = test_data,
                        z_thresh = z_thresh,
                        mean2use = mean2use,
                        sd2use = sd2use)

#===========================================================================
#===========================================================================
# # compute model
# mod2use = svm(x = tmp_train[,vars2use], y = tmp_train$z_ds_group)
# pred_labels = predict(mod2use, tmp_test[,vars2use])
# confmat = table(tmp_test$z_ds_group,pred_labels)
# acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/length(pred_labels)
#
# tmp_test$svm_pred_labels = pred_labels
#
# # plot confusion matrix
# setHook("grid.newpage", function() pushViewport(viewport(x=1,y=1,width=0.9, height=0.9, name="vp", just=c("right","top"))), action="prepend")
# pheatmap(confmat/rowSums(confmat)*100, display_numbers = confmat, color = colorRampPalette(c('white','red'))(100), cluster_rows = FALSE, cluster_cols = FALSE, fontsize_number = fontSize, fontsize_row = fontSize, fontsize_col = fontSize,labels_row = c("RRB>SC","SC=RRB","SC>RRB"),labels_col = c("RRB>SC","SC=RRB","SC>RRB"),angle_col=90,
#          breaks= seq(0,100, length=100))
# setHook("grid.newpage", NULL, "replace")
# grid::grid.text("Actual Labels", y=-0.07, gp=gpar(fontsize=fontSize))
# grid::grid.text("Predicted Labels", x=-0.07, rot=90, gp=gpar(fontsize=fontSize))
#===========================================================================
#===========================================================================

# scatterplot
p1 = ggplot(data = tmp_train, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(z_ds_group))) + geom_point() + xlab("Social-Communication") + ylab("Restricted Repetitive Behaviors") + ylim(0,0.8) + xlim(0,0.8) + ggtitle("NDAR ALL")
p1

p2 = ggplot(data = tmp_test, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(z_ds_group))) + geom_point() + xlab("Social-Communication") + ylab("Restricted Repetitive Behaviors") + ylim(0,0.8) + xlim(0,0.8) + ggtitle("EU-AIMS with Groups from NDAR ALL")
p2

#===========================================================================
#===========================================================================
# p3 = ggplot(data = tmp_test, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(pred_labels))) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,0.8) + xlim(0,0.8) + ggtitle("EU-AIMS")
# p5_bottom_right = p3 + guides(colour=FALSE)
# ggsave(filename = file.path(plotpath, sprintf("final_EUAIMS_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p5_bottom_right)
# p3
#===========================================================================
#===========================================================================

# # write out EU-AIMS LEAP data with subgroups defined by NDAR All
write.csv(tmp_test, file.path(datapath, sprintf("tidy_euaims_NDAR_subtypes_diffscore_z%s.csv",as.character(z_thresh))))

#===========================================================================
#===========================================================================
# # Make final plot
# p_final = p1_top_left + p3_middle_top + plot_spacer() + p2_bottom_left + p4_middle_bottom + p5_bottom_right + plot_layout(nrow=3, ncol=3, widths = c(4,4,4), heights = c(8,8,8))
# ggsave(filename = file.path(plotpath, sprintf("final_NDAR_EUAIMS_subtypes_plot_z%s.pdf",as.character(z_thresh))), plot = p_final)
# p_final
#===========================================================================
#===========================================================================

#------------------------------------------------------------------------------
# Integrate subtypes with rest of EU-AIMS LEAP data
euaims_data = read.csv(file.path(datapath,"tidy_euaims.csv"))
td_df = subset(euaims_data, euaims_data$Diagnosis=="TD",select=2:6)
td_df$A_pct_severity = as.numeric(NA)
td_df$B_pct_severity = as.numeric(NA)
td_df$subgrp = "TD"

#===========================================================================
#===========================================================================
# cols2use = c("subid","age","Centre","Schedule","Diagnosis","dbaes_atotal","dbaes_btotal","svm_pred_labels")
cols2use = c("subid","age","Centre","Schedule","Diagnosis","dbaes_atotal","dbaes_btotal","z_ds_group")
#===========================================================================
#===========================================================================
tmp_asd = tmp_test[,cols2use]
colnames(tmp_asd)[6] = "A_pct_severity"
colnames(tmp_asd)[7] = "B_pct_severity"
colnames(tmp_asd)[8] = "subgrp"
asd_df = tmp_asd

all_data = rbind(td_df,asd_df)

fname = "/Users/mlombardo/Dropbox/euaims/data/rsfmri_preproc/euaims_preproc.xlsx"
pp_data = read_excel(fname)
mask = pp_data$notes=="ok"
pp_data = subset(pp_data, mask)

asd_df = merge(pp_data[,c("subid","sex")],asd_df, by = "subid")
td_df = merge(pp_data[,c("subid","sex")],td_df, by = "subid")

all_data = rbind(td_df,asd_df)

data2write = merge(pp_data, all_data, by = "subid")
data2write$age = data2write$age.x
data2write$sex = data2write$sex.y
print(table(data2write$Schedule, data2write$subgrp))
print(table(data2write$Centre, data2write$subgrp))
print(table(data2write$sex, data2write$subgrp))

#DSM-5 - find best split that balances participants across sites
a = findBestSplit(asd_df, seed_range = c(172342)) #,300001:500000))
best_seeds = a$seed[!is.na(a$discrepancy) & a$discrepancy==min(a$discrepancy, na.rm = TRUE)]
print(best_seeds)

# Split datasets -------------------------------------------------------------
rngSeed = best_seeds[1]

# split Schedule A dataset
dset2use = subset(asd_df, asd_df$Schedule=="A")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
A_Discovery = tmp_d[[2]]
A_Replication = tmp_d[[1]]

# split Schedule B dataset
dset2use = subset(asd_df, asd_df$Schedule=="B")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
B_Discovery = tmp_d[[2]]
B_Replication = tmp_d[[1]]

# split Schedule C dataset
dset2use = subset(asd_df, asd_df$Schedule=="C")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
C_Discovery = tmp_d[[2]]
C_Replication = tmp_d[[1]]

# split Schedule D dataset
dset2use = subset(asd_df, asd_df$Schedule=="D")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
D_Discovery = tmp_d[[2]]
D_Replication = tmp_d[[1]]

df_Disc = rbind(A_Discovery, B_Discovery, C_Discovery, D_Discovery)
df_Rep = rbind(A_Replication, B_Replication, C_Replication, D_Replication)

a = table(df_Disc$Schedule, df_Disc$Centre); print(a)
b = table(df_Rep$Schedule, df_Rep$Centre); print(b)
print(a-b)
print(sum(rowSums(abs(a-b))))

data2write$dataset = NA
mask  = is.element(data2write$subid,df_Disc$subid)
data2write[mask,"dataset"] = "Discovery"
mask  = is.element(data2write$subid,df_Rep$subid)
data2write[mask,"dataset"] = "Replication"

asd_Disc = subset(data2write, data2write$dataset=="Discovery" & data2write$Diagnosis=="ASD")
asd_Rep = subset(data2write, data2write$dataset=="Replication" & data2write$Diagnosis=="ASD")

# # find which seed gives best TD age-match -------------------------------------
# seeds = 1:1000
# pvals = data.frame(matrix(nrow = length(seeds), ncol = 2))
# for (i in 1:length(seeds)) {
#   res = findTDAgeMatch(data2write, seed_range = c(seeds[i],seeds[i]))
#   td_Disc_matched = res[[2]]
#   td_Rep_matched = res[[1]]
#   tres = t.test(td_Disc_matched$age, asd_Disc$age)
#   pvals[i,1] = tres$p.value
#   tres = t.test(td_Rep_matched$age, asd_Rep$age)
#   pvals[i,2] = tres$p.value
#   #print(i)
# }
# a = sort.int(pvals[,1], decreasing = TRUE, index.return = TRUE)
# b=pvals[a$ix,]

seed2use = 929
res = findTDAgeMatch(data2write, seed_range = c(seed2use,seed2use))
td_Disc_matched = res[[2]]
td_Rep_matched = res[[1]]

mask = is.element(data2write$subid, td_Disc_matched$subid)
data2write$dataset[mask] = "Discovery"

mask = is.element(data2write$subid, td_Rep_matched$subid)
data2write$dataset[mask] = "Replication"

print(table(data2write$dataset, data2write$subgrp))

fname2save = here(sprintf("asd_subgrp_data_rsfmri_ALL_DSM5_diffzscoreGrps_z%s.csv",as.character(z_thresh)))
write.csv(data2write,file = fname2save)


#------------------------------------------------------------------------------
# Descriptive stats
df2use = data2write[,c("subid","Diagnosis","dataset","Centre","meanFD","age","sex","subgrp","viq_all","piq_all","fsiq4_all","A_pct_severity","B_pct_severity","ADI_social_total","ADI_communication_total","ADI_RRB_total","ados_2_SA_CSS","ados_2_RRB_CSS","SRS_tscore","SRS_tscore_self","RBS_total","SSP_total","vabsdscoresc_dss","vabsdscoresd_dss","vabsdscoress_dss","vabsabcabc_standard")]
mask = df2use==999 | df2use==777
df2use[mask] = NA
df2use$age = df2use$age/365

cols2use = c("dataset","subgrp","age","meanFD","viq_all","piq_all","fsiq4_all","A_pct_severity","B_pct_severity","ADI_social_total","ADI_communication_total","ADI_RRB_total","ados_2_SA_CSS","ados_2_RRB_CSS","SRS_tscore","SRS_tscore_self","RBS_total","SSP_total","vabsdscoresc_dss","vabsdscoresd_dss","vabsdscoress_dss","vabsabcabc_standard")
res=describeBy(x = df2use[,cols2use], group = c("subgrp","dataset"))
res

#------------------------------------------------------------------------------
# Table of subtypes X sex

# Discovery
data2use = subset(data2write,data2write$dataset=="Discovery")
table(data2use$subgrp,data2use$sex)
cs_res = chisq.test(data2use$subgrp,data2use$sex)
cs_res

# Replication
data2use = subset(data2write,data2write$dataset=="Replication")
table(data2use$subgrp,data2use$sex)
cs_res = chisq.test(data2use$subgrp,data2use$sex)
cs_res

#------------------------------------------------------------------------------
vars2analyze = c("age","meanFD","viq_all","piq_all","fsiq4_all",
                 "A_pct_severity","B_pct_severity",
                 "ADI_social_total","ADI_communication_total","ADI_RRB_total",
                 "ados_2_SA_CSS","ados_2_RRB_CSS",
                 "SRS_tscore_self","RBS_total","SSP_total",
                 "vabsdscoress_dss","vabsdscoresd_dss","vabsdscoresc_dss","vabsabcabc_standard")

vnames = c("Age","Mean FD","VIQ","PIQ","FIQ","ADI-R SC","ADI-R RRB","ADI-R Social","ADI-R Communication","ADI-R RRB","ADOS SA CSS","ADOS RRB CSS","SRS","RBS","SSP","Vineland Socialization","Vineland Daily Living Skills","Vineland Communication","Vineland ABC")

cnames = c("All_Disc.fstat","All_Disc.pval","All_Rep.fstat","All_Rep.pval",
           "SCequalRRB_vs_SCoverRRB_Disc.fstat","SCequalRRB_vs_SCoverRRB_Disc.tstat",
           "SCequalRRB_vs_SCoverRRB_Disc.pval","SCequalRRB_vs_SCoverRRB_Disc.es",
           "SCequalRRB_vs_SCoverRRB_Rep.fstat","SCequalRRB_vs_SCoverRRB_Rep.tstat",
           "SCequalRRB_vs_SCoverRRB_Rep.pval","SCequalRRB_vs_SCoverRRB_Rep.es",
           "SCequalRRB_vs_SCoverRRB.repBF")

output_res = data.frame(matrix(nrow = length(vars2analyze),ncol = length(cnames)))
colnames(output_res) = cnames
rownames(output_res) = vars2analyze
output_res$varNames = vars2analyze

for (ivar in 1:length(vars2analyze)){

  y_var = vars2analyze[ivar]
  # print(y_var)
  #----------------------------------------------------------------------------
  # Discovery
  df4mod = subset(df2use, df2use$dataset=="Discovery")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"All_Disc.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"All_Disc.pval"] = res["subgrp","p-value"]

  #----------------------------------------------------------------------------
  # Replication
  df4mod = subset(df2use, df2use$dataset=="Replication")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"All_Rep.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"All_Rep.pval"] = res["subgrp","p-value"]

  #----------------------------------------------------------------------------
  # Discovery
  df4mod = subset(df2use, df2use$dataset=="Discovery" & !is.element(df2use$subgrp,c("TD","RRB_over_SC")))
  n1 = sum(df4mod$subgrp=="SC_equal_RRB")
  m1 = sum(df4mod$subgrp=="SC_over_RRB")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.pval"] = res["subgrp","p-value"]
  res = summary(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.tstat"] = res$tTable[2,"t-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.es"] = cohens_d(df4mod[df4mod$subgrp=="SC_equal_RRB",y_var],
                                                                 df4mod[df4mod$subgrp=="SC_over_RRB",y_var])

  #----------------------------------------------------------------------------
  # Replication
  df4mod = subset(df2use, df2use$dataset=="Replication" & !is.element(df2use$subgrp,c("TD","RRB_over_SC")))
  n2 = sum(df4mod$subgrp=="SC_equal_RRB")
  m2 = sum(df4mod$subgrp=="SC_over_RRB")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.pval"] = res["subgrp","p-value"]
  res = summary(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.tstat"] = res$tTable[2,"t-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.es"] = cohens_d(df4mod[df4mod$subgrp=="SC_equal_RRB",y_var],
                                                                 df4mod[df4mod$subgrp=="SC_over_RRB",y_var])

  #----------------------------------------------------------------------------
  # Replication Bayes Factor
  res_bf = BFSALL(tobs = output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.tstat"],
                  trep = output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.tstat"],
                  n1 = n1,
                  n2 = n2,
                  m1 = m1,
                  m2 = m2,
                  sample = 2,
                  Type = 'ALL')
  output_res[y_var,"SCequalRRB_vs_SCoverRRB.repBF"] = res_bf["Replication BF","Replication 1"]

  # make a plot
  colors2use = get_ggColorHue(3)
  df4plot = subset(df2use, df2use$subgrp!="RRB_over_SC")
  p = ggplot(data = df4plot, aes_string(x = "subgrp", y = y_var, colour = "subgrp")) + facet_grid(. ~ dataset)
  p = p + geom_jitter() + geom_boxplot(fill = NA, colour = "#000000", outlier.shape = NA)
  p = p + ylab(vnames[ivar]) + xlab("Group") +
    scale_x_discrete(labels=c("SC_equal_RRB"="SC=RRB","SC_over_RRB"="SC>RRB","TD"="TD")) +
                       scale_colour_manual(values = c(colors2use[2:3],"grey60")) + guides(colour=FALSE) +
    theme(text = element_text(size=fontSize-5),
        axis.text.x = element_text(size=fontSize-5),
        axis.text.y = element_text(size=fontSize-5))
  print(p)

}
vabc["0.8","Discovery"] = output_res["vabsabcabc_standard","SCequalRRB_vs_SCoverRRB_Disc.es"]
vabc["0.8","Replication"] = output_res["vabsabcabc_standard","SCequalRRB_vs_SCoverRRB_Rep.es"]
vabc_dls["0.8","Discovery"] = output_res["vabsdscoresd_dss","SCequalRRB_vs_SCoverRRB_Disc.es"]
vabc_dls["0.8","Replication"] = output_res["vabsdscoresd_dss","SCequalRRB_vs_SCoverRRB_Rep.es"]
output_res
```

## SC-RRB difference z = 0.9

```{r, warning=FALSE, message=FALSE}
#------------------------------------------------------------------------------
# Z-score threshold to use for subtyping
z_thresh = 0.9

# vars2use = c("dbaes_atotal","dbaes_btotal")

# compute Discovery mean and sd
ds_disc = Dverbal_Discovery[,vars2use[1]] - Dverbal_Discovery[,vars2use[2]]
mean2use = mean(ds_disc)
sd2use = sd(ds_disc)

Dverbal_Discovery = make_subtype(data2use = Dverbal_Discovery,
                                 z_thresh = z_thresh,
                                 mean2use = mean2use,
                                 sd2use = sd2use)

# compute Replication mean and sd
ds_rep = Dverbal_Replication[,vars2use[1]] - Dverbal_Replication[,vars2use[2]]
mean2use = mean(ds_rep)
sd2use = sd(ds_rep)

Dverbal_Replication = make_subtype(data2use = Dverbal_Replication,
                                 z_thresh = z_thresh,
                                 mean2use = mean2use,
                                 sd2use = sd2use)

#------------------------------------------------------------------------------
# Table of subtypes X sex

# Discovery
table(Dverbal_Discovery$z_ds_group,Dverbal_Discovery$sex)
cs_res = chisq.test(Dverbal_Discovery$z_ds_group,Dverbal_Discovery$sex)
cs_res

# Replication
table(Dverbal_Replication$z_ds_group,Dverbal_Replication$sex)
cs_res = chisq.test(Dverbal_Replication$z_ds_group,Dverbal_Replication$sex)
cs_res

#------------------------------------------------------------------------------
# Descriptive stats

# Discovery
df2use = Dverbal_Discovery[,c("subjectkey","dataset_id","collection_id","interview_age","sex","z_ds_group","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")]
df2use$age = df2use$interview_age/12

cols2use = c("z_ds_group","sex","age","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")
res=describeBy(x = df2use[,cols2use], group = "z_ds_group")
res

# Replication
df2use = Dverbal_Replication[,c("subjectkey","dataset_id","collection_id","interview_age","sex","z_ds_group","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")]
df2use$age = df2use$interview_age/12

cols2use = c("z_ds_group","sex","age","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")
res=describeBy(x = df2use[,cols2use], group = "z_ds_group")
res

#------------------------------------------------------------------------------
# Tests of differences in interview age across the subtypes

# Discovery
mod2use = lm(formula = interview_age ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = interview_age ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in SC across the subtypes

# Discovery
mod2use = lm(formula = dbaes_atotal ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = dbaes_atotal ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in RRB across the subtypes

# Discovery
mod2use = lm(formula = dbaes_btotal ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = dbaes_btotal ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in ADOS SA CSS across the subtypes

# Discovery
mod2use = lm(formula = ados_sa_css ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = ados_sa_css ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in ADOS RRB CSS across the subtypes

# Discovery
mod2use = lm(formula = ados_rrb_css ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = ados_rrb_css ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)


#------------------------------------------------------------------------------
# Tests of differences in IQ across the subtypes

# Discovery
mod2use = lm(formula = iq ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = iq ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)


#------------------------------------------------------------------------------
# Make scatterplots with difference score Z subtypes in different colors
maxScores = c(3,4)

p_disc = ggplot(data = Dverbal_Discovery, aes(x = dbaes_atotal, y = dbaes_btotal, colour = z_ds_group)) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,1) + xlim(0,1) + ggtitle("NDAR Discovery")
p1_top_left = p_disc + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Disc_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p1_top_left)
p_disc
table(Dverbal_Discovery$z_ds_group)

cor_res = cor.test(Dverbal_Discovery$dbaes_atotal, Dverbal_Discovery$dbaes_btotal)
cor_res

p_rep = ggplot(data = Dverbal_Replication, aes(x = dbaes_atotal, y = dbaes_btotal, colour = z_ds_group)) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,1) + xlim(0,1) +  ggtitle("NDAR Replication")
p2_bottom_left = p_rep + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Rep_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p2_bottom_left)
p_rep
table(Dverbal_Replication$z_ds_group)

cor_res = cor.test(Dverbal_Replication$dbaes_atotal, Dverbal_Replication$dbaes_btotal)
cor_res

#------------------------------------------------------------------------------
# Run supervised model with Discovery as training and Replication as Test

# run validation
# make subtypes using z-scores computed from the mean and sd of the training set
train_data = Dverbal_Discovery
test_data = Dverbal_Replication

mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]])
sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]])
tmp_train = make_subtype(data2use = train_data,
                         z_thresh = z_thresh,
                         mean2use = mean2use,
                         sd2use = sd2use)

mean2use = mean(test_data[,vars2use[1]] - test_data[,vars2use[2]])
sd2use = sd(test_data[,vars2use[1]] - test_data[,vars2use[2]])
tmp_test = make_subtype(data2use = test_data,
                        z_thresh = z_thresh,
                        mean2use = mean2use,
                        sd2use = sd2use)

#==============================================================================
#==============================================================================
# make labels based on train mean and sd
mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]])
sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]])
train_mean = mean2use
train_sd = sd2use

pred_labels = make_subtype(data2use = test_data,
                        z_thresh = z_thresh,
                        mean2use = train_mean,
                        sd2use = train_sd)
confmat = table(tmp_test$z_ds_group,pred_labels$z_ds_group)
acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/dim(pred_labels)[1]

# # compute model
# mod2use = svm(x = tmp_train[,vars2use], y = tmp_train$z_ds_group)
# pred_labels = predict(mod2use, tmp_test[,vars2use])
# confmat = table(tmp_test$z_ds_group,pred_labels)
# acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/length(pred_labels)
#==============================================================================
#==============================================================================

# plot confusion matrix
setHook("grid.newpage", function() pushViewport(viewport(x=1,y=1,width=0.9, height=0.9, name="vp", just=c("right","top"))), action="prepend")
pheatmap(confmat/rowSums(confmat)*100, display_numbers = confmat, color = colorRampPalette(c('white','red'))(100), cluster_rows = FALSE, cluster_cols = FALSE, fontsize_number = fontSize, fontsize_row = fontSize, fontsize_col = fontSize,labels_row = c("RRB>SC","SC=RRB","SC>RRB"),labels_col = c("RRB>SC","SC=RRB","SC>RRB"),angle_col=90,
         breaks= seq(0,100, length=100))
setHook("grid.newpage", NULL, "replace")
grid::grid.text("Actual Labels", y=-0.07, gp=gpar(fontsize=fontSize))
grid::grid.text("Predicted Labels", x=-0.07, rot=90, gp=gpar(fontsize=fontSize))


# show accuracy
true_accuracy = acc
true_accuracy

#================================================================================
#================================================================================
# #------------------------------------------------------------------------------
# # Permute subtype labels to examine how well supervised model performs
#
# # nperm = 10000
#
# # make subtypes using z-scores computed from the mean and sd of the training set
# train_data = Dverbal_Discovery
# test_data = Dverbal_Replication
# mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]])
# sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]])
# tmp_train = make_subtype(data2use = train_data,
#                          z_thresh = z_thresh,
#                          mean2use = mean2use,
#                          sd2use = sd2use)
#
# mean2use = mean(test_data[,vars2use[1]] - test_data[,vars2use[2]])
# sd2use = sd(test_data[,vars2use[1]] - test_data[,vars2use[2]])
# tmp_test = make_subtype(data2use = test_data,
#                         z_thresh = z_thresh,
#                         mean2use = mean2use,
#                         sd2use = sd2use)
#
# acc = vector(length = nperm)
# for (iperm in 1:nperm){
#   # set seed for reproducibility
#   set.seed(iperm)
#
#   sc_perm = sample(train_data[,vars2use[1]])
#   rrb_perm = sample(train_data[,vars2use[2]])
#   perm_mean2use = mean(sc_perm - rrb_perm)
#   perm_sd2use = sd(sc_perm - rrb_perm)
#   # perm_mean2use = mean(train_data[,vars2use[1]] - rrb_perm)
#   # perm_sd2use = sd(train_data[,vars2use[1]] - rrb_perm)
#   pred_labels = make_subtype(data2use = tmp_test,
#                         z_thresh = z_thresh,
#                         mean2use = perm_mean2use,
#                         sd2use = perm_sd2use)
#   confmat = table(tmp_test$z_ds_group,pred_labels$z_ds_group)
#   acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/dim(pred_labels)[1]
#
#   # compute model
#   permuted_labels = sample(tmp_train$z_ds_group)
#   mod2use = svm(x = tmp_train[,vars2use], y = permuted_labels)
#   pred_labels = predict(mod2use, tmp_test[,vars2use])
#   confmat = table(tmp_test$z_ds_group,pred_labels)
#   acc[iperm] = (confmat[1,1]+confmat[2,2]+confmat[3,3])/length(pred_labels)
#   #============================================================================
# } # for (iperm in 1:nperm)
#
# df2plot = data.frame(Accuracy = acc)
# p = ggplot(data = df2plot, aes(x = Accuracy)) + geom_histogram() + geom_vline(xintercept=true_accuracy)
# p
#
# # compute p-value
# pval = sum(c(true_accuracy,acc)>=true_accuracy)/(nperm+1)
# pval
#================================================================================
#================================================================================

#------------------------------------------------------------------------------
# Plot difference score Z subtypes in Discovery set
maxScores = c(3,4)

# Discovery - make plot with all individuals shown as lines
df2use = Dverbal_Discovery[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(tmp_train$z_ds_group)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$SC = df2use$dbaes_atotal
df2use$RRB = df2use$dbaes_btotal

df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"),
               measure.vars = c("SC","RRB"))

p = ggplot(data = df4plot, aes(x = variable,
                               y = value,
                               colour = subgrp,
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + ylim(0,1) + guides(color=FALSE)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
p3_middle_top = p + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Disc_jitterplot_z%s.pdf",as.character(z_thresh))), plot = p3_middle_top)
p

# Plot difference score Z subtypes in Replication set
maxScores = c(3,4)

# Replication - make plot with all individuals shown as lines
df2use = Dverbal_Replication[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(tmp_test$z_ds_group)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$SC = df2use$dbaes_atotal
df2use$RRB = df2use$dbaes_btotal

df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"),
               measure.vars = c("SC","RRB"))

p = ggplot(data = df4plot, aes(x = variable,
                               y = value,
                               colour = subgrp,
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + ylim(0,1) + guides(color=FALSE)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
p4_middle_bottom = p + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Rep_jitterplot_z%s.pdf",as.character(z_thresh))), plot = p4_middle_bottom)
p

#------------------------------------------------------------------------------
# Apply NDAR subtypes to EU-AIMS LEAP data

# make SC and RRB percentages since EU-AIMS data is specified as percentages
Dverbal = read.csv(file.path(datapath,"tidy_verbal.csv"))
euaims_data = read.csv(file.path(datapath,"tidy_euaims.csv"))
mask1 = euaims_data$Diagnosis=="ASD"
mask2 =  (is.na(euaims_data$A1_pct_severity) | is.na(euaims_data$A2_pct_severity) | is.na(euaims_data$A3_pct_severity) | is.na(euaims_data$B1_pct_severity) | is.na(euaims_data$B2_pct_severity) | is.na(euaims_data$B3_pct_severity) | is.na(euaims_data$B4_pct_severity))
euaims_data = subset(euaims_data, (mask1 & !mask2))

Dverbal[,vars2use[1]] = Dverbal[,vars2use[1]]
Dverbal[,vars2use[2]] = Dverbal[,vars2use[2]]
euaims_data[,vars2use[1]] = (euaims_data$A1_pct_severity +
                               euaims_data$A2_pct_severity +
                               euaims_data$A3_pct_severity)/3
euaims_data[,vars2use[2]] = (euaims_data$B1_pct_severity +
                               euaims_data$B2_pct_severity +
                               euaims_data$B3_pct_severity +
                               euaims_data$B4_pct_severity)/4

train_data = Dverbal
test_data = euaims_data

mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]], na.rm=TRUE)
sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]], na.rm=TRUE)
c(mean2use, sd2use)

tmp_train = make_subtype(data2use = train_data,
                         z_thresh = z_thresh,
                         mean2use = mean2use,
                         sd2use = sd2use)

tmp_test = make_subtype(data2use = test_data,
                        z_thresh = z_thresh,
                        mean2use = mean2use,
                        sd2use = sd2use)

#===========================================================================
#===========================================================================
# # compute model
# mod2use = svm(x = tmp_train[,vars2use], y = tmp_train$z_ds_group)
# pred_labels = predict(mod2use, tmp_test[,vars2use])
# confmat = table(tmp_test$z_ds_group,pred_labels)
# acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/length(pred_labels)
#
# tmp_test$svm_pred_labels = pred_labels
#
# # plot confusion matrix
# setHook("grid.newpage", function() pushViewport(viewport(x=1,y=1,width=0.9, height=0.9, name="vp", just=c("right","top"))), action="prepend")
# pheatmap(confmat/rowSums(confmat)*100, display_numbers = confmat, color = colorRampPalette(c('white','red'))(100), cluster_rows = FALSE, cluster_cols = FALSE, fontsize_number = fontSize, fontsize_row = fontSize, fontsize_col = fontSize,labels_row = c("RRB>SC","SC=RRB","SC>RRB"),labels_col = c("RRB>SC","SC=RRB","SC>RRB"),angle_col=90,
#          breaks= seq(0,100, length=100))
# setHook("grid.newpage", NULL, "replace")
# grid::grid.text("Actual Labels", y=-0.07, gp=gpar(fontsize=fontSize))
# grid::grid.text("Predicted Labels", x=-0.07, rot=90, gp=gpar(fontsize=fontSize))
#===========================================================================
#===========================================================================

# scatterplot
p1 = ggplot(data = tmp_train, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(z_ds_group))) + geom_point() + xlab("Social-Communication") + ylab("Restricted Repetitive Behaviors") + ylim(0,0.8) + xlim(0,0.8) + ggtitle("NDAR ALL")
p1

p2 = ggplot(data = tmp_test, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(z_ds_group))) + geom_point() + xlab("Social-Communication") + ylab("Restricted Repetitive Behaviors") + ylim(0,0.8) + xlim(0,0.8) + ggtitle("EU-AIMS with Groups from NDAR ALL")
p2

#===========================================================================
#===========================================================================
# p3 = ggplot(data = tmp_test, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(pred_labels))) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,0.8) + xlim(0,0.8) + ggtitle("EU-AIMS")
# p5_bottom_right = p3 + guides(colour=FALSE)
# ggsave(filename = file.path(plotpath, sprintf("final_EUAIMS_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p5_bottom_right)
# p3
#===========================================================================
#===========================================================================

# # write out EU-AIMS LEAP data with subgroups defined by NDAR All
write.csv(tmp_test, file.path(datapath, sprintf("tidy_euaims_NDAR_subtypes_diffscore_z%s.csv",as.character(z_thresh))))

#===========================================================================
#===========================================================================
# # Make final plot
# p_final = p1_top_left + p3_middle_top + plot_spacer() + p2_bottom_left + p4_middle_bottom + p5_bottom_right + plot_layout(nrow=3, ncol=3, widths = c(4,4,4), heights = c(8,8,8))
# ggsave(filename = file.path(plotpath, sprintf("final_NDAR_EUAIMS_subtypes_plot_z%s.pdf",as.character(z_thresh))), plot = p_final)
# p_final
#===========================================================================
#===========================================================================

#------------------------------------------------------------------------------
# Integrate subtypes with rest of EU-AIMS LEAP data
euaims_data = read.csv(file.path(datapath,"tidy_euaims.csv"))
td_df = subset(euaims_data, euaims_data$Diagnosis=="TD",select=2:6)
td_df$A_pct_severity = as.numeric(NA)
td_df$B_pct_severity = as.numeric(NA)
td_df$subgrp = "TD"

#===========================================================================
#===========================================================================
# cols2use = c("subid","age","Centre","Schedule","Diagnosis","dbaes_atotal","dbaes_btotal","svm_pred_labels")
cols2use = c("subid","age","Centre","Schedule","Diagnosis","dbaes_atotal","dbaes_btotal","z_ds_group")
#===========================================================================
#===========================================================================
tmp_asd = tmp_test[,cols2use]
colnames(tmp_asd)[6] = "A_pct_severity"
colnames(tmp_asd)[7] = "B_pct_severity"
colnames(tmp_asd)[8] = "subgrp"
asd_df = tmp_asd

all_data = rbind(td_df,asd_df)

fname = "/Users/mlombardo/Dropbox/euaims/data/rsfmri_preproc/euaims_preproc.xlsx"
pp_data = read_excel(fname)
mask = pp_data$notes=="ok"
pp_data = subset(pp_data, mask)

asd_df = merge(pp_data[,c("subid","sex")],asd_df, by = "subid")
td_df = merge(pp_data[,c("subid","sex")],td_df, by = "subid")

all_data = rbind(td_df,asd_df)

data2write = merge(pp_data, all_data, by = "subid")
data2write$age = data2write$age.x
data2write$sex = data2write$sex.y
print(table(data2write$Schedule, data2write$subgrp))
print(table(data2write$Centre, data2write$subgrp))
print(table(data2write$sex, data2write$subgrp))

#DSM-5 - find best split that balances participants across sites
a = findBestSplit(asd_df, seed_range = c(172342)) #,300001:500000))
best_seeds = a$seed[!is.na(a$discrepancy) & a$discrepancy==min(a$discrepancy, na.rm = TRUE)]
print(best_seeds)

# Split datasets -------------------------------------------------------------
rngSeed = best_seeds[1]

# split Schedule A dataset
dset2use = subset(asd_df, asd_df$Schedule=="A")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
A_Discovery = tmp_d[[2]]
A_Replication = tmp_d[[1]]

# split Schedule B dataset
dset2use = subset(asd_df, asd_df$Schedule=="B")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
B_Discovery = tmp_d[[2]]
B_Replication = tmp_d[[1]]

# split Schedule C dataset
dset2use = subset(asd_df, asd_df$Schedule=="C")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
C_Discovery = tmp_d[[2]]
C_Replication = tmp_d[[1]]

# split Schedule D dataset
dset2use = subset(asd_df, asd_df$Schedule=="D")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
D_Discovery = tmp_d[[2]]
D_Replication = tmp_d[[1]]

df_Disc = rbind(A_Discovery, B_Discovery, C_Discovery, D_Discovery)
df_Rep = rbind(A_Replication, B_Replication, C_Replication, D_Replication)

a = table(df_Disc$Schedule, df_Disc$Centre); print(a)
b = table(df_Rep$Schedule, df_Rep$Centre); print(b)
print(a-b)
print(sum(rowSums(abs(a-b))))

data2write$dataset = NA
mask  = is.element(data2write$subid,df_Disc$subid)
data2write[mask,"dataset"] = "Discovery"
mask  = is.element(data2write$subid,df_Rep$subid)
data2write[mask,"dataset"] = "Replication"

asd_Disc = subset(data2write, data2write$dataset=="Discovery" & data2write$Diagnosis=="ASD")
asd_Rep = subset(data2write, data2write$dataset=="Replication" & data2write$Diagnosis=="ASD")

# # find which seed gives best TD age-match -------------------------------------
# seeds = 1:1000
# pvals = data.frame(matrix(nrow = length(seeds), ncol = 2))
# for (i in 1:length(seeds)) {
#   res = findTDAgeMatch(data2write, seed_range = c(seeds[i],seeds[i]))
#   td_Disc_matched = res[[2]]
#   td_Rep_matched = res[[1]]
#   tres = t.test(td_Disc_matched$age, asd_Disc$age)
#   pvals[i,1] = tres$p.value
#   tres = t.test(td_Rep_matched$age, asd_Rep$age)
#   pvals[i,2] = tres$p.value
#   #print(i)
# }
# a = sort.int(pvals[,1], decreasing = TRUE, index.return = TRUE)
# b=pvals[a$ix,]

seed2use = 929
res = findTDAgeMatch(data2write, seed_range = c(seed2use,seed2use))
td_Disc_matched = res[[2]]
td_Rep_matched = res[[1]]

mask = is.element(data2write$subid, td_Disc_matched$subid)
data2write$dataset[mask] = "Discovery"

mask = is.element(data2write$subid, td_Rep_matched$subid)
data2write$dataset[mask] = "Replication"

print(table(data2write$dataset, data2write$subgrp))

fname2save = here(sprintf("asd_subgrp_data_rsfmri_ALL_DSM5_diffzscoreGrps_z%s.csv",as.character(z_thresh)))
write.csv(data2write,file = fname2save)

#------------------------------------------------------------------------------
# Descriptive stats
df2use = data2write[,c("subid","Diagnosis","dataset","Centre","meanFD","age","sex","subgrp","viq_all","piq_all","fsiq4_all","A_pct_severity","B_pct_severity","ADI_social_total","ADI_communication_total","ADI_RRB_total","ados_2_SA_CSS","ados_2_RRB_CSS","SRS_tscore","SRS_tscore_self","RBS_total","SSP_total","vabsdscoresc_dss","vabsdscoresd_dss","vabsdscoress_dss","vabsabcabc_standard")]
mask = df2use==999 | df2use==777
df2use[mask] = NA
df2use$age = df2use$age/365

cols2use = c("dataset","subgrp","age","meanFD","viq_all","piq_all","fsiq4_all","A_pct_severity","B_pct_severity","ADI_social_total","ADI_communication_total","ADI_RRB_total","ados_2_SA_CSS","ados_2_RRB_CSS","SRS_tscore","SRS_tscore_self","RBS_total","SSP_total","vabsdscoresc_dss","vabsdscoresd_dss","vabsdscoress_dss","vabsabcabc_standard")
res=describeBy(x = df2use[,cols2use], group = c("subgrp","dataset"))
res

#------------------------------------------------------------------------------
# Table of subtypes X sex

# Discovery
data2use = subset(data2write,data2write$dataset=="Discovery")
table(data2use$subgrp,data2use$sex)
cs_res = chisq.test(data2use$subgrp,data2use$sex)
cs_res

# Replication
data2use = subset(data2write,data2write$dataset=="Replication")
table(data2use$subgrp,data2use$sex)
cs_res = chisq.test(data2use$subgrp,data2use$sex)
cs_res

#------------------------------------------------------------------------------
vars2analyze = c("age","meanFD","viq_all","piq_all","fsiq4_all",
                 "A_pct_severity","B_pct_severity",
                 "ADI_social_total","ADI_communication_total","ADI_RRB_total",
                 "ados_2_SA_CSS","ados_2_RRB_CSS",
                 "SRS_tscore_self","RBS_total","SSP_total",
                 "vabsdscoress_dss","vabsdscoresd_dss","vabsdscoresc_dss","vabsabcabc_standard")

vnames = c("Age","Mean FD","VIQ","PIQ","FIQ","ADI-R SC","ADI-R RRB","ADI-R Social","ADI-R Communication","ADI-R RRB","ADOS SA CSS","ADOS RRB CSS","SRS","RBS","SSP","Vineland Socialization","Vineland Daily Living Skills","Vineland Communication","Vineland ABC")

cnames = c("All_Disc.fstat","All_Disc.pval","All_Rep.fstat","All_Rep.pval",
           "SCequalRRB_vs_SCoverRRB_Disc.fstat","SCequalRRB_vs_SCoverRRB_Disc.tstat",
           "SCequalRRB_vs_SCoverRRB_Disc.pval","SCequalRRB_vs_SCoverRRB_Disc.es",
           "SCequalRRB_vs_SCoverRRB_Rep.fstat","SCequalRRB_vs_SCoverRRB_Rep.tstat",
           "SCequalRRB_vs_SCoverRRB_Rep.pval","SCequalRRB_vs_SCoverRRB_Rep.es",
           "SCequalRRB_vs_SCoverRRB.repBF")

output_res = data.frame(matrix(nrow = length(vars2analyze),ncol = length(cnames)))
colnames(output_res) = cnames
rownames(output_res) = vars2analyze
output_res$varNames = vars2analyze

for (ivar in 1:length(vars2analyze)){

  y_var = vars2analyze[ivar]
  # print(y_var)
  #----------------------------------------------------------------------------
  # Discovery
  df4mod = subset(df2use, df2use$dataset=="Discovery")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"All_Disc.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"All_Disc.pval"] = res["subgrp","p-value"]

  #----------------------------------------------------------------------------
  # Replication
  df4mod = subset(df2use, df2use$dataset=="Replication")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"All_Rep.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"All_Rep.pval"] = res["subgrp","p-value"]

  #----------------------------------------------------------------------------
  # Discovery
  df4mod = subset(df2use, df2use$dataset=="Discovery" & !is.element(df2use$subgrp,c("TD","RRB_over_SC")))
  n1 = sum(df4mod$subgrp=="SC_equal_RRB")
  m1 = sum(df4mod$subgrp=="SC_over_RRB")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.pval"] = res["subgrp","p-value"]
  res = summary(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.tstat"] = res$tTable[2,"t-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.es"] = cohens_d(df4mod[df4mod$subgrp=="SC_equal_RRB",y_var],
                                                                 df4mod[df4mod$subgrp=="SC_over_RRB",y_var])

  #----------------------------------------------------------------------------
  # Replication
  df4mod = subset(df2use, df2use$dataset=="Replication" & !is.element(df2use$subgrp,c("TD","RRB_over_SC")))
  n2 = sum(df4mod$subgrp=="SC_equal_RRB")
  m2 = sum(df4mod$subgrp=="SC_over_RRB")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.pval"] = res["subgrp","p-value"]
  res = summary(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.tstat"] = res$tTable[2,"t-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.es"] = cohens_d(df4mod[df4mod$subgrp=="SC_equal_RRB",y_var],
                                                                 df4mod[df4mod$subgrp=="SC_over_RRB",y_var])

  #----------------------------------------------------------------------------
  # Replication Bayes Factor
  res_bf = BFSALL(tobs = output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.tstat"],
                  trep = output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.tstat"],
                  n1 = n1,
                  n2 = n2,
                  m1 = m1,
                  m2 = m2,
                  sample = 2,
                  Type = 'ALL')
  output_res[y_var,"SCequalRRB_vs_SCoverRRB.repBF"] = res_bf["Replication BF","Replication 1"]

  # make a plot
  colors2use = get_ggColorHue(3)
  df4plot = subset(df2use, df2use$subgrp!="RRB_over_SC")
  p = ggplot(data = df4plot, aes_string(x = "subgrp", y = y_var, colour = "subgrp")) + facet_grid(. ~ dataset)
  p = p + geom_jitter() + geom_boxplot(fill = NA, colour = "#000000", outlier.shape = NA)
  p = p + ylab(vnames[ivar]) + xlab("Group") +
    scale_x_discrete(labels=c("SC_equal_RRB"="SC=RRB","SC_over_RRB"="SC>RRB","TD"="TD")) +
                       scale_colour_manual(values = c(colors2use[2:3],"grey60")) + guides(colour=FALSE) +
    theme(text = element_text(size=fontSize-5),
        axis.text.x = element_text(size=fontSize-5),
        axis.text.y = element_text(size=fontSize-5))
  print(p)

}
vabc["0.9","Discovery"] = output_res["vabsabcabc_standard","SCequalRRB_vs_SCoverRRB_Disc.es"]
vabc["0.9","Replication"] = output_res["vabsabcabc_standard","SCequalRRB_vs_SCoverRRB_Rep.es"]
vabc_dls["0.9","Discovery"] = output_res["vabsdscoresd_dss","SCequalRRB_vs_SCoverRRB_Disc.es"]
vabc_dls["0.9","Replication"] = output_res["vabsdscoresd_dss","SCequalRRB_vs_SCoverRRB_Rep.es"]
output_res
```

## SC-RRB difference z = 1

```{r, warning=FALSE, message=FALSE}
#------------------------------------------------------------------------------
# Z-score threshold to use for subtyping
z_thresh = 1

# vars2use = c("dbaes_atotal","dbaes_btotal")

# compute Discovery mean and sd
ds_disc = Dverbal_Discovery[,vars2use[1]] - Dverbal_Discovery[,vars2use[2]]
mean2use = mean(ds_disc)
sd2use = sd(ds_disc)

Dverbal_Discovery = make_subtype(data2use = Dverbal_Discovery,
                                 z_thresh = z_thresh,
                                 mean2use = mean2use,
                                 sd2use = sd2use)

# compute Replication mean and sd
ds_rep = Dverbal_Replication[,vars2use[1]] - Dverbal_Replication[,vars2use[2]]
mean2use = mean(ds_rep)
sd2use = sd(ds_rep)

Dverbal_Replication = make_subtype(data2use = Dverbal_Replication,
                                 z_thresh = z_thresh,
                                 mean2use = mean2use,
                                 sd2use = sd2use)

#------------------------------------------------------------------------------
# Table of subtypes X sex

# Discovery
table(Dverbal_Discovery$z_ds_group,Dverbal_Discovery$sex)
cs_res = chisq.test(Dverbal_Discovery$z_ds_group,Dverbal_Discovery$sex)
cs_res

# Replication
table(Dverbal_Replication$z_ds_group,Dverbal_Replication$sex)
cs_res = chisq.test(Dverbal_Replication$z_ds_group,Dverbal_Replication$sex)
cs_res

#------------------------------------------------------------------------------
# Descriptive stats

# Discovery
df2use = Dverbal_Discovery[,c("subjectkey","dataset_id","collection_id","interview_age","sex","z_ds_group","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")]
df2use$age = df2use$interview_age/12

cols2use = c("z_ds_group","sex","age","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")
res=describeBy(x = df2use[,cols2use], group = "z_ds_group")
res

# Replication
df2use = Dverbal_Replication[,c("subjectkey","dataset_id","collection_id","interview_age","sex","z_ds_group","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")]
df2use$age = df2use$interview_age/12

cols2use = c("z_ds_group","sex","age","ados_age","ados_sa_css","ados_rrb_css","iq","dbaes_atotal","dbaes_btotal")
res=describeBy(x = df2use[,cols2use], group = "z_ds_group")
res

#------------------------------------------------------------------------------
# Tests of differences in interview age across the subtypes

# Discovery
mod2use = lm(formula = interview_age ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = interview_age ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in SC across the subtypes

# Discovery
mod2use = lm(formula = dbaes_atotal ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = dbaes_atotal ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in RRB across the subtypes

# Discovery
mod2use = lm(formula = dbaes_btotal ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = dbaes_btotal ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in ADOS SA CSS across the subtypes

# Discovery
mod2use = lm(formula = ados_sa_css ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = ados_sa_css ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)

#------------------------------------------------------------------------------
# Tests of differences in ADOS RRB CSS across the subtypes

# Discovery
mod2use = lm(formula = ados_rrb_css ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = ados_rrb_css ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)


#------------------------------------------------------------------------------
# Tests of differences in IQ across the subtypes

# Discovery
mod2use = lm(formula = iq ~ z_ds_group, data = Dverbal_Discovery)
anova(mod2use)

# Replication
mod2use = lm(formula = iq ~ z_ds_group, data = Dverbal_Replication)
anova(mod2use)


#------------------------------------------------------------------------------
# Make scatterplots with difference score Z subtypes in different colors
maxScores = c(3,4)

p_disc = ggplot(data = Dverbal_Discovery, aes(x = dbaes_atotal, y = dbaes_btotal, colour = z_ds_group)) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,1) + xlim(0,1) + ggtitle("NDAR Discovery")
p1_top_left = p_disc + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Disc_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p1_top_left)
p_disc
table(Dverbal_Discovery$z_ds_group)

cor_res = cor.test(Dverbal_Discovery$dbaes_atotal, Dverbal_Discovery$dbaes_btotal)
cor_res

p_rep = ggplot(data = Dverbal_Replication, aes(x = dbaes_atotal, y = dbaes_btotal, colour = z_ds_group)) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,1) + xlim(0,1) +  ggtitle("NDAR Replication")
p2_bottom_left = p_rep + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Rep_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p2_bottom_left)
p_rep
table(Dverbal_Replication$z_ds_group)

cor_res = cor.test(Dverbal_Replication$dbaes_atotal, Dverbal_Replication$dbaes_btotal)
cor_res

#------------------------------------------------------------------------------
# Run supervised model with Discovery as training and Replication as Test

# run validation
# make subtypes using z-scores computed from the mean and sd of the training set
train_data = Dverbal_Discovery
test_data = Dverbal_Replication

mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]])
sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]])
tmp_train = make_subtype(data2use = train_data,
                         z_thresh = z_thresh,
                         mean2use = mean2use,
                         sd2use = sd2use)

mean2use = mean(test_data[,vars2use[1]] - test_data[,vars2use[2]])
sd2use = sd(test_data[,vars2use[1]] - test_data[,vars2use[2]])
tmp_test = make_subtype(data2use = test_data,
                        z_thresh = z_thresh,
                        mean2use = mean2use,
                        sd2use = sd2use)

#==============================================================================
#==============================================================================
# make labels based on train mean and sd
mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]])
sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]])
train_mean = mean2use
train_sd = sd2use

pred_labels = make_subtype(data2use = test_data,
                        z_thresh = z_thresh,
                        mean2use = train_mean,
                        sd2use = train_sd)
confmat = table(tmp_test$z_ds_group,pred_labels$z_ds_group)
acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/dim(pred_labels)[1]

# # compute model
# mod2use = svm(x = tmp_train[,vars2use], y = tmp_train$z_ds_group)
# pred_labels = predict(mod2use, tmp_test[,vars2use])
# confmat = table(tmp_test$z_ds_group,pred_labels)
# acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/length(pred_labels)
#==============================================================================
#==============================================================================

# plot confusion matrix
setHook("grid.newpage", function() pushViewport(viewport(x=1,y=1,width=0.9, height=0.9, name="vp", just=c("right","top"))), action="prepend")
pheatmap(confmat/rowSums(confmat)*100, display_numbers = confmat, color = colorRampPalette(c('white','red'))(100), cluster_rows = FALSE, cluster_cols = FALSE, fontsize_number = fontSize, fontsize_row = fontSize, fontsize_col = fontSize,labels_row = c("RRB>SC","SC=RRB","SC>RRB"),labels_col = c("RRB>SC","SC=RRB","SC>RRB"),angle_col=90,
         breaks= seq(0,100, length=100))
setHook("grid.newpage", NULL, "replace")
grid::grid.text("Actual Labels", y=-0.07, gp=gpar(fontsize=fontSize))
grid::grid.text("Predicted Labels", x=-0.07, rot=90, gp=gpar(fontsize=fontSize))


# show accuracy
true_accuracy = acc
true_accuracy

#================================================================================
#================================================================================
# #------------------------------------------------------------------------------
# # Permute subtype labels to examine how well supervised model performs
#
# # nperm = 10000
#
# # make subtypes using z-scores computed from the mean and sd of the training set
# train_data = Dverbal_Discovery
# test_data = Dverbal_Replication
# mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]])
# sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]])
# tmp_train = make_subtype(data2use = train_data,
#                          z_thresh = z_thresh,
#                          mean2use = mean2use,
#                          sd2use = sd2use)
#
# mean2use = mean(test_data[,vars2use[1]] - test_data[,vars2use[2]])
# sd2use = sd(test_data[,vars2use[1]] - test_data[,vars2use[2]])
# tmp_test = make_subtype(data2use = test_data,
#                         z_thresh = z_thresh,
#                         mean2use = mean2use,
#                         sd2use = sd2use)
#
# acc = vector(length = nperm)
# for (iperm in 1:nperm){
#   # set seed for reproducibility
#   set.seed(iperm)
#
#   sc_perm = sample(train_data[,vars2use[1]])
#   rrb_perm = sample(train_data[,vars2use[2]])
#   perm_mean2use = mean(sc_perm - rrb_perm)
#   perm_sd2use = sd(sc_perm - rrb_perm)
#   # perm_mean2use = mean(train_data[,vars2use[1]] - rrb_perm)
#   # perm_sd2use = sd(train_data[,vars2use[1]] - rrb_perm)
#   pred_labels = make_subtype(data2use = tmp_test,
#                         z_thresh = z_thresh,
#                         mean2use = perm_mean2use,
#                         sd2use = perm_sd2use)
#   confmat = table(tmp_test$z_ds_group,pred_labels$z_ds_group)
#   acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/dim(pred_labels)[1]
#
#   # compute model
#   permuted_labels = sample(tmp_train$z_ds_group)
#   mod2use = svm(x = tmp_train[,vars2use], y = permuted_labels)
#   pred_labels = predict(mod2use, tmp_test[,vars2use])
#   confmat = table(tmp_test$z_ds_group,pred_labels)
#   acc[iperm] = (confmat[1,1]+confmat[2,2]+confmat[3,3])/length(pred_labels)
#   #============================================================================
# } # for (iperm in 1:nperm)
#
# df2plot = data.frame(Accuracy = acc)
# p = ggplot(data = df2plot, aes(x = Accuracy)) + geom_histogram() + geom_vline(xintercept=true_accuracy)
# p
#
# # compute p-value
# pval = sum(c(true_accuracy,acc)>=true_accuracy)/(nperm+1)
# pval
#================================================================================
#================================================================================

#------------------------------------------------------------------------------
# Plot difference score Z subtypes in Discovery set
maxScores = c(3,4)

# Discovery - make plot with all individuals shown as lines
df2use = Dverbal_Discovery[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(tmp_train$z_ds_group)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$SC = df2use$dbaes_atotal
df2use$RRB = df2use$dbaes_btotal

df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"),
               measure.vars = c("SC","RRB"))

p = ggplot(data = df4plot, aes(x = variable,
                               y = value,
                               colour = subgrp,
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + ylim(0,1) + guides(color=FALSE)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
p3_middle_top = p + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Disc_jitterplot_z%s.pdf",as.character(z_thresh))), plot = p3_middle_top)
p

# Plot difference score Z subtypes in Replication set
maxScores = c(3,4)

# Replication - make plot with all individuals shown as lines
df2use = Dverbal_Replication[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(tmp_test$z_ds_group)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$SC = df2use$dbaes_atotal
df2use$RRB = df2use$dbaes_btotal

df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"),
               measure.vars = c("SC","RRB"))

p = ggplot(data = df4plot, aes(x = variable,
                               y = value,
                               colour = subgrp,
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + ylim(0,1) + guides(color=FALSE)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
p4_middle_bottom = p + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_NDAR_Rep_jitterplot_z%s.pdf",as.character(z_thresh))), plot = p4_middle_bottom)
p

#------------------------------------------------------------------------------
# Apply NDAR subtypes to EU-AIMS LEAP data

# make SC and RRB percentages since EU-AIMS data is specified as percentages
Dverbal = read.csv(file.path(datapath,"tidy_verbal.csv"))
euaims_data = read.csv(file.path(datapath,"tidy_euaims.csv"))
mask1 = euaims_data$Diagnosis=="ASD"
mask2 =  (is.na(euaims_data$A1_pct_severity) | is.na(euaims_data$A2_pct_severity) | is.na(euaims_data$A3_pct_severity) | is.na(euaims_data$B1_pct_severity) | is.na(euaims_data$B2_pct_severity) | is.na(euaims_data$B3_pct_severity) | is.na(euaims_data$B4_pct_severity))
euaims_data = subset(euaims_data, (mask1 & !mask2))

Dverbal[,vars2use[1]] = Dverbal[,vars2use[1]]
Dverbal[,vars2use[2]] = Dverbal[,vars2use[2]]
euaims_data[,vars2use[1]] = (euaims_data$A1_pct_severity +
                               euaims_data$A2_pct_severity +
                               euaims_data$A3_pct_severity)/3
euaims_data[,vars2use[2]] = (euaims_data$B1_pct_severity +
                               euaims_data$B2_pct_severity +
                               euaims_data$B3_pct_severity +
                               euaims_data$B4_pct_severity)/4

train_data = Dverbal
test_data = euaims_data

mean2use = mean(train_data[,vars2use[1]] - train_data[,vars2use[2]], na.rm=TRUE)
sd2use = sd(train_data[,vars2use[1]] - train_data[,vars2use[2]], na.rm=TRUE)
c(mean2use, sd2use)

tmp_train = make_subtype(data2use = train_data,
                         z_thresh = z_thresh,
                         mean2use = mean2use,
                         sd2use = sd2use)

tmp_test = make_subtype(data2use = test_data,
                        z_thresh = z_thresh,
                        mean2use = mean2use,
                        sd2use = sd2use)

#===========================================================================
#===========================================================================
# # compute model
# mod2use = svm(x = tmp_train[,vars2use], y = tmp_train$z_ds_group)
# pred_labels = predict(mod2use, tmp_test[,vars2use])
# confmat = table(tmp_test$z_ds_group,pred_labels)
# acc = (confmat[1,1]+confmat[2,2]+confmat[3,3])/length(pred_labels)
#
# tmp_test$svm_pred_labels = pred_labels
#
# # plot confusion matrix
# setHook("grid.newpage", function() pushViewport(viewport(x=1,y=1,width=0.9, height=0.9, name="vp", just=c("right","top"))), action="prepend")
# pheatmap(confmat/rowSums(confmat)*100, display_numbers = confmat, color = colorRampPalette(c('white','red'))(100), cluster_rows = FALSE, cluster_cols = FALSE, fontsize_number = fontSize, fontsize_row = fontSize, fontsize_col = fontSize,labels_row = c("RRB>SC","SC=RRB","SC>RRB"),labels_col = c("RRB>SC","SC=RRB","SC>RRB"),angle_col=90,
#          breaks= seq(0,100, length=100))
# setHook("grid.newpage", NULL, "replace")
# grid::grid.text("Actual Labels", y=-0.07, gp=gpar(fontsize=fontSize))
# grid::grid.text("Predicted Labels", x=-0.07, rot=90, gp=gpar(fontsize=fontSize))
#===========================================================================
#===========================================================================

# scatterplot
p1 = ggplot(data = tmp_train, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(z_ds_group))) + geom_point() + xlab("Social-Communication") + ylab("Restricted Repetitive Behaviors") + ylim(0,1) + xlim(0,1) + ggtitle("NDAR ALL")
p1

p2 = ggplot(data = tmp_test, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(z_ds_group))) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,1) + xlim(0,1) + ggtitle("EU-AIMS with Groups from NDAR ALL") +
  theme(text = element_text(size=fontSize),
        axis.text.x = element_text(size=fontSize),
        axis.text.y = element_text(size=fontSize))
p5_bottom_right = p2 + guides(colour=FALSE)
ggsave(filename = file.path(plotpath, sprintf("final_EUAIMS_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p5_bottom_right)
p2

#===========================================================================
#===========================================================================
# p3 = ggplot(data = tmp_test, aes(x = dbaes_atotal, y = dbaes_btotal, colour = factor(pred_labels))) + geom_point() + xlab("SC") + ylab("RRB") + ylim(0,0.8) + xlim(0,0.8) + ggtitle("EU-AIMS")
# p5_bottom_right = p3 + guides(colour=FALSE)
# ggsave(filename = file.path(plotpath, sprintf("final_EUAIMS_scatterplot_z%s.pdf",as.character(z_thresh))), plot = p5_bottom_right)
# p3
#===========================================================================
#===========================================================================

# # write out EU-AIMS LEAP data with subgroups defined by NDAR All
write.csv(tmp_test, file.path(datapath, sprintf("tidy_euaims_NDAR_subtypes_diffscore_z%s.csv",as.character(z_thresh))))

#===========================================================================
#===========================================================================
# # Make final plot
# p_final = p1_top_left + p3_middle_top + plot_spacer() + p2_bottom_left + p4_middle_bottom + p5_bottom_right + plot_layout(nrow=3, ncol=3, widths = c(4,4,4), heights = c(8,8,8))
# ggsave(filename = file.path(plotpath, sprintf("final_NDAR_EUAIMS_subtypes_plot_z%s.pdf",as.character(z_thresh))), plot = p_final)
# p_final
#===========================================================================
#===========================================================================

#------------------------------------------------------------------------------
# Integrate subtypes with rest of EU-AIMS LEAP data
euaims_data = read.csv(file.path(datapath,"tidy_euaims.csv"))
td_df = subset(euaims_data, euaims_data$Diagnosis=="TD",select=2:6)
td_df$A_pct_severity = as.numeric(NA)
td_df$B_pct_severity = as.numeric(NA)
td_df$subgrp = "TD"

#===========================================================================
#===========================================================================
# cols2use = c("subid","age","Centre","Schedule","Diagnosis","dbaes_atotal","dbaes_btotal","svm_pred_labels")
cols2use = c("subid","age","Centre","Schedule","Diagnosis","dbaes_atotal","dbaes_btotal","z_ds_group")
#===========================================================================
#===========================================================================
tmp_asd = tmp_test[,cols2use]
colnames(tmp_asd)[6] = "A_pct_severity"
colnames(tmp_asd)[7] = "B_pct_severity"
colnames(tmp_asd)[8] = "subgrp"
asd_df = tmp_asd

all_data = rbind(td_df,asd_df)

fname = "/Users/mlombardo/Dropbox/euaims/data/rsfmri_preproc/euaims_preproc.xlsx"
pp_data = read_excel(fname)
mask = pp_data$notes=="ok"
pp_data = subset(pp_data, mask)

asd_df = merge(pp_data[,c("subid","sex")],asd_df, by = "subid")
td_df = merge(pp_data[,c("subid","sex")],td_df, by = "subid")

all_data = rbind(td_df,asd_df)

data2write = merge(pp_data, all_data, by = "subid")
data2write$age = data2write$age.x
data2write$sex = data2write$sex.y
print(table(data2write$Schedule, data2write$subgrp))
print(table(data2write$Centre, data2write$subgrp))
print(table(data2write$sex, data2write$subgrp))

#DSM-5 - find best split that balances participants across sites
a = findBestSplit(asd_df, seed_range = c(172342)) #,300001:500000))
best_seeds = a$seed[!is.na(a$discrepancy) & a$discrepancy==min(a$discrepancy, na.rm = TRUE)]
print(best_seeds)

# Split datasets -------------------------------------------------------------
rngSeed = best_seeds[1]

# split Schedule A dataset
dset2use = subset(asd_df, asd_df$Schedule=="A")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
A_Discovery = tmp_d[[2]]
A_Replication = tmp_d[[1]]

# split Schedule B dataset
dset2use = subset(asd_df, asd_df$Schedule=="B")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
B_Discovery = tmp_d[[2]]
B_Replication = tmp_d[[1]]

# split Schedule C dataset
dset2use = subset(asd_df, asd_df$Schedule=="C")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
C_Discovery = tmp_d[[2]]
C_Replication = tmp_d[[1]]

# split Schedule D dataset
dset2use = subset(asd_df, asd_df$Schedule=="D")
tmp_d = SplitDatasetsBySex(dset2use, rngSeed = rngSeed)
D_Discovery = tmp_d[[2]]
D_Replication = tmp_d[[1]]

df_Disc = rbind(A_Discovery, B_Discovery, C_Discovery, D_Discovery)
df_Rep = rbind(A_Replication, B_Replication, C_Replication, D_Replication)

a = table(df_Disc$Schedule, df_Disc$Centre); print(a)
b = table(df_Rep$Schedule, df_Rep$Centre); print(b)
print(a-b)
print(sum(rowSums(abs(a-b))))

data2write$dataset = NA
mask  = is.element(data2write$subid,df_Disc$subid)
data2write[mask,"dataset"] = "Discovery"
mask  = is.element(data2write$subid,df_Rep$subid)
data2write[mask,"dataset"] = "Replication"

asd_Disc = subset(data2write, data2write$dataset=="Discovery" & data2write$Diagnosis=="ASD")
asd_Rep = subset(data2write, data2write$dataset=="Replication" & data2write$Diagnosis=="ASD")

# # find which seed gives best TD age-match -------------------------------------
# seeds = 1:1000
# pvals = data.frame(matrix(nrow = length(seeds), ncol = 2))
# for (i in 1:length(seeds)) {
#   res = findTDAgeMatch(data2write, seed_range = c(seeds[i],seeds[i]))
#   td_Disc_matched = res[[2]]
#   td_Rep_matched = res[[1]]
#   tres = t.test(td_Disc_matched$age, asd_Disc$age)
#   pvals[i,1] = tres$p.value
#   tres = t.test(td_Rep_matched$age, asd_Rep$age)
#   pvals[i,2] = tres$p.value
#   #print(i)
# }
# a = sort.int(pvals[,1], decreasing = TRUE, index.return = TRUE)
# b=pvals[a$ix,]

seed2use = 929
res = findTDAgeMatch(data2write, seed_range = c(seed2use,seed2use))
td_Disc_matched = res[[2]]
td_Rep_matched = res[[1]]

mask = is.element(data2write$subid, td_Disc_matched$subid)
data2write$dataset[mask] = "Discovery"

mask = is.element(data2write$subid, td_Rep_matched$subid)
data2write$dataset[mask] = "Replication"

print(table(data2write$dataset, data2write$subgrp))

fname2save = here(sprintf("asd_subgrp_data_rsfmri_ALL_DSM5_diffzscoreGrps_z%s.csv",as.character(z_thresh)))
write.csv(data2write,file = fname2save)


#------------------------------------------------------------------------------
# Descriptive stats
df2use = data2write[,c("subid","Diagnosis","dataset","Centre","meanFD","age","sex","subgrp","viq_all","piq_all","fsiq4_all","A_pct_severity","B_pct_severity","ADI_social_total","ADI_communication_total","ADI_RRB_total","ados_2_SA_CSS","ados_2_RRB_CSS","SRS_tscore","SRS_tscore_self","RBS_total","SSP_total","vabsdscoresc_dss","vabsdscoresd_dss","vabsdscoress_dss","vabsabcabc_standard")]
mask = df2use==999 | df2use==777
df2use[mask] = NA
df2use$age = df2use$age/365

cols2use = c("dataset","subgrp","age","meanFD","viq_all","piq_all","fsiq4_all","A_pct_severity","B_pct_severity","ADI_social_total","ADI_communication_total","ADI_RRB_total","ados_2_SA_CSS","ados_2_RRB_CSS","SRS_tscore","SRS_tscore_self","RBS_total","SSP_total","vabsdscoresc_dss","vabsdscoresd_dss","vabsdscoress_dss","vabsabcabc_standard")
res=describeBy(x = df2use[,cols2use], group = c("subgrp","dataset"))
res

#------------------------------------------------------------------------------
# Table of subtypes X sex

# Discovery
data2use = subset(data2write,data2write$dataset=="Discovery")
table(data2use$subgrp,data2use$sex)
cs_res = chisq.test(data2use$subgrp,data2use$sex)
cs_res

# Replication
data2use = subset(data2write,data2write$dataset=="Replication")
table(data2use$subgrp,data2use$sex)
cs_res = chisq.test(data2use$subgrp,data2use$sex)
cs_res

#------------------------------------------------------------------------------
vars2analyze = c("age","meanFD","viq_all","piq_all","fsiq4_all",
                 "A_pct_severity","B_pct_severity",
                 "ADI_social_total","ADI_communication_total","ADI_RRB_total",
                 "ados_2_SA_CSS","ados_2_RRB_CSS",
                 "SRS_tscore_self","RBS_total","SSP_total",
                 "vabsdscoress_dss","vabsdscoresd_dss","vabsdscoresc_dss","vabsabcabc_standard")

vnames = c("Age","Mean FD","VIQ","PIQ","FIQ","ADI-R SC","ADI-R RRB","ADI-R Social","ADI-R Communication","ADI-R RRB","ADOS SA CSS","ADOS RRB CSS","SRS","RBS","SSP","Vineland Socialization","Vineland Daily Living Skills","Vineland Communication","Vineland ABC")

cnames = c("All_Disc.fstat","All_Disc.pval","All_Rep.fstat","All_Rep.pval",
           "SCequalRRB_vs_SCoverRRB_Disc.fstat","SCequalRRB_vs_SCoverRRB_Disc.tstat",
           "SCequalRRB_vs_SCoverRRB_Disc.pval","SCequalRRB_vs_SCoverRRB_Disc.es",
           "SCequalRRB_vs_SCoverRRB_Rep.fstat","SCequalRRB_vs_SCoverRRB_Rep.tstat",
           "SCequalRRB_vs_SCoverRRB_Rep.pval","SCequalRRB_vs_SCoverRRB_Rep.es",
           "SCequalRRB_vs_SCoverRRB.repBF")

output_res = data.frame(matrix(nrow = length(vars2analyze),ncol = length(cnames)))
colnames(output_res) = cnames
rownames(output_res) = vars2analyze
output_res$varNames = vars2analyze

for (ivar in 1:length(vars2analyze)){

  y_var = vars2analyze[ivar]
  # print(y_var)
  #----------------------------------------------------------------------------
  # Discovery
  df4mod = subset(df2use, df2use$dataset=="Discovery")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"All_Disc.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"All_Disc.pval"] = res["subgrp","p-value"]

  #----------------------------------------------------------------------------
  # Replication
  df4mod = subset(df2use, df2use$dataset=="Replication")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"All_Rep.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"All_Rep.pval"] = res["subgrp","p-value"]

  #----------------------------------------------------------------------------
  # Discovery
  df4mod = subset(df2use, df2use$dataset=="Discovery" & !is.element(df2use$subgrp,c("TD","RRB_over_SC")))
  n1 = sum(df4mod$subgrp=="SC_equal_RRB")
  m1 = sum(df4mod$subgrp=="SC_over_RRB")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.pval"] = res["subgrp","p-value"]
  res = summary(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.tstat"] = res$tTable[2,"t-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.es"] = cohens_d(df4mod[df4mod$subgrp=="SC_equal_RRB",y_var],
                                                                 df4mod[df4mod$subgrp=="SC_over_RRB",y_var])

  #----------------------------------------------------------------------------
  # Replication
  df4mod = subset(df2use, df2use$dataset=="Replication" & !is.element(df2use$subgrp,c("TD","RRB_over_SC")))
  n2 = sum(df4mod$subgrp=="SC_equal_RRB")
  m2 = sum(df4mod$subgrp=="SC_over_RRB")

  # construct linear model
  # mixed-effect model: site as random factor, all other covariates as fixed factors
  fx_form = as.formula(sprintf("%s ~ %s",y_var,"subgrp"))
  rx_form = as.formula(sprintf("~ 1|%s","Centre"))
  mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

  # run ANOVA
  res = anova(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.fstat"] = res["subgrp","F-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.pval"] = res["subgrp","p-value"]
  res = summary(mod2use)
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.tstat"] = res$tTable[2,"t-value"]
  output_res[y_var,"SCequalRRB_vs_SCoverRRB_Rep.es"] = cohens_d(df4mod[df4mod$subgrp=="SC_equal_RRB",y_var],
                                                                 df4mod[df4mod$subgrp=="SC_over_RRB",y_var])

  #----------------------------------------------------------------------------
  # Replication Bayes Factor
  res_bf = BFSALL(tobs = output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.tstat"],
                  trep = output_res[y_var,"SCequalRRB_vs_SCoverRRB_Disc.tstat"],
                  n1 = n1,
                  n2 = n2,
                  m1 = m1,
                  m2 = m2,
                  sample = 2,
                  Type = 'ALL')
  output_res[y_var,"SCequalRRB_vs_SCoverRRB.repBF"] = res_bf["Replication BF","Replication 1"]

  # make a plot
  colors2use = get_ggColorHue(3)
  df4plot = subset(df2use, df2use$subgrp!="RRB_over_SC")
  p = ggplot(data = df4plot, aes_string(x = "subgrp", y = y_var, colour = "subgrp")) + facet_grid(. ~ dataset)
  p = p + geom_jitter() + geom_boxplot(fill = NA, colour = "#000000", outlier.shape = NA)
  p = p + ylab(vnames[ivar]) + xlab("Group") +
    scale_x_discrete(labels=c("SC_equal_RRB"="SC=RRB","SC_over_RRB"="SC>RRB","TD"="TD")) +
                       scale_colour_manual(values = c(colors2use[2:3],"grey60")) + guides(colour=FALSE) +
    theme(text = element_text(size=fontSize-5),
        axis.text.x = element_text(size=fontSize-5),
        axis.text.y = element_text(size=fontSize-5))
  print(p)

}
vabc["1","Discovery"] = output_res["vabsabcabc_standard","SCequalRRB_vs_SCoverRRB_Disc.es"]
vabc["1","Replication"] = output_res["vabsabcabc_standard","SCequalRRB_vs_SCoverRRB_Rep.es"]
vabc_dls["1","Discovery"] = output_res["vabsdscoresd_dss","SCequalRRB_vs_SCoverRRB_Disc.es"]
vabc_dls["1","Replication"] = output_res["vabsdscoresd_dss","SCequalRRB_vs_SCoverRRB_Rep.es"]
output_res

# # plot Vineland ABC effect sizes over thresholds
# tmp = data.frame(vabc)
# tmp$threshold = factor(rownames(tmp))
#
# df2plot = melt(tmp)
# p = ggplot(data = df2plot, aes(x = threshold, y =value, color=variable, group=variable)) + facet_grid(. ~ variable)
# p = p + geom_line(size=4) +
#   geom_point(size=7) +
#   ylab("Cohen's d") +
#   xlab("Z-threshold") +
#   ylim(0,1) +
#   guides(color=FALSE) +
#   theme(text = element_text(size=fontSize),
#         axis.text.x = element_text(size=fontSize),
#         axis.text.y = element_text(size=fontSize))
# p
```

# Vineland ABC

```{r, warning=FALSE, message=FALSE}
# plot Vineland ABC effect sizes over thresholds
tmp = data.frame(vabc)
tmp$threshold = factor(rownames(tmp))

df2plot = melt(tmp)
p = ggplot(data = df2plot, aes(x = threshold, y =value, color=variable, group=variable)) + facet_grid(. ~ variable)
p = p + geom_line(size=4) +
  geom_point(size=7) +
  ylab("Cohen's d") +
  xlab("Z-threshold") +
  ylim(0,1) + scale_colour_manual(values = c("dodger blue","#ff8d1e")) +
  guides(color=FALSE) +
  theme(text = element_text(size=fontSize),
        axis.text.x = element_text(size=fontSize),
        axis.text.y = element_text(size=fontSize))
p

#------------------------------------------------------------------------------
# model effect of z difference score on Vineland ABC
y_var = "vabsabcabc_standard"

# Discovery
df4mod = subset(data2write, data2write$dataset=="Discovery")
df4mod = merge(df4mod,tmp_test[,c("subid","z_ds")],by.x="subid",by.y="subid")
df4mod[df4mod[,y_var]==999,y_var] = NA
# df4mod[df4mod[,y_var]==777,y_var] = NA
n_disc = sum(!is.na(df4mod[,y_var]))

# construct linear model
# mixed-effect model: site as random factor, all other covariates as fixed factors
fx_form = as.formula(sprintf("%s ~ %s",y_var,"z_ds"))
rx_form = as.formula(sprintf("~ 1|%s","Centre"))
mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

# run ANOVA
res = anova(mod2use)
tres = summary(mod2use)
t_disc = tres$tTable["z_ds","t-value"]
res
cor.test(df4mod[,y_var],df4mod$z_ds)

# Replication
df4mod = subset(data2write, data2write$dataset=="Replication")
df4mod = merge(df4mod,tmp_test[,c("subid","z_ds")],by.x="subid",by.y="subid")
df4mod[df4mod[,y_var]==999,y_var] = NA
# df4mod[df4mod[,y_var]==777,y_var] = NA
n_rep = sum(!is.na(df4mod[,y_var]))

# construct linear model
# mixed-effect model: site as random factor, all other covariates as fixed factors
fx_form = as.formula(sprintf("%s ~ %s",y_var,"z_ds"))
rx_form = as.formula(sprintf("~ 1|%s","Centre"))
mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

# run ANOVA
res = anova(mod2use)
tres = summary(mod2use)
t_rep = tres$tTable["z_ds","t-value"]
res
cor.test(df4mod[,y_var],df4mod$z_ds)

# replication Bayes Factor
res_bf = BFSALL(tobs =t_disc,
                      trep = t_rep,
                      n1 = n_disc,
                      n2 = n_rep,
                      sample = 1,
                      Type = 'ALL')
res_bf["Replication BF","Replication 1"]

# plot scatterplot of z_ds by Vineland ABC
df4plot = subset(data2write)
df4plot = merge(df4plot,tmp_test[,c("subid","z_ds")],by.x="subid",by.y="subid")
df4plot[df4plot[,y_var]==999,y_var] = NA
# df4plot[df4plot[,y_var]==777,y_var] = NA

p = ggplot(data=df4plot, aes(x = z_ds, y = vabsabcabc_standard, colour = dataset)) + facet_grid(. ~ dataset)
p = p + geom_point(size=3) + geom_smooth(method=lm) + xlab("Z SC-RRB") + ylab("Vineland ABC") +
  scale_colour_manual(values = c("dodger blue","#ff8d1e")) + guides(colour=FALSE) +
  theme(text = element_text(size=fontSize),
        axis.text.x = element_text(size=fontSize),
        axis.text.y = element_text(size=fontSize))
p
```

# Vineland Daily Living Skills

```{r, warning=FALSE, message=FALSE}
# plot Vineland Daily Living Skills effect sizes over thresholds
tmp = data.frame(vabc_dls)
tmp$threshold = factor(rownames(tmp))

df2plot = melt(tmp)
p = ggplot(data = df2plot, aes(x = threshold, y =value, color=variable, group=variable)) + facet_grid(. ~ variable)
p = p + geom_line(size=4) +
  geom_point(size=7) +
  ylab("Cohen's d") +
  xlab("Z-threshold") +
  ylim(-0.1,1) + scale_colour_manual(values = c("dodger blue","#ff8d1e")) +
  guides(color=FALSE) +
  theme(text = element_text(size=fontSize),
        axis.text.x = element_text(size=fontSize),
        axis.text.y = element_text(size=fontSize))
p

#------------------------------------------------------------------------------
# model effect of z difference score on Vineland ABC
y_var = "vabsdscoresd_dss"

# Discovery
df4mod = subset(data2write, data2write$dataset=="Discovery")
df4mod = merge(df4mod,tmp_test[,c("subid","z_ds")],by.x="subid",by.y="subid")
df4mod[df4mod[,y_var]==999,y_var] = NA
# df4mod[df4mod[,y_var]==777,y_var] = NA
n_disc = sum(!is.na(df4mod[,y_var]))

# construct linear model
# mixed-effect model: site as random factor, all other covariates as fixed factors
fx_form = as.formula(sprintf("%s ~ %s",y_var,"z_ds"))
rx_form = as.formula(sprintf("~ 1|%s","Centre"))
mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

# run ANOVA
res = anova(mod2use)
tres = summary(mod2use)
t_disc = tres$tTable["z_ds","t-value"]
res
cor.test(df4mod[,y_var],df4mod$z_ds)

# Replication
df4mod = subset(data2write, data2write$dataset=="Replication")
df4mod = merge(df4mod,tmp_test[,c("subid","z_ds")],by.x="subid",by.y="subid")
df4mod[df4mod[,y_var]==999,y_var] = NA
# df4mod[df4mod[,y_var]==777,y_var] = NA
n_rep = sum(!is.na(df4mod[,y_var]))

# construct linear model
# mixed-effect model: site as random factor, all other covariates as fixed factors
fx_form = as.formula(sprintf("%s ~ %s",y_var,"z_ds"))
rx_form = as.formula(sprintf("~ 1|%s","Centre"))
mod2use = eval(substitute(lme(fixed = fx_form, random = rx_form, data = df4mod, na.action = na.omit)))

# run ANOVA
res = anova(mod2use)
tres = summary(mod2use)
t_rep = tres$tTable["z_ds","t-value"]
res
cor.test(df4mod[,y_var],df4mod$z_ds)

# replication Bayes Factor
res_bf = BFSALL(tobs =t_disc,
                      trep = t_rep,
                      n1 = n_disc,
                      n2 = n_rep,
                      sample = 1,
                      Type = 'ALL')
res_bf["Replication BF","Replication 1"]

# plot scatterplot of z_ds by Vineland ABC
df4plot = subset(data2write)
df4plot = merge(df4plot,tmp_test[,c("subid","z_ds")],by.x="subid",by.y="subid")
df4plot[df4plot[,y_var]==999,y_var] = NA
# df4plot[df4plot[,y_var]==777,y_var] = NA

p = ggplot(data=df4plot, aes(x = z_ds, y = vabsdscoresd_dss, colour = dataset)) + facet_grid(. ~ dataset)
p = p + geom_point(size=3) + geom_smooth(method=lm) + xlab("Z SC-RRB") + ylab("Vineland Daily Living Skills") +
  scale_colour_manual(values = c("dodger blue","#ff8d1e")) + guides(colour=FALSE) +
  theme(text = element_text(size=fontSize),
        axis.text.x = element_text(size=fontSize),
        axis.text.y = element_text(size=fontSize))
p
```
