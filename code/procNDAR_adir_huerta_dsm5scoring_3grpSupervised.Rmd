---
title: "NDAR subtyping"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load libraries and data

```{r, warning=FALSE, message=FALSE}
easypackages::libraries("readxl","reshape2","here","WGCNA","ggplot2")
source(here("code","ndar_functions.R"))
source(here("code","get_ggColorHue.R"))

options(stringsAsFactors = FALSE)

# rootpath = "/Users/mlombardo/Dropbox/NDARdata/ADI"
codepath = here("code")
datapath = here("data")
figpath = here("figures")
resultpath = here("results","ndar")
plotpath = here("plots","ndar")
ndardatapath = "/Users/mlombardo/Dropbox/NDARdata/ADI/data/13.12.2019"

# read in the dataset
# fname = file.path(datapath,"adi_200304_tmp.xlsx")
# D = read_excel(fname)
fname = file.path(ndardatapath,"adi_200304.csv")
D = read.csv(fname)

sub_table = read.csv(file.path(ndardatapath,"ndar_subject01.csv"))

D$phenotype = NA
for (subid in D$subjectkey){
  # print(subid)
  if (length(sub_table[sub_table$subjectkey==subid,"phenotype"])==0){
    D$phenotype[D$subjectkey==subid] = NA
  } else if (length(sub_table[sub_table$subjectkey==subid,"phenotype"])==1){
    D$phenotype[D$subjectkey==subid] = unique(sub_table[sub_table$subjectkey==subid,"phenotype"])[1]
  } else if (length(sub_table[sub_table$subjectkey==subid,"phenotype"])>1){
    D$phenotype[D$subjectkey==subid] = unique(sub_table[sub_table$subjectkey==subid,"phenotype"])[1]
  }
  # print(D$phenotype[D$subjectkey==subid])
}

# asd_codes = c("ADOS diagnosis of ASD level 2 with mild ID; Overall Total ADOS score of 17",
#               "ADOS diagnosis of ASD level 2 with moderate ID; Overall Total ADOS score of 15",
#               "ADOS diagnosis of ASD level 2; Overall Total ADOS score of 14",
#               "ADOS diagnosis of ASD with language impairments; Overall Total ADOS score of14",
#               "ADOS diagnosis of Autism Spectrum; Overall Total ADOS score of 12",
#               "ADOS diagnosis of Autism Spectrum; Overall Total ADOS score of 13",
#               "ADOS diagnosis of Autism Spectrum; Overall Total ADOS score of 9",
#               "ADOS diagnosis of Autism; Overall Total ADOS score of 14",
#               "ADOS diagnosis of Autism; Overall Total ADOS score of 15",
#               "ADOS diagnosis of Autism; Overall Total ADOS score of 16",
#               "ADOS diagnosis of Autism; Overall Total ADOS score of 17",
#               "ADOS diagnosis of Autism; Overall Total ADOS score of 18",
#               "ADOS diagnosis of Autism; Overall Total ADOS score of 19",
#               "ADOS diagnosis of autism; Overall Total ADOS score of 20",
#               "ADOS diagnosis of Autism; Overall Total ADOS score of 21",
#               "ADOS diagnosis of autism; Overall Total ADOS score of 22",
#               "ADOS diagnosis of Autism; Overall Total ADOS score of 23",
#               "ADOS diagnosis of autism; Overall Total ADOS score of 8",
#               "ADOS diagnosis of autism: Overall Total ADOS score of 24",
#               "ADOS diagnosis of mild ASD; Overall Total ADOS score of 10",
#               "ADOS diagnosis of mild ASD; Overall Total ADOS score of 9",
#               "ADOS diagnosis of mod/severe ASD; Overall Total ASD score of 16",
#               "asd",
#               "ASD","ASD and ADHD Combined Group",
#               "ASD and ADHD-C",
#               "ASD and ADHD-C and ODD","ASD and ADHD-C and specific phobia of cacti",
#               "ASD and ADHD-HI and Depression NOS","ASD and ADHD-I","ASD and ADHD-nos",
#               "ASD and GAD","ASD and OCD and specific phobia of dogs","ASD Group",
#               "ASD_ATA","Asperger","Asperger's","Auditory ASD, 4017",
#               "Auditory ASD, 4079",
#               "Auditory ASD, 7061",
#               "Auditory ASD, 7176",
#               "Auditory ASD, 7253",
#               "Auditory ASD, 7255",
#               "Auditory ASD, 7308",
#               "Auditory ASD, 7309",
#               "Auditory ASD, 7310",
#               "Auditory ASD, 7341",
#               "Auditory ASD, 7354",
#               "Auditory ASD, 7357",
#               "AutFeat",
#               "autism",
#               "Autism",
#               "Autism and  specific phobias (snakes; planes); encopresis; persistent motor or vocal tic disorder with vocal tics only",
#               "Autism and ADHD-Combined",
#               "Autism and ADHD-Combined and Generalized Anxiety and persistent tic disorder (motor)",
#               "Autism and ADHD-Combined and persistent motor or vocal tic disorder (vocal tics only)",
#               "Autism and ADHD-HI",
#               "Autism and ADHD-HI and Generalized Anxiety",
#               "Autism and ADHD-HI and specific phobia-animal(insects)",
#               "Autism and ADHD-I and specific phobia butterflies and dogs",
#               "Autism and comorbid depression NOS",
#               "Autism and Generalized Anxiety",
#               "Autism and specific phobia of dogs",
#               "Autism and unspecified depressive disorder",
#               "Autism Diagnosis",
#               "autism spectrum",
#               "Autism Spectrum",
#               "Autism Spectrum Affected",
#               "autism spectrum disorder",
#               "Autism Spectrum Disorder",
#               "Autism Spectrum Disorder (ASD)",
#               "AutismSpectrumDisorder",
#               "Autistic",
#               "Autsim",
#               "HFA",
#               "HFA,Autism",
#               "High-functioning ASD and impairing anxiety","idiopathic autism spectrum disorder",
#               "Idiopathic Autism Spectrum Disorder",
#               "LFA",
#               "PDD",
#               "PDD NOS",
#               "pdd-nos",
#               "PDD-NOS",
#               "PDDNOS",
#               "PDDNOS / Autism Spectrum")

asd_codes = c("ASD",
              "Autism",
              "PDD-NOS",
              "Proband",
              "Autistic",
              "PDDNOS",
              "Autism Spectrum",
              "Autism Spectrum Disorder",
              "PDD",
              "abcct-main.10.asd",
              "autism",
              "autism spectrum",
              "Affected",
              "severe",
              "Asperger's",
              "moderate",
              "abcct-main.11.asd",
              "Calculated using ADOS vars [ADOS_module ADOS_SARRB ADOS_Olang] and Mullen vars [MSLelTscore MSLvrTscore MSLrlTscore MSLfmTscore]",
              "LFA",
              "Autism Spectrum Disorder (ASD)",
              "PDDNOS / Autism Spectrum",
              "ADOS diagnosis of Autism; Overall Total ADOS score of 23",
              "Autsim",
              "ADOS diagnosis of autism; Overall Total ADOS score of 22",
              "ADOS diagnosis of Autism Spectrum; Overall Total ADOS score of 9",
              "ADOS diagnosis of ASD level 2; Overall Total ADOS score of 14",
              "ADOS diagnosis of Autism; Overall Total ADOS score of 16",
              "ADOS diagnosis of autism; Overall Total ADOS score of 20",
              "ADOS diagnosis of Autism; Overall Total ADOS score of 15",
              "ADOS diagnosis of mild ASD; Overall Total ADOS score of 10",
              "ADOS diagnosis of mild ASD; Overall Total ADOS score of 9",
              "ADOS diagnosis of Autism; Overall Total ADOS score of 21",
              "ADOS diagnosis of Autism; Overall Total ADOS score of 18",
              "ADOS diagnosis of mod/severe ASD; Overall Total ASD score of 16",
              "Autism Diagnosis",
              "ADOS diagnosis of ASD level 2 with moderate ID; Overall Total ADOS score of 15",
              "ADOS diagnosis of Autism; Overall Total ADOS score of 14",
              "ADOS diagnosis of Autism; Overall Total ADOS score of 19",
              "ADOS diagnosis of Autism; Overall Total ADOS score of 17",
              "ADOS diagnosis of ASD level 2 with mild ID; Overall Total ADOS score of 17",
              "ADOS diagnosis of Autism Spectrum; Overall Total ADOS score of 12",
              "ADOS diagnosis of ASD with language impairments; Overall Total ADOS score of14",
              "ADOS diagnosis of Autism Spectrum; Overall Total ADOS score of 13",
              "ADOS diagnosis of Autism; Overall Total ADOS score of 22",
              "ADOS diagnosis of autism; Overall Total ADOS score of 8",
              "ADOS diagnosis of autism; Overall Total ADOS score of 21",
              "ADOS diagnosis of autism: Overall Total ADOS score of 24",
              "ASD and ADHD-HI and Depression NOS",
              "Autism and Generalized Anxiety",
              "Autism and ADHD-Combined",
              "Autism and ADHD-HI and specific phobia-animal(insects)",
              "PDD NOS",
              "Asperger",
              "Autism and specific phobia of dogs",
              "Autism and ADHD-HI",
              "Autism and ADHD-Combined and Generalized Anxiety and persistent tic disorder (motor)",
              "Autism and unspecified depressive disorder",
              "Autism and ADHD-HI and Generalized Anxiety",
              "Autism and ADHD-I and specific phobia butterflies and dogs",
              "Autism and comorbid depression NOS",
              "Autism and  specific phobias (snakes; planes); encopresis; persistent motor or vocal tic disorder with vocal tics only",
              "Autism and ADHD-Combined and persistent motor or vocal tic disorder (vocal tics only)",
              "ASD Group",
              "Idiopathic Autism Spectrum Disorder",
              "Autism Spectrum Affected",
              "HFA,Autism",
              "ASD_ATA",
              "idiopathic autism spectrum disorder",
              "Auditory ASD, 7357",
              "Auditory ASD, 7354",
              "Auditory ASD, 7309",
              "Auditory ASD, 7255",
              "Auditory ASD, 7310",
              "AutismSpectrumDisorder",
              "ASD and ADHD-I",
              "ASD and GAD",
              "ASD and ADHD-C and ODD",
              "ASD and ADHD-C",
              "ASD and OCD and specific phobia of dogs",
              "ASD and ADHD-nos",
              "ASD and ADHD-C and specific phobia of cacti",
              "pdd-nos")

# D_merge = merge(sub_table[,c("subjectkey","phenotype")],D, by = "subjectkey")

# sub_table_subset = subset(sub_table, is.element(sub_table$phenotype, asd_codes))

# D_subset = subset(D, is.element(D$subjectkey,sub_table_subset$subjectkey))
D_subset = subset(D, is.element(D$phenotype,asd_codes))

D_orig = D
D = D_subset

# Information on what variables to look for
# background variables
# backgrnd_vars2use = c("collection_id",
#                       "dataset_id",
#                       "subjectkey",
#                       "gender",
#                       "interview_age",
#                       "bkgrnd_diag",
#                       "rx",
#                       "bkgrnd_med")
backgrnd_vars2use = c("collection_id",
                      "dataset_id",
                      "subjectkey",
                      "sex",
                      "interview_age",
                      "bkgrnd_diag",
                      "rx",
                      "bkgrnd_med")

# print out number of unique datasets
sprintf("Number of datasets = %d",length(unique(D$collection_id)))

#print out number of unique individuals
sprintf("Number of individuals = %d",dim(D)[1])
```

Rescore data

```{r, warning=FALSE, message=FALSE}
# nonverbal masks
# acquisition of words
mask1 = D[,c("acqorlossoflang_aword")]>900 | is.na(D[,c("acqorlossoflang_aword")]) 
# acquisition of phrases
mask2 = D[,c("acqorlossoflang_aphrase")]>900 | is.na(D[,c("acqorlossoflang_aphrase")])
# social verbalization, chit chat
mask3 = is.na(D[,"funccom_cchat"]) | D[,"funccom_cchat"]==7 | D[,"funccom_cchat"]==8 | D[,"funccom_cchat"]==9 
# reciprocal conversation
mask4 = is.na(D[,"funccom_chat5"]) | D[,"funccom_chat5"]==7 | D[,"funccom_chat5"]==8 | D[,"funccom_chat5"]==9 
# inappropriate questions
mask5 = is.na(D[,"funccom_cinappq"]) | D[,"funccom_cinappq"]==7 | D[,"funccom_cinappq"]==8 | 
D[,"funccom_cinappq"]==9 
# stereotype utterances and delayed echolalia 
mask6 = is.na(D[,"funccom_estereo"]) | D[,"funccom_estereo"]==7 | D[,"funccom_estereo"]==8 | 
D[,"funccom_estereo"]==9 
# pronominal reversal 
mask7 = is.na(D[,"funccom_epron"]) | D[,"funccom_epron"]==7 | D[,"funccom_epron"]==8 | 
D[,"funccom_epron"]==9 
# neologisms and idiosyncratic language 
mask8 = is.na(D[,"funccom_eneoid"]) | D[,"funccom_eneoid"]==7 | D[,"funccom_eneoid"]==8 | 
D[,"funccom_eneoid"]==9 
# verbal rituals 
mask9 = is.na(D[,"funccom_everrit"]) | D[,"funccom_everrit"]==7 | D[,"funccom_everrit"]==8 | 
D[,"funccom_everrit"]==9 

# mask of subjects that are likely nonverbal because of missing data across all these communication items
nonverbal_mask = mask3 & mask4 & mask5 & mask6 & mask7 & mask8 & mask9

# replace A1 scores with rescored data
D$dbaes_a1_orig = D$dbaes_a1
D$dbaes_a1 = RescoreADI_DSM5(D, adi_A1_items, "A1")

# replace A2 scores with rescored data
D$dbaes_a2_orig = D$dbaes_a2
D$dbaes_a2 = RescoreADI_DSM5(D, adi_A2_items, "A2")

# replace A3 scores with rescored data
D$dbaes_a3_orig = D$dbaes_a3
D$dbaes_a3 = RescoreADI_DSM5(D, adi_A3_items, "A3")

# replace B1 scores with rescored data
D$dbaes_b1_orig = D$dbaes_b1
D$dbaes_b1 = RescoreADI_DSM5(D, adi_B1_items, "B1")

# replace B2 scores with rescored data
D$dbaes_b2_orig = D$dbaes_b2
D$dbaes_b2 = RescoreADI_DSM5(D, adi_B2_items, "B2")

# replace B3 scores with rescored data
D$dbaes_b3_orig = D$dbaes_b3
D$dbaes_b3 = RescoreADI_DSM5(D, adi_B3_items, "B3")

# replace B4 scores with rescored data
D$dbaes_b4_orig = D$dbaes_b4
D$dbaes_b4 = RescoreADI_DSM5(D, adi_B4_items, "B4")

# score DSMIV verbal items
D$dbaes_dsmivverbal_total = RescoreADI_DSM5(D, adi_DSMIVverbal_items, "DSMIVverbal")

# recompute the atotal
D$dbaes_atotal = D$dbaes_a1 + D$dbaes_a2 + D$dbaes_a3

# recompute the btotal
D$dbaes_btotal = D$dbaes_b1 + D$dbaes_b2 +  D$dbaes_b3 + D$dbaes_b4

# dataset to exclude because of lots of zeros UW ACE Extended Family Study
dsetID2exclude = c(8395)
mask = is.element(D$dataset_id,dsetID2exclude)
D = D[!mask,]

# missing data codes
missingCodes = c(-999,999,9999)
atotal_missingMask = is.element(D$dbaes_atotal,missingCodes) | is.na(D$dbaes_atotal)
btotal_missingMask = is.element(D$dbaes_btotal,missingCodes) | is.na(D$dbaes_btotal)

# c(sum(atotal_missingMask), sum(btotal_missingMask))

# verbal_mask = !is.na(D$dbaes_dsmivverbal_total)
verbal_mask = !nonverbal_mask
# find subjects with A, B totals
verbal_ONLY_submask = !atotal_missingMask & !btotal_missingMask & verbal_mask
# # # find subjects with A, B C totals
nonverbal_ONLY_submask = !atotal_missingMask & !btotal_missingMask & !verbal_mask

# # print total number of subjects
# c(sum(verbal_ONLY_submask), sum(nonverbal_ONLY_submask))

vars2use = c(backgrnd_vars2use, "dbaes_dsmivverbal_total",
             adi_total_vars2use, adi_subtotal_vars2use,
             adi_A1_items, adi_A2_items, adi_A3_items,
             adi_B1_items, adi_B2_items, adi_B3_items, adi_B4_items)

Dverbal = D[verbal_ONLY_submask, vars2use]
Dnonverbal = D[nonverbal_ONLY_submask, vars2use]

# print total number of individuals from verbal subset
sprintf("Number of individuals with verbal ADI-R data = %d",dim(Dverbal)[1])

# print out total number of datasets within verbal subset
sprintf("Number of datasets with verbal ADI-R data = %d",length(unique(Dverbal$collection_id)))

# print total number of individuals from nonverbal subset
sprintf("Number of individuals with nonverbal ADI-R data = %d",dim(Dnonverbal)[1])

# print out total number of datasets within nonverbal subset
sprintf("Number of datasets with nonverbal ADI-R data = %d",length(unique(Dnonverbal$collection_id)))
```

Split datasets

```{r, warning=FALSE, message=FALSE}
# # Split datasets
# rngSeed = 1
# # split verbal dataset
# tmp_d = SplitDatasets(Dverbal, rngSeed = rngSeed)
# Dverbal_Discovery = tmp_d[[1]]
# Dverbal_Replication = tmp_d[[2]]
# 
# c(dim(Dverbal_Discovery)[1], dim(Dverbal_Replication)[1])

# Split datasets by sex
rngSeed = 1
# split verbal dataset
tmp_d = SplitDatasetsBySex(Dverbal, rngSeed = rngSeed)
Dverbal_Discovery = tmp_d[[1]]
Dverbal_Replication = tmp_d[[2]]

c(dim(Dverbal_Discovery)[1], dim(Dverbal_Replication)[1])


# Split datasets by sex
rngSeed = 1
# split nonverbal dataset
tmp_d = SplitDatasetsBySex(Dnonverbal, rngSeed = rngSeed)
Dnonverbal_Discovery = tmp_d[[1]]
Dnonverbal_Replication = tmp_d[[2]]

c(dim(Dnonverbal_Discovery)[1], dim(Dnonverbal_Replication)[1])
```

Cluster verbal datasets

```{r, warning=FALSE, message=FALSE}
itemSummaryPlotWidth = 14
dS = 0

# cluster verbal datasets by ADI-R Algorithm Domain Totals-------------------
# Discovery+Replication------------------------------------------------------
maxScores = c(3,4)
data2use = Dverbal[,adi_total_vars2use]

# discReorderedItems = colnames(data2use)
fname2save = file.path(plotpath,
                       sprintf("clustergram_ADIalgoTotals_verbalDiscovery+Replication_euclidean_ward_deepSplit%d.pdf",dS))
verbalALL_clustResults = ClusterData(data2use, 
                                           deepSplit=dS, 
                                           fname2save = fname2save)
fname2save = file.path(resultpath,
                       sprintf("results_ADIalgoTotals_verbalDiscovery+Replication_euclidean_ward_deepSplit%d.rds",dS))
saveRDS(verbalALL_clustResults, file = fname2save)

# fname2save = file.path(plotpath,
#                        sprintf("summaryPlot_ADIalgoTotals_verbalDiscovery_euclidean_ward_deepSplit%d.pdf",dS))
# makeSummaryPlot(verbalDiscovery_clustResults,
#                 fname2save = fname2save,
#                 transformPercentSeverity = maxScores)
# OLD==========================================================================
# oldColors = c("blue","brown","green","red","turquoise","yellow")
# newColors = c("2","3","1","6","4","5")
# NEW==========================================================================
oldColors = c("black","blue","brown","green","pink","red","turquoise","yellow")
newColors = c("6","8","4","5","3","2","7","1")

verbalALL_clustResults = relabelClusters(verbalALL_clustResults, oldColors, newColors)
makeClustergram(verbalALL_clustResults, fname2save = fname2save)
# fname2save = file.path(plotpath,
#                        sprintf("summaryPlot_ADIalgoTotals_verbalDiscovery_euclidean_ward_deepSplit%d.pdf",dS))
# makeSummaryPlot(verbalDiscovery_clustResults, 
#                 fname2save = fname2save, 
#                 transformPercentSeverity = maxScores)

# make plot with all individuals shown as lines
df2use = Dverbal[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(verbalALL_clustResults$dynamicColors)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$dbaes_atotal = df2use$dbaes_atotal/maxScores[1]
df2use$dbaes_btotal = df2use$dbaes_btotal/maxScores[2]
df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"), 
               measure.vars = c("dbaes_atotal","dbaes_btotal"))

ggcolors = get_ggColorHue(3)
colors2use = c(ggcolors[1],ggcolors[1],ggcolors[1],ggcolors[2],ggcolors[2],ggcolors[3],ggcolors[3],ggcolors[3])
p = ggplot(data = df4plot, aes(x = variable, 
                               y = value, 
                               colour = subgrp, 
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + guides(color=FALSE) +
  scale_colour_manual(values = colors2use) + ylim(0,0.8)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
fname2save = file.path(plotpath,
                       sprintf("summaryPlot_IndividualSubs_ADIalgoTotals_verbalDiscovery+Replication_euclidean_ward_deepSplit%d.pdf",dS))
ggsave(filename = fname2save)
p



# cluster verbal datasets by ADI-R Algorithm Domain Totals-------------------
# Discovery------------------------------------------------------------------
maxScores = c(3,4)
data2use = Dverbal_Discovery[,adi_total_vars2use]

# discReorderedItems = colnames(data2use)
fname2save = file.path(plotpath,
                       sprintf("clustergram_ADIalgoTotals_verbalDiscovery_euclidean_ward_deepSplit%d.pdf",dS))
verbalDiscovery_clustResults = ClusterData(data2use, 
                                           deepSplit=dS, 
                                           fname2save = fname2save)
fname2save = file.path(resultpath,
                       sprintf("results_ADIalgoTotals_verbalDiscovery_euclidean_ward_deepSplit%d.rds",dS))
saveRDS(verbalDiscovery_clustResults, file = fname2save)

# fname2save = file.path(plotpath,
#                        sprintf("summaryPlot_ADIalgoTotals_verbalDiscovery_euclidean_ward_deepSplit%d.pdf",dS))
# makeSummaryPlot(verbalDiscovery_clustResults,
#                 fname2save = fname2save,
#                 transformPercentSeverity = maxScores)
# OLD==========================================================================
# oldColors = c("blue","brown","green","red","turquoise","yellow")
# newColors = c("2","3","1","6","4","5")
# NEW==========================================================================
oldColors = c("black","blue","brown","green","red","turquoise","yellow")
# newColors = c("7","6","4","1","3","2","5")
newColors = c("3","7","5","1","4","2","6")

verbalDiscovery_clustResults = relabelClusters(verbalDiscovery_clustResults, oldColors, newColors)
makeClustergram(verbalDiscovery_clustResults, fname2save = fname2save)
# fname2save = file.path(plotpath,
#                        sprintf("summaryPlot_ADIalgoTotals_verbalDiscovery_euclidean_ward_deepSplit%d.pdf",dS))
# makeSummaryPlot(verbalDiscovery_clustResults, 
#                 fname2save = fname2save, 
#                 transformPercentSeverity = maxScores)

# make plot with all individuals shown as lines
df2use = Dverbal_Discovery[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(verbalDiscovery_clustResults$dynamicColors)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$dbaes_atotal = df2use$dbaes_atotal/maxScores[1]
df2use$dbaes_btotal = df2use$dbaes_btotal/maxScores[2]
df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"), 
               measure.vars = c("dbaes_atotal","dbaes_btotal"))

ggcolors = get_ggColorHue(3)
colors2use = c(ggcolors[1],ggcolors[1],ggcolors[1],ggcolors[2],ggcolors[2],ggcolors[3],ggcolors[3])
p = ggplot(data = df4plot, aes(x = variable, 
                               y = value, 
                               colour = subgrp, 
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + guides(color=FALSE) +
  scale_colour_manual(values = colors2use) + ylim(0,0.8)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
fname2save = file.path(plotpath,
                       sprintf("summaryPlot_IndividualSubs_ADIalgoTotals_verbalDiscovery_euclidean_ward_deepSplit%d.pdf",dS))
ggsave(filename = fname2save)
p


# Replication----------------------------------------------------------------
data2use = Dverbal_Replication[,adi_total_vars2use]

fname2save = file.path(plotpath,
                       sprintf("clustergram_ADIalgoTotals_verbalReplication_euclidean_ward_deepSplit%d.pdf",dS))
verbalReplication_clustResults = ClusterData(data2use, 
                                             deepSplit=dS, 
                                             fname2save = fname2save)
fname2save = file.path(resultpath,
                       sprintf("results_ADIalgoTotals_verbalReplication_euclidean_ward_deepSplit%d.rds",dS))
saveRDS(verbalReplication_clustResults, file = fname2save)

# fname2save = file.path(plotpath,
#                        sprintf("summaryPlot_ADIalgoTotals_verbalReplication_euclidean_ward_deepSplit%d.pdf",dS))
# makeSummaryPlot(verbalReplication_clustResults, 
#                 fname2save = fname2save, 
#                 transformPercentSeverity = maxScores)

# OLD==========================================================================
# oldColors = c("black","blue","brown","green","red","turquoise","yellow")
# newColors = c("3","5","1","2","6","7","4")
# NEW==========================================================================
oldColors = c("black","blue","brown","green","pink","red","turquoise","yellow")
# newColors = c("5","2","7","8","4","1","3","6")
newColors = c("5","1","8","3","4","6","2","7")

verbalReplication_clustResults = relabelClusters(verbalReplication_clustResults, 
                                                 oldColors, 
                                                 newColors)
makeClustergram(verbalReplication_clustResults, fname2save = fname2save)
# fname2save = file.path(plotpath,
#                        sprintf("summaryPlot_ADIalgoTotals_verbalReplication_euclidean_ward_deepSplit%d.pdf",dS))
# makeSummaryPlot(verbalReplication_clustResults, 
#                 fname2save = fname2save, 
#                 transformPercentSeverity = maxScores)

# make plot with all individuals shown as lines
df2use = Dverbal_Replication[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(verbalReplication_clustResults$dynamicColors)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$dbaes_atotal = df2use$dbaes_atotal/maxScores[1]
df2use$dbaes_btotal = df2use$dbaes_btotal/maxScores[2]
df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"), 
               measure.vars = c("dbaes_atotal","dbaes_btotal"))

ggcolors = get_ggColorHue(3)
colors2use = c(ggcolors[1],ggcolors[1],ggcolors[1],ggcolors[2],ggcolors[2],ggcolors[3],ggcolors[3],ggcolors[3])
# colors2use = ggcolors[1:8]
p = ggplot(data = df4plot, aes(x = variable, 
                               y = value, 
                               colour = subgrp, 
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + guides(color=FALSE) +
  scale_colour_manual(values = colors2use) + ylim(0,0.8)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
fname2save = file.path(plotpath,
                       sprintf("summaryPlot_IndividualSubs_ADIalgoTotals_verbalReplication_euclidean_ward_deepSplit%d.pdf",dS))
ggsave(filename = fname2save)
p
```

Cluster nonverbal datasets

```{r, warning=FALSE, message=FALSE}
itemSummaryPlotWidth = 14
dS = 0

# cluster nonverbal datasets by ADI-R Algorithm Domain Totals-------------------
# Discovery------------------------------------------------------------------
maxScores = c(3,4)
data2use = Dnonverbal_Discovery[,adi_total_vars2use]

# discReorderedItems = colnames(data2use)
fname2save = file.path(plotpath,
                       sprintf("clustergram_ADIalgoTotals_nonverbalDiscovery_euclidean_ward_deepSplit%d.pdf",dS))
nonverbalDiscovery_clustResults = ClusterData(data2use, 
                                           deepSplit=dS, 
                                           fname2save = fname2save)
fname2save = file.path(resultpath,
                       sprintf("results_ADIalgoTotals_nonverbalDiscovery_euclidean_ward_deepSplit%d.rds",dS))
saveRDS(nonverbalDiscovery_clustResults, file = fname2save)

# fname2save = file.path(plotpath,
#                        sprintf("summaryPlot_ADIalgoTotals_verbalDiscovery_euclidean_ward_deepSplit%d.pdf",dS))
# makeSummaryPlot(verbalDiscovery_clustResults,
#                 fname2save = fname2save,
#                 transformPercentSeverity = maxScores)
# OLD==========================================================================
# oldColors = c("blue","brown","green","red","turquoise","yellow")
# newColors = c("2","3","1","6","4","5")
# NEW==========================================================================
oldColors = c("blue","brown","green","red","turquoise","yellow")
newColors = c("2","1","6","4","3","5")

nonverbalDiscovery_clustResults = relabelClusters(nonverbalDiscovery_clustResults, oldColors, newColors)
makeClustergram(nonverbalDiscovery_clustResults, fname2save = fname2save)
# fname2save = file.path(plotpath,
#                        sprintf("summaryPlot_ADIalgoTotals_verbalDiscovery_euclidean_ward_deepSplit%d.pdf",dS))
# makeSummaryPlot(verbalDiscovery_clustResults, 
#                 fname2save = fname2save, 
#                 transformPercentSeverity = maxScores)

# make plot with all individuals shown as lines
df2use = Dnonverbal_Discovery[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(nonverbalDiscovery_clustResults$dynamicColors)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$dbaes_atotal = df2use$dbaes_atotal/maxScores[1]
df2use$dbaes_btotal = df2use$dbaes_btotal/maxScores[2]
df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"), 
               measure.vars = c("dbaes_atotal","dbaes_btotal"))

ggcolors = get_ggColorHue(5)
colors2use = c(ggcolors[1],ggcolors[1],ggcolors[2],ggcolors[3],ggcolors[4],ggcolors[5])
p = ggplot(data = df4plot, aes(x = variable, 
                               y = value, 
                               colour = subgrp, 
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + guides(color=FALSE) +
  scale_colour_manual(values = colors2use) + ylim(0,0.8)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
fname2save = file.path(plotpath,
                       sprintf("summaryPlot_IndividualSubs_ADIalgoTotals_nonverbalDiscovery_euclidean_ward_deepSplit%d.pdf",dS))
ggsave(filename = fname2save)
p


# Replication----------------------------------------------------------------
data2use = Dnonverbal_Replication[,adi_total_vars2use]

fname2save = file.path(plotpath,
                       sprintf("clustergram_ADIalgoTotals_nonverbalReplication_euclidean_ward_deepSplit%d.pdf",dS))
nonverbalReplication_clustResults = ClusterData(data2use, 
                                             deepSplit=dS, 
                                             fname2save = fname2save)
fname2save = file.path(resultpath,
                       sprintf("results_ADIalgoTotals_nonverbalReplication_euclidean_ward_deepSplit%d.rds",dS))
saveRDS(nonverbalReplication_clustResults, file = fname2save)

# fname2save = file.path(plotpath,
#                        sprintf("summaryPlot_ADIalgoTotals_verbalReplication_euclidean_ward_deepSplit%d.pdf",dS))
# makeSummaryPlot(verbalReplication_clustResults, 
#                 fname2save = fname2save, 
#                 transformPercentSeverity = maxScores)

# OLD==========================================================================
# oldColors = c("black","blue","brown","green","red","turquoise","yellow")
# newColors = c("3","5","1","2","6","7","4")
# NEW==========================================================================
oldColors = c("black","blue","brown","green","red","turquoise","yellow")
newColors = c("4","3","2","6","5","1","7")

nonverbalReplication_clustResults = relabelClusters(nonverbalReplication_clustResults, 
                                                 oldColors, 
                                                 newColors)
makeClustergram(nonverbalReplication_clustResults, fname2save = fname2save)
# fname2save = file.path(plotpath,
#                        sprintf("summaryPlot_ADIalgoTotals_verbalReplication_euclidean_ward_deepSplit%d.pdf",dS))
# makeSummaryPlot(verbalReplication_clustResults, 
#                 fname2save = fname2save, 
#                 transformPercentSeverity = maxScores)

# make plot with all individuals shown as lines
df2use = Dnonverbal_Replication[,c("subjectkey",adi_total_vars2use)]
df2use$subgrp = factor(nonverbalReplication_clustResults$dynamicColors)
df2use = data.frame(df2use)
df2use$subjectkey = factor(df2use$subjectkey)
df2use$dbaes_atotal = df2use$dbaes_atotal/maxScores[1]
df2use$dbaes_btotal = df2use$dbaes_btotal/maxScores[2]
df4plot = melt(df2use,
               id.vars = c("subjectkey","subgrp"), 
               measure.vars = c("dbaes_atotal","dbaes_btotal"))

ggcolors = get_ggColorHue(5)
colors2use = c(ggcolors[1],ggcolors[2],ggcolors[2],ggcolors[3],ggcolors[3],ggcolors[4],ggcolors[5])
p = ggplot(data = df4plot, aes(x = variable, 
                               y = value, 
                               colour = subgrp, 
                               group = subjectkey)) + facet_grid(. ~ subgrp)
p = p + geom_point(shape=1) + geom_line(alpha = 0.2) + guides(color=FALSE) +
  scale_colour_manual(values = colors2use) + ylim(0,0.8)
p = p + ylab("Percent Severity") + xlab("ADI-R subscale")
fname2save = file.path(plotpath,
                       sprintf("summaryPlot_IndividualSubs_ADIalgoTotals_nonverbalReplication_euclidean_ward_deepSplit%d.pdf",dS))
ggsave(filename = fname2save)
p
```



```{r, warning=FALSE, message=FALSE}
n_disc = length(verbalDiscovery_clustResults$dynamicColors)
n_rep =  length(verbalReplication_clustResults$dynamicColors)

table(verbalDiscovery_clustResults$dynamicColors)
table(verbalDiscovery_clustResults$dynamicColors)/n_disc

table(verbalReplication_clustResults$dynamicColors)
table(verbalReplication_clustResults$dynamicColors)/n_rep

# compute mean age for subgroups
group_labels = c("1","2","3","4","5","6")

for (grp in group_labels){
  mask = verbalDiscovery_clustResults$dynamicColors==grp
  print(grp)
  print(table(Dverbal_Discovery[mask,"dataset_id"]))
  print(median(as.matrix(Dverbal_Discovery[mask,"interview_age"],na.rm=TRUE))/12)
  print(sd(as.matrix(Dverbal_Discovery[mask,"interview_age"],na.rm=TRUE))/12)
  # print(hist(as.matrix(Dverbal_Discovery[mask,"interview_age"])/12, breaks=50))
}

Dverbal_Discovery$subgrp = verbalDiscovery_clustResults$dynamicColors
Dverbal_Replication$subgrp = verbalReplication_clustResults$dynamicColors

# table(Dverbal_Discovery$subgrp,Dverbal_Discovery$gender)/rowSums(table(Dverbal_Discovery$subgrp,Dverbal_Discovery$gender))
# table(Dverbal_Replication$subgrp,Dverbal_Replication$gender)/rowSums(table(Dverbal_Replication$subgrp,Dverbal_Replication$gender))

```